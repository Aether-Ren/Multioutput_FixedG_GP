{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb6b3d5",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ed3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "import contextlib\n",
    "\n",
    "import math\n",
    "\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import statsmodels\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from pyro.ops.stats import (\n",
    "    gelman_rubin,\n",
    "    split_gelman_rubin,\n",
    "    autocorrelation,\n",
    "    effective_sample_size,\n",
    "    resample,\n",
    "    quantile,\n",
    "    weighed_quantile\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import GP_functions.Loss_function as Loss_function\n",
    "import GP_functions.bound as bound\n",
    "import GP_functions.Estimation as Estimation\n",
    "import GP_functions.Training as Training\n",
    "import GP_functions.Prediction as Prediction\n",
    "import GP_functions.GP_models as GP_models\n",
    "import GP_functions.Tools as Tools\n",
    "import GP_functions.FeatureE as FeatureE\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdfe27c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a96409",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('RealCase/RealCase_X_train.csv', header=None, delimiter=',').values\n",
    "X_test = pd.read_csv('RealCase/RealCase_X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('RealCase/RealCase_Y_train_std.csv', header=None, delimiter=',').values\n",
    "Y_test_std = pd.read_csv('RealCase/RealCase_Y_test_std.csv', header=None, delimiter=',').values\n",
    "Realcase_data_std = pd.read_csv('RealCase/RealCase_Y_std.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train = pd.read_csv('RealCase/RealCase_Y_train.csv', header=None, delimiter=',').values\n",
    "Y_test = pd.read_csv('RealCase/RealCase_Y_test.csv', header=None, delimiter=',').values\n",
    "Realcase_data = pd.read_csv('RealCase/RealCase.csv', header=None, delimiter=',').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e18a361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(X_train, dtype=torch.float32)\n",
    "test_x = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "train_y = torch.tensor(Y_train_std, dtype=torch.float32)\n",
    "test_y = torch.tensor(Y_test_std, dtype=torch.float32)\n",
    "realcase_y = torch.tensor(Realcase_data_std, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419613d6",
   "metadata": {},
   "source": [
    "# Emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ea816",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('multitask_gp_checkpoint_Realcase.pth', map_location=Device)\n",
    "model_params = checkpoint['model_params']\n",
    "\n",
    "MVGP_models = GP_models.MultitaskVariationalGP(train_x, train_y, \n",
    "                                               num_latents=model_params['num_latents'],\n",
    "                                               num_inducing=model_params['num_inducing'],  \n",
    "                                               covar_type=model_params['covar_type']).to(Device)\n",
    "\n",
    "MVGP_models.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "MVGP_likelihoods = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=train_y.shape[1]).to(Device)\n",
    "MVGP_likelihoods.load_state_dict(checkpoint['likelihood_state_dict'])\n",
    "\n",
    "MVGP_models.eval()\n",
    "MVGP_likelihoods.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e1083",
   "metadata": {},
   "source": [
    "# MCMC Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32744007",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_samples = torch.load(\"mcmc_RealCase_final_mcmc_infer_2block_independent.pt\", map_location=Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4872eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = Tools.extract_vector_params_from_mcmc(\n",
    "    loaded_samples,\n",
    "    key=\"params\",\n",
    "    param_names=[f\"theta_{i}\" for i in range(10)]  # 你也可以用真实参数名\n",
    ")\n",
    "\n",
    "posterior_samples_theta = posterior_samples.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba73df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_extract = ['sigma_meas_1', 'sigma_meas_2']\n",
    "posterior_samples.update({k: loaded_samples[k] for k in keys_to_extract})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0633bac",
   "metadata": {},
   "source": [
    "# MCMC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tools.visualize_posterior_1d_params(\n",
    "    posterior_samples,\n",
    "    bins=15,\n",
    "    acf_lags=40,\n",
    "    clip_percentiles=(0.5, 99.5),\n",
    "    xlim=None,          # 需要固定范围就填 (low, high)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef0a67",
   "metadata": {},
   "source": [
    "# Posterior predictive resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42969ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _sorted_param_keys(sample_dict):\n",
    "    \"\"\"\n",
    "    支持 key 形如:\n",
    "      - \"param_0\", \"param_1\", ...\n",
    "      - \"theta_0\", \"theta_1\", ...\n",
    "      - 任何以 _数字 结尾的 key\n",
    "    \"\"\"\n",
    "    def idx(k: str) -> int:\n",
    "        m = re.search(r\"(\\d+)$\", k)\n",
    "        if m is None:\n",
    "            raise ValueError(f\"Cannot parse index from key='{k}'. Expect suffix like _0, _1, ...\")\n",
    "        return int(m.group(1))\n",
    "\n",
    "    return sorted(sample_dict.keys(), key=idx)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def posterior_predictive_resample(\n",
    "    samples,\n",
    "    Pre_function,\n",
    "    Models,\n",
    "    Likelihoods,\n",
    "    num_draws=20,\n",
    "    *,\n",
    "    device=\"cpu\",\n",
    "    chunk_size=256,\n",
    "    group_by_chain=False,      # True: samples[k] is [C,S,...] -> flatten to [C*S,...]\n",
    "    use_fast_pred_var=False,   # 如果你在 Pre_function 内部已经开了 fast_pred_var，就设 False\n",
    "    return_mean_var=False,     # 可选：同时返回每个 theta 的预测 mean/var\n",
    "    use_rsample=True,          # True: rsample; False: sample\n",
    "):\n",
    "    \"\"\"\n",
    "    Posterior predictive resampling for GPyTorch multitask GP predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : dict[str, Tensor]\n",
    "        MCMC samples dict, each key maps to Tensor on CPU or GPU.\n",
    "        Typical shapes:\n",
    "          - [S] for single-chain\n",
    "          - [C,S] for multi-chain (if group_by_chain=True will flatten)\n",
    "\n",
    "    Pre_function : callable(model, likelihood, x)\n",
    "        Should return a GPyTorch distribution, e.g. MultitaskMultivariateNormal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    theta_all : Tensor [S_total, P]  (CPU)\n",
    "    y_pp      : Tensor [S_total, num_draws, D]  (CPU)\n",
    "    (optional) mean_all : Tensor [S_total, D] (CPU)\n",
    "    (optional) var_all  : Tensor [S_total, D] (CPU)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- 0) make sample_shape torch.Size (GPyTorch rsample expects torch.Size in some versions) ----\n",
    "    if isinstance(num_draws, int):\n",
    "        sample_shape = torch.Size([num_draws])\n",
    "    else:\n",
    "        # allow user pass tuple/list like (n,) or [n]\n",
    "        sample_shape = torch.Size(list(num_draws))\n",
    "\n",
    "    keys = _sorted_param_keys(samples)\n",
    "\n",
    "    def flatten_chain(x: torch.Tensor) -> torch.Tensor:\n",
    "        # If multi-chain tensor [C,S,...] and group_by_chain=True -> [C*S,...]\n",
    "        if group_by_chain and x.dim() >= 2:\n",
    "            return x.reshape(-1, *x.shape[2:])\n",
    "        return x\n",
    "\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # ---- 1) build theta_all: [S_total, P] ----\n",
    "    param_list = []\n",
    "    for k in keys:\n",
    "        x = flatten_chain(samples[k])\n",
    "        x = x.to(device=device, dtype=torch.float32)\n",
    "        # Expect x is [S_total] for scalar params, or [S_total, ...] if vector params\n",
    "        param_list.append(x)\n",
    "\n",
    "    # Stack last dim as parameter dim P\n",
    "    # Scalar params -> theta_all [S_total, P]\n",
    "    theta_all = torch.stack(param_list, dim=-1)\n",
    "    S_total, P = theta_all.shape\n",
    "\n",
    "    # ---- 2) set eval mode (supports single model or list/tuple) ----\n",
    "    try:\n",
    "        Models.eval()\n",
    "    except Exception:\n",
    "        if isinstance(Models, (list, tuple)):\n",
    "            for m in Models:\n",
    "                if hasattr(m, \"eval\"):\n",
    "                    m.eval()\n",
    "\n",
    "    try:\n",
    "        Likelihoods.eval()\n",
    "    except Exception:\n",
    "        if isinstance(Likelihoods, (list, tuple)):\n",
    "            for l in Likelihoods:\n",
    "                if hasattr(l, \"eval\"):\n",
    "                    l.eval()\n",
    "\n",
    "    # ---- 3) chunked posterior predictive sampling ----\n",
    "    y_chunks = []\n",
    "    mean_chunks, var_chunks = [], []\n",
    "\n",
    "    fast_ctx = None\n",
    "    if use_fast_pred_var:\n",
    "        import gpytorch\n",
    "        fast_ctx = gpytorch.settings.fast_pred_var()\n",
    "\n",
    "    # helper: normalize draws to [B, num_draws, D]\n",
    "    def _to_BSD(draws: torch.Tensor, B: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Common cases:\n",
    "          - [num_draws, B, D]\n",
    "          - [num_draws, 1, B, D]  (extra singleton batch)\n",
    "          - [num_draws, B, 1, D]  (extra singleton batch)\n",
    "          - [num_draws, D]        (B==1)\n",
    "        Return:\n",
    "          - [B, num_draws, D]\n",
    "        \"\"\"\n",
    "        if draws.dim() == 4:\n",
    "            # [num_draws, 1, B, D] -> [num_draws, B, D]\n",
    "            if draws.shape[1] == 1 and draws.shape[2] == B:\n",
    "                draws = draws.squeeze(1)\n",
    "            # [num_draws, B, 1, D] -> [num_draws, B, D]\n",
    "            elif draws.shape[2] == 1 and draws.shape[1] == B:\n",
    "                draws = draws.squeeze(2)\n",
    "\n",
    "        if draws.dim() == 2:\n",
    "            # [num_draws, D] -> [num_draws, 1, D]\n",
    "            draws = draws.unsqueeze(1)\n",
    "\n",
    "        if draws.dim() != 3:\n",
    "            raise RuntimeError(f\"Unexpected draws shape {tuple(draws.shape)}; cannot convert to [B,S,D].\")\n",
    "\n",
    "        # now [num_draws, B, D] -> [B, num_draws, D]\n",
    "        if draws.shape[1] != B:\n",
    "            raise RuntimeError(\n",
    "                f\"Draws has shape {tuple(draws.shape)}; expected second dim == B={B}.\"\n",
    "            )\n",
    "        return draws.permute(1, 0, 2).contiguous()\n",
    "\n",
    "    # helper: normalize mean/var to [B, D]\n",
    "    def _to_BD(x: torch.Tensor, B: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Common cases:\n",
    "          - [B, D]\n",
    "          - [1, B, D]\n",
    "          - [B] or [1, D] shouldn't happen for multitask, but handle minimally\n",
    "        \"\"\"\n",
    "        if x.dim() == 3 and x.shape[0] == 1 and x.shape[1] == B:\n",
    "            x = x.squeeze(0)\n",
    "        if x.dim() == 2 and x.shape[0] == B:\n",
    "            return x\n",
    "        if x.dim() == 1 and B == 1:\n",
    "            # [D] -> [1, D]\n",
    "            return x.unsqueeze(0)\n",
    "        raise RuntimeError(f\"Unexpected mean/var shape {tuple(x.shape)}; expected [B,D] (B={B}).\")\n",
    "\n",
    "    with (fast_ctx if fast_ctx is not None else contextlib.nullcontext()):\n",
    "        for start in range(0, S_total, chunk_size):\n",
    "            th = theta_all[start:start + chunk_size]  # [B, P]\n",
    "            B = th.shape[0]\n",
    "\n",
    "            # 3.1 preferred: vectorized call\n",
    "            try:\n",
    "                pred_dist = Pre_function(Models, Likelihoods, th)\n",
    "\n",
    "                if use_rsample and hasattr(pred_dist, \"rsample\"):\n",
    "                    draws = pred_dist.rsample(sample_shape=sample_shape)\n",
    "                else:\n",
    "                    draws = pred_dist.sample(sample_shape=sample_shape)\n",
    "\n",
    "                draws = _to_BSD(draws, B)  # [B, num_draws, D]\n",
    "                y_chunks.append(draws.detach().cpu())\n",
    "\n",
    "                if return_mean_var:\n",
    "                    mean = _to_BD(pred_dist.mean, B)\n",
    "                    var = _to_BD(pred_dist.variance, B)\n",
    "                    mean_chunks.append(mean.detach().cpu())\n",
    "                    var_chunks.append(var.detach().cpu())\n",
    "\n",
    "            except Exception:\n",
    "                # 3.2 fallback: per-theta loop\n",
    "                draws_list = []\n",
    "                mean_list, var_list = [], []\n",
    "\n",
    "                for i in range(B):\n",
    "                    pred_i = Pre_function(Models, Likelihoods, th[i].unsqueeze(0))  # [1,P]\n",
    "\n",
    "                    if use_rsample and hasattr(pred_i, \"rsample\"):\n",
    "                        d_i = pred_i.rsample(sample_shape=sample_shape)\n",
    "                    else:\n",
    "                        d_i = pred_i.sample(sample_shape=sample_shape)\n",
    "\n",
    "                    # expected [num_draws, 1, D] or [num_draws, D]\n",
    "                    if d_i.dim() == 3 and d_i.shape[1] == 1:\n",
    "                        d_i = d_i.squeeze(1)  # [num_draws, D]\n",
    "                    if d_i.dim() == 2:\n",
    "                        pass\n",
    "                    else:\n",
    "                        raise RuntimeError(f\"Unexpected per-theta draws shape {tuple(d_i.shape)}\")\n",
    "\n",
    "                    draws_list.append(d_i)\n",
    "\n",
    "                    if return_mean_var:\n",
    "                        # pred_i.mean likely [1,D]\n",
    "                        mean_list.append(pred_i.mean.squeeze(0))\n",
    "                        var_list.append(pred_i.variance.squeeze(0))\n",
    "\n",
    "                # stack: B * [num_draws, D] -> [B, num_draws, D]\n",
    "                draws = torch.stack(draws_list, dim=0)\n",
    "                y_chunks.append(draws.detach().cpu())\n",
    "\n",
    "                if return_mean_var:\n",
    "                    mean_chunks.append(torch.stack(mean_list, dim=0).detach().cpu())\n",
    "                    var_chunks.append(torch.stack(var_list, dim=0).detach().cpu())\n",
    "\n",
    "    y_pp = torch.cat(y_chunks, dim=0)  # [S_total, num_draws, D]\n",
    "    theta_cpu = theta_all.detach().cpu()\n",
    "\n",
    "    if return_mean_var:\n",
    "        mean_all = torch.cat(mean_chunks, dim=0)  # [S_total, D]\n",
    "        var_all = torch.cat(var_chunks, dim=0)    # [S_total, D]\n",
    "        return theta_cpu, y_pp, mean_all, var_all\n",
    "\n",
    "    return theta_cpu, y_pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples, y_pp = posterior_predictive_resample(\n",
    "    posterior_samples,\n",
    "    Pre_function=Prediction.preds_distribution,\n",
    "    Models=MVGP_models,\n",
    "    Likelihoods=MVGP_likelihoods,\n",
    "    num_draws=10,\n",
    "    device=\"cuda\",\n",
    "    chunk_size=256,\n",
    "    group_by_chain=False,\n",
    "    use_fast_pred_var=True,   # 如果你想在这里统一开 fast_pred_var，就改 True\n",
    ")\n",
    "\n",
    "print(theta_samples.shape)  # [S, P]\n",
    "print(y_pp.shape)           # [S, 20, D]  (比如 D=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb3bb1b",
   "metadata": {},
   "source": [
    "# Plot violin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097663b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 定义你要求的 33 个标签列表\n",
    "CARDIAC_LABELS = [\n",
    "    \"Volume\",\n",
    "    \"cir-Basal-InfSept\", \"cir-Basal-AntSept\", \"cir-Basal-Ant\", \"cir-Basal-AntLat\", \"cir-Basal-InfLat\", \"cir-Basal-Inf\",\n",
    "    \"cir-Mid-InfSept\", \"cir-Mid-AntSept\", \"cir-Mid-Ant\", \"cir-Mid-AntLat\", \"cir-Mid-InfLat\", \"cir-Mid-Inf\",\n",
    "    \"cir-Apical-Septal\", \"cir-Apical-Anterior\", \"cir-Apical-Lateral\", \"cir-Apical-Inferior\",\n",
    "    \"rad-Basal-InfSept\", \"rad-Basal-AntSept\", \"rad-Basal-Ant\", \"rad-Basal-AntLat\", \"rad-Basal-InfLat\", \"rad-Basal-Inf\",\n",
    "    \"rad-Mid-InfSept\", \"rad-Mid-AntSept\", \"rad-Mid-Ant\", \"rad-Mid-AntLat\", \"rad-Mid-InfLat\", \"rad-Mid-Inf\",\n",
    "    \"rad-Apical-Septal\", \"rad-Apical-Anterior\", \"rad-Apical-Lateral\", \"rad-Apical-Inferior\"\n",
    "]\n",
    "\n",
    "def plot_violin_by_dim_with_truth(\n",
    "    y_pp: torch.Tensor,          # [S, R, D]\n",
    "    y_true: torch.Tensor,        # [1, D] or [D]\n",
    "    *,\n",
    "    dim_labels=None,             # List of strings\n",
    "    max_points_per_dim=5000,\n",
    "    show_median=True,\n",
    "    show_extrema=False,\n",
    "    figsize=(20, 6),             # 稍微加宽画布以适应33个维度\n",
    "    label_rotation=90,           # 新增参数：控制标签旋转角度，默认90度\n",
    "    title=\"Posterior Distribution of Volume, Circumferential & Radial Strains\"\n",
    "):\n",
    "    # ---------- shape checks ----------\n",
    "    if y_pp.dim() != 3:\n",
    "        raise ValueError(f\"y_pp must be [S,R,D], got shape {tuple(y_pp.shape)}\")\n",
    "    S, R, D = y_pp.shape\n",
    "\n",
    "    y_true = y_true.detach()\n",
    "    if y_true.dim() == 2 and y_true.shape[0] == 1:\n",
    "        y_true = y_true.squeeze(0)\n",
    "    if y_true.dim() != 1 or y_true.numel() != D:\n",
    "        raise ValueError(f\"y_true must be [D] or [1,D] with D={D}, got shape {tuple(y_true.shape)}\")\n",
    "\n",
    "    # ---------- flatten samples ----------\n",
    "    y_dim = y_pp.permute(2, 0, 1).contiguous().reshape(D, -1)\n",
    "    N = y_dim.shape[1]\n",
    "\n",
    "    if max_points_per_dim is not None and N > max_points_per_dim:\n",
    "        idx = torch.randperm(N, device=y_dim.device)[:max_points_per_dim]\n",
    "        y_dim = y_dim[:, idx]\n",
    "\n",
    "    y_list = [y_dim[d].detach().cpu().numpy() for d in range(D)]\n",
    "    truth = y_true.detach().cpu().numpy()\n",
    "\n",
    "    # ---------- labels check ----------\n",
    "    if dim_labels is None:\n",
    "        dim_labels = [str(i + 1) for i in range(D)]\n",
    "    \n",
    "    # 检查维度是否匹配 (防止传入的 labels 数量和数据维度不一致)\n",
    "    if len(dim_labels) != D:\n",
    "        print(f\"Warning: dim_labels length ({len(dim_labels)}) != D ({D}). Using indices instead.\")\n",
    "        dim_labels = [str(i + 1) for i in range(D)]\n",
    "\n",
    "    positions = np.arange(1, D + 1)\n",
    "\n",
    "    # ---------- plot ----------\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    vp = plt.violinplot(\n",
    "        y_list,\n",
    "        positions=positions,\n",
    "        showmeans=False,\n",
    "        showmedians=show_median,\n",
    "        showextrema=show_extrema\n",
    "    )\n",
    "\n",
    "    # --- 红色/蓝色 区分逻辑 ---\n",
    "    in_range_x, in_range_y = [], []\n",
    "    out_range_x, out_range_y = [], []\n",
    "\n",
    "    for i, samples in enumerate(y_list):\n",
    "        t_val = truth[i]\n",
    "        v_min, v_max = np.min(samples), np.max(samples)\n",
    "        pos = positions[i]\n",
    "        \n",
    "        if t_val < v_min or t_val > v_max:\n",
    "            out_range_x.append(pos)\n",
    "            out_range_y.append(t_val)\n",
    "        else:\n",
    "            in_range_x.append(pos)\n",
    "            in_range_y.append(t_val)\n",
    "\n",
    "    if in_range_x:\n",
    "        plt.scatter(in_range_x, in_range_y, s=25, zorder=3, c='C0', label=\"Observation (in range)\")\n",
    "    if out_range_x:\n",
    "        plt.scatter(out_range_x, out_range_y, s=40, zorder=3, c='red', marker='x', label=\"Observation (out of range)\")\n",
    "\n",
    "    # --- 设置标签并旋转 ---\n",
    "    plt.xticks(positions, dim_labels, rotation=label_rotation) # 关键修改：应用旋转\n",
    "    \n",
    "    plt.xlim(0.5, D + 0.5) # 确保两边留白\n",
    "    plt.xlabel(\"Output dimension\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout() # 自动调整布局防止标签被切掉\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b879b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin_by_dim_with_truth(\n",
    "    y_pp, \n",
    "    realcase_y, \n",
    "    dim_labels=CARDIAC_LABELS, # 传入标签\n",
    "    max_points_per_dim=None,  # 可以根据需要调整这个值，或者设为 None 来使用所有点\n",
    "    figsize=(20, 8)            # 画布高度加大，给旋转的标签留空间\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c3741",
   "metadata": {},
   "source": [
    "# Inverse standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f175aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "\n",
    "scaler = joblib.load(\"RealCase/y_scaler_RealCase.joblib\")\n",
    "\n",
    "def inverse_standardize_torch(y: torch.Tensor, scaler) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    y: torch Tensor, last dim must be D\n",
    "    return: same shape as y, inversed to original scale\n",
    "    \"\"\"\n",
    "    if not (hasattr(scaler, \"mean_\") and hasattr(scaler, \"scale_\")):\n",
    "        raise TypeError(\"Scaler has no mean_/scale_. If this is not StandardScaler, use method B.\")\n",
    "\n",
    "    mean = torch.tensor(scaler.mean_, dtype=y.dtype, device=y.device)   # [D]\n",
    "    scale = torch.tensor(scaler.scale_, dtype=y.dtype, device=y.device) # [D]\n",
    "    return y * scale + mean\n",
    "\n",
    "# ---- usage ----\n",
    "# y_pp: [S,R,D]\n",
    "y_pp_inv = inverse_standardize_torch(y_pp, scaler)\n",
    "\n",
    "# y_true: [1,D] or [D]\n",
    "y_true_t = realcase_y.squeeze(0) if (realcase_y.dim() == 2 and realcase_y.shape[0] == 1) else realcase_y\n",
    "y_true_inv = inverse_standardize_torch(y_true_t, scaler)  # [D]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68143f42",
   "metadata": {},
   "source": [
    "# Histogram for Volum Violin for remaining dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01e45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_hist_rest_violin(\n",
    "    y_pp: torch.Tensor,                 # [S, R, D]\n",
    "    y_true: torch.Tensor,               # [1,D] or [D]\n",
    "    *,\n",
    "    first_dim: int = 0,                 # 第一个维度的 index（默认 0）\n",
    "    dim_labels=None,                    # list[str], len=D；默认 1..D\n",
    "    scaler_path: str | None = None,     # 如 \"RealCase/y_scaler_RealCase.joblib\"；None则不逆标准化\n",
    "    already_inverse_scaled: bool = False,  # 如果你已经提前 inverse 过，就设 True\n",
    "    max_points_per_dim: int = 6000,     # 小提琴每维最多采样点数（避免太慢）\n",
    "    max_hist_points: int = 200000,      # 直方图最多采样点数（避免太慢）\n",
    "    bins: int = 60,\n",
    "    density: bool = True,\n",
    "    figsize=(18, 7),\n",
    "    title_prefix=\"Posterior predictive (original scale)\"\n",
    "):\n",
    "    # ---------- checks ----------\n",
    "    if y_pp.dim() != 3:\n",
    "        raise ValueError(f\"y_pp must be [S,R,D], got {tuple(y_pp.shape)}\")\n",
    "    S, R, D = y_pp.shape\n",
    "\n",
    "    y_true = y_true.detach()\n",
    "    if y_true.dim() == 2 and y_true.shape[0] == 1:\n",
    "        y_true = y_true.squeeze(0)\n",
    "    if y_true.dim() != 1 or y_true.numel() != D:\n",
    "        raise ValueError(f\"y_true must be [D] or [1,D], with D={D}, got {tuple(y_true.shape)}\")\n",
    "\n",
    "    if not (0 <= first_dim < D):\n",
    "        raise ValueError(f\"first_dim must be in [0, {D-1}]\")\n",
    "\n",
    "    # ---------- inverse scaling if needed ----------\n",
    "    if scaler_path is not None and (not already_inverse_scaled):\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        y_pp = inverse_standardize_torch(y_pp, scaler)\n",
    "        y_true = inverse_standardize_torch(y_true, scaler)\n",
    "\n",
    "    # ---------- prepare samples by dimension ----------\n",
    "    # y_pp: [S,R,D] -> y_dim: [D, N] where N=S*R\n",
    "    y_dim = y_pp.permute(2, 0, 1).contiguous().reshape(D, -1)  # [D, N]\n",
    "    N = y_dim.shape[1]\n",
    "\n",
    "    # labels\n",
    "    if dim_labels is None:\n",
    "        dim_labels = [str(i + 1) for i in range(D)]\n",
    "    if len(dim_labels) != D:\n",
    "        raise ValueError(\"dim_labels length must equal D\")\n",
    "\n",
    "    # ---------- subsample for speed ----------\n",
    "    # histogram samples (for first dim)\n",
    "    first_samples = y_dim[first_dim]\n",
    "    if max_hist_points is not None and first_samples.numel() > max_hist_points:\n",
    "        idx = torch.randperm(first_samples.numel(), device=first_samples.device)[:max_hist_points]\n",
    "        first_samples = first_samples[idx]\n",
    "\n",
    "    # violin samples (for remaining dims)\n",
    "    rest_dims = [d for d in range(D) if d != first_dim]\n",
    "    rest_samples = y_dim[rest_dims]  # [D-1, N]\n",
    "    if max_points_per_dim is not None and N > max_points_per_dim:\n",
    "        idx = torch.randperm(N, device=rest_samples.device)[:max_points_per_dim]\n",
    "        rest_samples = rest_samples[:, idx]  # [D-1, max_points_per_dim]\n",
    "\n",
    "    # move to cpu numpy for matplotlib\n",
    "    first_np = first_samples.detach().cpu().numpy()\n",
    "    truth_np = y_true.detach().cpu().numpy()\n",
    "    rest_list = [rest_samples[i].detach().cpu().numpy() for i in range(rest_samples.shape[0])]\n",
    "\n",
    "    # ---------- plotting (two panels: hist + violin) ----------\n",
    "    fig, axes = plt.subplots(2, 1, figsize=figsize, gridspec_kw={\"height_ratios\": [1, 1.4]})\n",
    "\n",
    "    # (A) histogram for first dim\n",
    "    ax0 = axes[0]\n",
    "    ax0.hist(first_np, bins=bins, density=density)\n",
    "    ax0.axvline(truth_np[first_dim], linestyle=\"--\", linewidth=2, label=\"Truth\")\n",
    "    ax0.set_title(f\"{title_prefix} — dim {dim_labels[first_dim]}: histogram\")\n",
    "    ax0.set_xlabel(\"Value\")\n",
    "    ax0.set_ylabel(\"Density\" if density else \"Count\")\n",
    "    ax0.legend()\n",
    "\n",
    "    # (B) violin for remaining dims\n",
    "    ax1 = axes[1]\n",
    "    positions = np.arange(1, len(rest_dims) + 1)\n",
    "    ax1.violinplot(rest_list, positions=positions, showmeans=False, showmedians=True, showextrema=False)\n",
    "\n",
    "    # overlay truth points for rest dims\n",
    "    truth_rest = truth_np[rest_dims]\n",
    "    ax1.scatter(positions, truth_rest, s=22, zorder=3, label=\"Truth\")\n",
    "\n",
    "    ax1.set_title(f\"{title_prefix} — all dims except {dim_labels[first_dim]}: violin\")\n",
    "    ax1.set_xlabel(\"Output dimension\")\n",
    "    ax1.set_ylabel(\"Value\")\n",
    "    ax1.set_xticks(positions)\n",
    "    ax1.set_xticklabels([dim_labels[d] for d in rest_dims], rotation=0)\n",
    "    ax1.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---------------- usage example ----------------\n",
    "# y_pp: [S_total, num_draws, 33]  (standardized or original)\n",
    "# y_true: [1,33] or [33] (same scale as y_pp)\n",
    "\n",
    "# 1) 如果 y_pp / y_true 还是标准化尺度：传 scaler_path 让函数内部 inverse\n",
    "# plot_first_hist_rest_violin(y_pp, y_true, scaler_path=\"RealCase/y_scaler_RealCase.joblib\")\n",
    "\n",
    "# 2) 如果你已经提前 inverse 过：already_inverse_scaled=True 或 scaler_path=None realcase_y\n",
    "# plot_first_hist_rest_violin(y_pp_inv, y_true_inv, already_inverse_scaled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd43d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_first_hist_rest_violin(y_pp_inv, y_true_inv, \n",
    "                            already_inverse_scaled=True, \n",
    "                            max_points_per_dim=None, \n",
    "                            max_hist_points=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPTG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
