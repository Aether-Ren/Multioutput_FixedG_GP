{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ab895d",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f20e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2744d6",
   "metadata": {},
   "source": [
    "# RealCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca663fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load slices\n",
    "s1 = pd.read_csv(\"slice1.csv\")\n",
    "s2 = pd.read_csv(\"slice2.csv\")\n",
    "s3 = pd.read_csv(\"slice3.csv\")\n",
    "s4 = pd.read_csv(\"slice4.csv\")\n",
    "s5 = pd.read_csv(\"slice5.csv\")\n",
    "\n",
    "def per_slice_extrema(df):\n",
    "    cir_cols = [c for c in df.columns if c.startswith(\"cir\")]\n",
    "    rad_cols = [c for c in df.columns if c.startswith(\"rad\")]\n",
    "    def pos_name(col):\n",
    "        name = col[3:]\n",
    "        if name.endswith(\"Total\"):\n",
    "            name = name[:-5]\n",
    "        return name\n",
    "    cir_min = {pos_name(c): df[c].min(skipna=True) for c in cir_cols}\n",
    "    rad_max = {pos_name(c): df[c].max(skipna=True) for c in rad_cols}\n",
    "    return cir_min, rad_max\n",
    "\n",
    "# Per-slice extrema\n",
    "cir1, rad1 = per_slice_extrema(s1)\n",
    "cir2, rad2 = per_slice_extrema(s2)\n",
    "cir3, rad3 = per_slice_extrema(s3)\n",
    "cir4, rad4 = per_slice_extrema(s4)\n",
    "cir5, rad5 = per_slice_extrema(s5)\n",
    "\n",
    "# Average pairs (slice1,slice2) and (slice3,slice4)\n",
    "def avg_maps(m1, m2):\n",
    "    keys = set(m1.keys()) | set(m2.keys())\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        v1 = m1.get(k, float('nan'))\n",
    "        v2 = m2.get(k, float('nan'))\n",
    "        out[k] = pd.Series([v1, v2]).mean(skipna=True)\n",
    "    return out\n",
    "\n",
    "cir12 = avg_maps(cir1, cir2)\n",
    "rad12 = avg_maps(rad1, rad2)\n",
    "cir34 = avg_maps(cir3, cir4)\n",
    "rad34 = avg_maps(rad3, rad4)\n",
    "\n",
    "# Canonical 6-sector order\n",
    "aha6_order = [\"Ant\", \"AntSept\", \"InfSept\", \"Inf\", \"InfLat\", \"AntLat\"]\n",
    "\n",
    "rows = []\n",
    "# Segments 1–6\n",
    "for i, pos in enumerate(aha6_order, start=1):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label\": f\"Basal-{pos}\",\n",
    "        \"cir_min\": cir12.get(pos, float('nan')),\n",
    "        \"rad_max\": rad12.get(pos, float('nan'))\n",
    "    })\n",
    "# Segments 7–12\n",
    "for i, pos in enumerate(aha6_order, start=7):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label\": f\"Mid-{pos}\",\n",
    "        \"cir_min\": cir34.get(pos, float('nan')),\n",
    "        \"rad_max\": rad34.get(pos, float('nan'))\n",
    "    })\n",
    "\n",
    "# Apical ring (13–16): use slice5 only, with positional averaging per previous rule\n",
    "def mean2(a, b):\n",
    "    return pd.Series([a, b]).mean(skipna=True)\n",
    "\n",
    "apical_map = [\n",
    "    (13, \"Apical-Anterior\",  (\"Ant\",)),                    # Ant\n",
    "    (14, \"Apical-Septal\",    (\"AntSept\", \"InfSept\")),      # mean of septal pair\n",
    "    (15, \"Apical-Inferior\",  (\"Inf\",)),                    # Inf\n",
    "    (16, \"Apical-Lateral\",   (\"AntLat\", \"InfLat\")),        # mean of lateral pair\n",
    "]\n",
    "\n",
    "for seg, label, positions in apical_map:\n",
    "    if len(positions) == 1:\n",
    "        pos = positions[0]\n",
    "        cir_v = cir5.get(pos, float('nan'))\n",
    "        rad_v = rad5.get(pos, float('nan'))\n",
    "    else:\n",
    "        cir_v = mean2(cir5.get(positions[0], float('nan')), cir5.get(positions[1], float('nan')))\n",
    "        rad_v = mean2(rad5.get(positions[0], float('nan')), rad5.get(positions[1], float('nan')))\n",
    "    rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"label\": label,\n",
    "        \"cir_min\": cir_v,\n",
    "        \"rad_max\": rad_v\n",
    "    })\n",
    "\n",
    "# Segment 17 remains missing\n",
    "rows.append({\n",
    "    \"segment\": 17,\n",
    "    \"label\": \"Apex (missing)\",\n",
    "    \"cir_min\": float('nan'),\n",
    "    \"rad_max\": float('nan')\n",
    "})\n",
    "\n",
    "result = pd.DataFrame(rows).sort_values(\"segment\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1feb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_row_maps(df):\n",
    "    row = df.iloc[-2]  # second-to-last\n",
    "    cir_cols = [c for c in df.columns if c.startswith(\"cir\")]\n",
    "    rad_cols = [c for c in df.columns if c.startswith(\"rad\")]\n",
    "    def pos_name(col):\n",
    "        name = col[3:]\n",
    "        if name.endswith(\"Total\"):\n",
    "            name = name[:-5]\n",
    "        return name\n",
    "    cir_map = {pos_name(c): row[c] for c in cir_cols}\n",
    "    rad_map = {pos_name(c): row[c] for c in rad_cols}\n",
    "    return cir_map, rad_map\n",
    "\n",
    "cir1, rad1 = extract_row_maps(s1)\n",
    "cir2, rad2 = extract_row_maps(s2)\n",
    "cir3, rad3 = extract_row_maps(s3)\n",
    "cir4, rad4 = extract_row_maps(s4)\n",
    "cir5, rad5 = extract_row_maps(s5)\n",
    "\n",
    "# Average pairs (slice1,slice2) and (slice3,slice4)\n",
    "def avg_maps(m1, m2):\n",
    "    keys = set(m1.keys()) | set(m2.keys())\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        out[k] = pd.Series([m1.get(k, float('nan')), m2.get(k, float('nan'))]).mean(skipna=True)\n",
    "    return out\n",
    "\n",
    "cir12 = avg_maps(cir1, cir2)\n",
    "rad12 = avg_maps(rad1, rad2)\n",
    "cir34 = avg_maps(cir3, cir4)\n",
    "rad34 = avg_maps(rad3, rad4)\n",
    "\n",
    "aha6_order = [\"Ant\", \"AntSept\", \"InfSept\", \"Inf\", \"InfLat\", \"AntLat\"]\n",
    "\n",
    "rows = []\n",
    "# 1–6: average of slice1&2 at the second-to-last row\n",
    "for i, pos in enumerate(aha6_order, start=1):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label\": f\"Basal-{pos}\",\n",
    "        \"cir_value\": cir12.get(pos, float('nan')),\n",
    "        \"rad_value\": rad12.get(pos, float('nan')),\n",
    "        \"rule\": \"2nd-last row avg(s1,s2)\"\n",
    "    })\n",
    "\n",
    "# 7–12: average of slice3&4 at the second-to-last row\n",
    "for i, pos in enumerate(aha6_order, start=7):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label\": f\"Mid-{pos}\",\n",
    "        \"cir_value\": cir34.get(pos, float('nan')),\n",
    "        \"rad_value\": rad34.get(pos, float('nan')),\n",
    "        \"rule\": \"2nd-last row avg(s3,s4)\"\n",
    "    })\n",
    "\n",
    "# 13–16: from slice5's second-to-last row, with positional averaging\n",
    "def mean2(a, b):\n",
    "    return pd.Series([a, b]).mean(skipna=True)\n",
    "\n",
    "apical_map = [\n",
    "    (13, \"Apical-Anterior\",  (\"Ant\",)),\n",
    "    (14, \"Apical-Septal\",    (\"AntSept\", \"InfSept\")),\n",
    "    (15, \"Apical-Inferior\",  (\"Inf\",)),\n",
    "    (16, \"Apical-Lateral\",   (\"AntLat\", \"InfLat\")),\n",
    "]\n",
    "\n",
    "for seg, label, positions in apical_map:\n",
    "    if len(positions) == 1:\n",
    "        pos = positions[0]\n",
    "        cir_v = cir5.get(pos, float('nan'))\n",
    "        rad_v = rad5.get(pos, float('nan'))\n",
    "    else:\n",
    "        cir_v = mean2(cir5.get(positions[0], float('nan')), cir5.get(positions[1], float('nan')))\n",
    "        rad_v = mean2(rad5.get(positions[0], float('nan')), rad5.get(positions[1], float('nan')))\n",
    "    rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"label\": label,\n",
    "        \"cir_value\": cir_v,\n",
    "        \"rad_value\": rad_v,\n",
    "        \"rule\": \"2nd-last row slice5\"\n",
    "    })\n",
    "\n",
    "# 17: missing\n",
    "rows.append({\n",
    "    \"segment\": 17,\n",
    "    \"label\": \"Apex (missing)\",\n",
    "    \"cir_value\": float('nan'),\n",
    "    \"rad_value\": float('nan'),\n",
    "    \"rule\": \"N/A\"\n",
    "})\n",
    "\n",
    "result = pd.DataFrame(rows).sort_values(\"segment\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcdd546",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e5947a-818e-47f0-a79b-dc04f3ac3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('RealCase_X_train.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('RealCase_Y_train_std.csv', header=None, delimiter=',').values\n",
    "\n",
    "X_test = pd.read_csv('RealCase_X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_test_std = pd.read_csv('RealCase_Y_test_std.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9aa961",
   "metadata": {},
   "outputs": [],
   "source": [
    "RealCase = pd.read_csv('RealCase_Y.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506a0921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True, False,  True,  True,\n",
       "        False,  True,  True,  True, False,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_min = np.nanmin(Y_train_std, axis=0)\n",
    "col_max = np.nanmax(Y_train_std, axis=0)\n",
    "\n",
    "\n",
    "(RealCase >= col_min) & (RealCase <= col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "pca.fit(Y_train_std)\n",
    "\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb933d04-1eda-4de5-9e5f-ffe2cb26375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(cumulative_variance >= 0.999) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "157ca255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_apply_pca(train_data, test_data, RealCase, variance_threshold=0.999):\n",
    "\n",
    "    # 拆分第一列\n",
    "    train_first_col = train_data[:, 0].reshape(-1, 1)\n",
    "    test_first_col = test_data[:, 0].reshape(-1, 1)\n",
    "    RealCase_first_col = RealCase[:, 0].reshape(-1, 1)\n",
    "    \n",
    "    train_remaining = train_data[:, 1:]\n",
    "    test_remaining = test_data[:, 1:]\n",
    "    RealCase_remaining = RealCase[:, 1:]\n",
    "    \n",
    "    # 初始化 PCA 并拟合剩余的列\n",
    "    pca = PCA()\n",
    "    pca.fit(train_remaining)\n",
    "    \n",
    "    # 计算累计方差\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # 确定主成分个数\n",
    "    n_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "    \n",
    "    # 根据主成分数重新拟合 PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    train_reduced = pca.fit_transform(train_remaining)\n",
    "    test_reduced = pca.transform(test_remaining)\n",
    "    RealCase_reduced = pca.transform(RealCase_remaining)\n",
    "\n",
    "    \n",
    "    # 合并第一列与降维后的数据\n",
    "    train_final = np.hstack((train_first_col, train_reduced))\n",
    "    test_final = np.hstack((test_first_col, test_reduced))\n",
    "    RealCase_final = np.hstack((RealCase_first_col, RealCase_reduced))\n",
    "    \n",
    "    return train_final, test_final, RealCase_final, n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca37626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pca, Y_test_pca, RealCase_pca, n_components = split_and_apply_pca(Y_train_std, Y_test_std, RealCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f5bd347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False,  True,  True, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False,  True,  True, False, False, False, False,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False, False,  True, False, False, False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_min = np.nanmin(Y_train_pca, axis=0)\n",
    "col_max = np.nanmax(Y_train_pca, axis=0)\n",
    "\n",
    "\n",
    "(RealCase_pca >= col_min) & (RealCase_pca <= col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"RealCase_Y_train_pca.csv\", Y_train_pca, delimiter=\",\", fmt=\"%.8f\")\n",
    "\n",
    "# np.savetxt(\"RealCase_Y_test_pca.csv\", Y_test_pca, delimiter=\",\", fmt=\"%.8f\")\n",
    "\n",
    "np.savetxt(\"RealCase_Y_pca.csv\", RealCase_pca, delimiter=\",\", fmt=\"%.8f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FGPyT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
