{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ab895d",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f20e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2744d6",
   "metadata": {},
   "source": [
    "# RealCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba28972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved single-row (full labels) to: AHA17_one_row_full_labels_cir_then_rad_custom_order.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SLICE_FILES = {\n",
    "    \"slice1\": Path(\"slice1.csv\"),\n",
    "    \"slice2\": Path(\"slice2.csv\"),\n",
    "    \"slice3\": Path(\"slice3.csv\"),\n",
    "    \"slice4\": Path(\"slice4.csv\"),\n",
    "    \"slice5\": Path(\"slice5.csv\"),\n",
    "}\n",
    "\n",
    "# 输出文件\n",
    "OUT_TABLE = Path(\"AHA17_peak_strains_subset_2_to_-2_table.csv\")  # 逐段表（1行/段）\n",
    "OUT_ONE_ROW_FULL = Path(\"AHA17_one_row_full_labels_cir_then_rad_custom_order.csv\")  # 单行（全称标签）\n",
    "OUT_ONE_ROW_ABBR = Path(\"AHA17_one_row_abbr_labels_cir_then_rad_custom_order.csv\")  # 单行（缩写标签）\n",
    "\n",
    "# 列名使用全称(True)或缩写(False)\n",
    "USE_FULL_LABELS = True\n",
    "\n",
    "# 你给定的 16 段顺序（仅 1–16 段）\n",
    "CUSTOM_ORDER_ABBR = [\n",
    "    \"Basal-InfSept\", \"Basal-AntSept\", \"Basal-Ant\", \"Basal-AntLat\", \"Basal-InfLat\", \"Basal-Inf\",\n",
    "    \"Mid-InfSept\", \"Mid-AntSept\", \"Mid-Ant\", \"Mid-AntLat\", \"Mid-InfLat\", \"Mid-Inf\",\n",
    "    \"Apical-Septal\", \"Apical-Anterior\", \"Apical-Lateral\", \"Apical-Inferior\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 辅助函数\n",
    "# =========================\n",
    "def subset_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"仅保留第2行到倒数第2行；若行不足3，则返回空\"\"\"\n",
    "    if len(df) < 3:\n",
    "        return df.iloc[0:0].copy()\n",
    "    return df.iloc[1:-1].reset_index(drop=True)\n",
    "\n",
    "def pos_name(col: str) -> str:\n",
    "    \"\"\"将列名 'cirAntSeptTotal' / 'radInfLatTotal' 规范为位置名 'AntSept' / 'InfLat'\"\"\"\n",
    "    name = col[3:]  # 去掉前缀 'cir' 或 'rad'\n",
    "    if name.endswith(\"Total\"):\n",
    "        name = name[:-5]\n",
    "    return name\n",
    "\n",
    "def per_slice_extrema_on_subset(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    基于子集（去掉首尾行）计算单个 slice 极值：\n",
    "    - cir_* 列取最小值\n",
    "    - rad_* 列取最大值\n",
    "    返回两个 dict：cir_min_map, rad_max_map（键：位置名，如 'Ant','InfSept' 等）\n",
    "    \"\"\"\n",
    "    sub = subset_df(df)\n",
    "    cir_cols = [c for c in sub.columns if c.startswith(\"cir\")]\n",
    "    rad_cols = [c for c in sub.columns if c.startswith(\"rad\")]\n",
    "    cir_min = {pos_name(c): (sub[c].min(skipna=True) if not sub.empty else float('nan'))\n",
    "               for c in cir_cols}\n",
    "    rad_max = {pos_name(c): (sub[c].max(skipna=True) if not sub.empty else float('nan'))\n",
    "               for c in rad_cols}\n",
    "    return cir_min, rad_max\n",
    "\n",
    "def avg_maps(m1: dict, m2: dict) -> dict:\n",
    "    \"\"\"按键对两个映射做均值（忽略 NaN）\"\"\"\n",
    "    keys = set(m1.keys()) | set(m2.keys())\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        out[k] = pd.Series([m1.get(k, float('nan')), m2.get(k, float('nan'))]).mean(skipna=True)\n",
    "    return out\n",
    "\n",
    "def mean2(a, b):\n",
    "    return pd.Series([a, b]).mean(skipna=True)\n",
    "\n",
    "# 缩写→全称映射（环段位置）\n",
    "ABBR_TO_FULL = {\n",
    "    \"Ant\": \"Anterior\",\n",
    "    \"AntSept\": \"Anteroseptal\",\n",
    "    \"InfSept\": \"Inferoseptal\",\n",
    "    \"Inf\": \"Inferior\",\n",
    "    \"InfLat\": \"Inferolateral\",\n",
    "    \"AntLat\": \"Anterolateral\",\n",
    "    # 顶端象限（已是全称）\n",
    "    \"Septal\": \"Septal\",\n",
    "    \"Anterior\": \"Anterior\",\n",
    "    \"Lateral\": \"Lateral\",\n",
    "    \"Inferior\": \"Inferior\",\n",
    "}\n",
    "\n",
    "def to_full_label(label_abbr: str) -> str:\n",
    "    \"\"\"\n",
    "    将 'Basal-InfSept' → 'Basal-Inferoseptal'\n",
    "       'Apical-Septal' 保持不变\n",
    "       'Apex (missing)' → 'Apex'\n",
    "    \"\"\"\n",
    "    s = str(label_abbr).strip()\n",
    "    if s.startswith(\"Apex\"):\n",
    "        return \"Apex\"\n",
    "    if \"-\" in s:\n",
    "        ring, pos = s.split(\"-\", 1)\n",
    "        full_pos = ABBR_TO_FULL.get(pos, pos)\n",
    "        return f\"{ring}-{full_pos}\"\n",
    "    return s\n",
    "\n",
    "# =========================\n",
    "# 计算流程\n",
    "# =========================\n",
    "# 1) 读取数据 + 各 slice 子集极值\n",
    "s1 = pd.read_csv(SLICE_FILES[\"slice1\"])\n",
    "s2 = pd.read_csv(SLICE_FILES[\"slice2\"])\n",
    "s3 = pd.read_csv(SLICE_FILES[\"slice3\"])\n",
    "s4 = pd.read_csv(SLICE_FILES[\"slice4\"])\n",
    "s5 = pd.read_csv(SLICE_FILES[\"slice5\"])\n",
    "\n",
    "cir1, rad1 = per_slice_extrema_on_subset(s1)\n",
    "cir2, rad2 = per_slice_extrema_on_subset(s2)\n",
    "cir3, rad3 = per_slice_extrema_on_subset(s3)\n",
    "cir4, rad4 = per_slice_extrema_on_subset(s4)\n",
    "cir5_map, rad5_map = per_slice_extrema_on_subset(s5)\n",
    "\n",
    "# 2) (slice1,slice2) 与 (slice3,slice4) 对应位置平均\n",
    "cir12 = avg_maps(cir1, cir2)\n",
    "rad12 = avg_maps(rad1, rad2)\n",
    "cir34 = avg_maps(cir3, cir4)\n",
    "rad34 = avg_maps(rad3, rad4)\n",
    "\n",
    "# AHA 6 扇区顺序（环内位置的标准顺序）\n",
    "AHA6 = [\"Ant\", \"AntSept\", \"InfSept\", \"Inf\", \"InfLat\", \"AntLat\"]\n",
    "\n",
    "# 3) 组装 1–12 段（Basal、Mid）\n",
    "rows = []\n",
    "for i, pos in enumerate(AHA6, start=1):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label_abbr\": f\"Basal-{pos}\",\n",
    "        \"cir_min\": cir12.get(pos, float('nan')),\n",
    "        \"rad_max\": rad12.get(pos, float('nan'))\n",
    "    })\n",
    "for i, pos in enumerate(AHA6, start=7):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label_abbr\": f\"Mid-{pos}\",\n",
    "        \"cir_min\": cir34.get(pos, float('nan')),\n",
    "        \"rad_max\": rad34.get(pos, float('nan'))\n",
    "    })\n",
    "\n",
    "# 4) 组装 13–16 段（Apical，来自 slice5；按规则合并位置）\n",
    "APICAL_RULES = [\n",
    "    (13, \"Apical-Anterior\",  (\"Ant\",)),                      # 13=Ant\n",
    "    (14, \"Apical-Septal\",    (\"AntSept\", \"InfSept\")),        # 14=mean(AntSept, InfSept)\n",
    "    (15, \"Apical-Inferior\",  (\"Inf\",)),                      # 15=Inf\n",
    "    (16, \"Apical-Lateral\",   (\"AntLat\", \"InfLat\")),          # 16=mean(AntLat, InfLat)\n",
    "]\n",
    "for seg, label_full, pos_tuple in APICAL_RULES:\n",
    "    if len(pos_tuple) == 1:\n",
    "        p = pos_tuple[0]\n",
    "        cir_v = cir5_map.get(p, float('nan'))\n",
    "        rad_v = rad5_map.get(p, float('nan'))\n",
    "    else:\n",
    "        cir_v = mean2(cir5_map.get(pos_tuple[0], float('nan')),\n",
    "                      cir5_map.get(pos_tuple[1], float('nan')))\n",
    "        rad_v = mean2(rad5_map.get(pos_tuple[0], float('nan')),\n",
    "                      rad5_map.get(pos_tuple[1], float('nan')))\n",
    "    # 这里 label_abbr 使用 'Apical-Anterior' 等（已是全称位置词）\n",
    "    rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"label_abbr\": label_full,  # 作为缩写标签使用（Apical-* 已是全称）\n",
    "        \"cir_min\": cir_v,\n",
    "        \"rad_max\": rad_v\n",
    "    })\n",
    "\n",
    "# 5) 17 段占位\n",
    "rows.append({\n",
    "    \"segment\": 17,\n",
    "    \"label_abbr\": \"Apex (missing)\",\n",
    "    \"cir_min\": float('nan'),\n",
    "    \"rad_max\": float('nan')\n",
    "})\n",
    "\n",
    "table = pd.DataFrame(rows).sort_values(\"segment\").reset_index(drop=True)\n",
    "\n",
    "# 冗余一列：全称标签\n",
    "table[\"label_full\"] = table[\"label_abbr\"].map(to_full_label)\n",
    "\n",
    "# 保存逐段表（便于检查）\n",
    "table[[\"segment\", \"label_abbr\", \"label_full\", \"cir_min\", \"rad_max\"]].to_csv(OUT_TABLE, index=False)\n",
    "\n",
    "# 6) 依据你给定的 16 段顺序（仅 1–16 段）构建单行输出\n",
    "#    - 先 CIR 块（按顺序 16 列），再 RAD 块（按相同顺序 16 列）\n",
    "#    - 列名可选：全称或缩写\n",
    "order_abbr_16 = CUSTOM_ORDER_ABBR[:]  # 拷贝\n",
    "# 构造查找表：abbr → 值（从 table 中取）\n",
    "# 注意：table 中 apical 已采用全称词（Apical-Anterior 等），与 CUSTOM_ORDER_ABBR 的 Apical-* 保持一致\n",
    "lookup_abbr_to_vals = {\n",
    "    lab: table.loc[table[\"label_abbr\"] == lab, [\"cir_min\", \"rad_max\"]].iloc[0].to_dict()\n",
    "    for lab in table[\"label_abbr\"].tolist()\n",
    "    if lab != \"Apex (missing)\"\n",
    "}\n",
    "\n",
    "# 生成列名序列（根据 USE_FULL_LABELS 选择全称/缩写）\n",
    "def col_name_base(label_abbr: str) -> str:\n",
    "    return to_full_label(label_abbr) if USE_FULL_LABELS else label_abbr\n",
    "\n",
    "cir_cols = [f\"{col_name_base(lab)}_cir\" for lab in order_abbr_16]\n",
    "rad_cols = [f\"{col_name_base(lab)}_rad\" for lab in order_abbr_16]\n",
    "\n",
    "# 生成对应取值（严格按顺序）\n",
    "cir_vals = [lookup_abbr_to_vals.get(lab, {\"cir_min\": float('nan')})[\"cir_min\"]\n",
    "            for lab in order_abbr_16]\n",
    "rad_vals = [lookup_abbr_to_vals.get(lab, {\"rad_max\": float('nan')})[\"rad_max\"]\n",
    "            for lab in order_abbr_16]\n",
    "\n",
    "one_row = pd.DataFrame([cir_vals + rad_vals], columns=cir_cols + rad_cols)\n",
    "\n",
    "# 输出文件（按标签样式选择）\n",
    "if USE_FULL_LABELS:\n",
    "    one_row.to_csv(OUT_ONE_ROW_FULL, index=False)\n",
    "    print(f\"Saved single-row (full labels) to: {OUT_ONE_ROW_FULL}\")\n",
    "else:\n",
    "    one_row.to_csv(OUT_ONE_ROW_ABBR, index=False)\n",
    "    print(f\"Saved single-row (abbr labels) to: {OUT_ONE_ROW_ABBR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 配置\n",
    "# =========================\n",
    "SLICE_FILES = {\n",
    "    \"slice1\": Path(\"/mnt/data/slice1.csv\"),\n",
    "    \"slice2\": Path(\"/mnt/data/slice2.csv\"),\n",
    "    \"slice3\": Path(\"/mnt/data/slice3.csv\"),\n",
    "    \"slice4\": Path(\"/mnt/data/slice4.csv\"),\n",
    "    \"slice5\": Path(\"/mnt/data/slice5.csv\"),\n",
    "}\n",
    "\n",
    "# 输出文件\n",
    "OUT_TABLE = Path(\"/mnt/data/AHA17_peak_strains_subset_2_to_-2_table.csv\")  # 逐段表（1行/段）\n",
    "OUT_ONE_ROW_FULL = Path(\"/mnt/data/AHA17_one_row_full_labels_cir_then_rad_custom_order.csv\")  # 单行（全称标签）\n",
    "OUT_ONE_ROW_ABBR = Path(\"/mnt/data/AHA17_one_row_abbr_labels_cir_then_rad_custom_order.csv\")  # 单行（缩写标签）\n",
    "\n",
    "# 列名使用全称(True)或缩写(False)\n",
    "USE_FULL_LABELS = True\n",
    "\n",
    "# 你给定的 16 段顺序（仅 1–16 段）\n",
    "CUSTOM_ORDER_ABBR = [\n",
    "    \"Basal-InfSept\", \"Basal-AntSept\", \"Basal-Ant\", \"Basal-AntLat\", \"Basal-InfLat\", \"Basal-Inf\",\n",
    "    \"Mid-InfSept\", \"Mid-AntSept\", \"Mid-Ant\", \"Mid-AntLat\", \"Mid-InfLat\", \"Mid-Inf\",\n",
    "    \"Apical-Septal\", \"Apical-Anterior\", \"Apical-Lateral\", \"Apical-Inferior\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 辅助函数\n",
    "# =========================\n",
    "def subset_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"仅保留第2行到倒数第2行；若行不足3，则返回空\"\"\"\n",
    "    if len(df) < 3:\n",
    "        return df.iloc[0:0].copy()\n",
    "    return df.iloc[1:-1].reset_index(drop=True)\n",
    "\n",
    "def pos_name(col: str) -> str:\n",
    "    \"\"\"将列名 'cirAntSeptTotal' / 'radInfLatTotal' 规范为位置名 'AntSept' / 'InfLat'\"\"\"\n",
    "    name = col[3:]  # 去掉前缀 'cir' 或 'rad'\n",
    "    if name.endswith(\"Total\"):\n",
    "        name = name[:-5]\n",
    "    return name\n",
    "\n",
    "def per_slice_means_on_subset(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    基于子集（去掉首尾行）直接按相同行（同一行集合）对每一列取 **均值**：\n",
    "    - cir_* 列：均值\n",
    "    - rad_* 列：均值\n",
    "    返回两个 dict：cir_mean_map, rad_mean_map（键：位置名，如 'Ant','InfSept' 等）\n",
    "    \"\"\"\n",
    "    sub = subset_df(df)\n",
    "    cir_cols = [c for c in sub.columns if c.startswith(\"cir\")]\n",
    "    rad_cols = [c for c in sub.columns if c.startswith(\"rad\")]\n",
    "\n",
    "    if sub.empty:\n",
    "        cir_mean = {pos_name(c): float('nan') for c in cir_cols}\n",
    "        rad_mean = {pos_name(c): float('nan') for c in rad_cols}\n",
    "    else:\n",
    "        cir_mean = {pos_name(c): sub[c].mean(skipna=True) for c in cir_cols}\n",
    "        rad_mean = {pos_name(c): sub[c].mean(skipna=True) for c in rad_cols}\n",
    "\n",
    "    return cir_mean, rad_mean\n",
    "\n",
    "def avg_maps(m1: dict, m2: dict) -> dict:\n",
    "    \"\"\"按键对两个映射做均值（忽略 NaN）\"\"\"\n",
    "    keys = set(m1.keys()) | set(m2.keys())\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        out[k] = pd.Series([m1.get(k, float('nan')), m2.get(k, float('nan'))]).mean(skipna=True)\n",
    "    return out\n",
    "\n",
    "def mean2(a, b):\n",
    "    return pd.Series([a, b]).mean(skipna=True)\n",
    "\n",
    "# 缩写→全称映射（环段位置）\n",
    "ABBR_TO_FULL = {\n",
    "    \"Ant\": \"Anterior\",\n",
    "    \"AntSept\": \"Anteroseptal\",\n",
    "    \"InfSept\": \"Inferoseptal\",\n",
    "    \"Inf\": \"Inferior\",\n",
    "    \"InfLat\": \"Inferolateral\",\n",
    "    \"AntLat\": \"Anterolateral\",\n",
    "    # 顶端象限（已是全称）\n",
    "    \"Septal\": \"Septal\",\n",
    "    \"Anterior\": \"Anterior\",\n",
    "    \"Lateral\": \"Lateral\",\n",
    "    \"Inferior\": \"Inferior\",\n",
    "}\n",
    "\n",
    "def to_full_label(label_abbr: str) -> str:\n",
    "    \"\"\"\n",
    "    将 'Basal-InfSept' → 'Basal-Inferoseptal'\n",
    "       'Apical-Septal' 保持不变\n",
    "       'Apex (missing)' → 'Apex'\n",
    "    \"\"\"\n",
    "    s = str(label_abbr).strip()\n",
    "    if s.startswith(\"Apex\"):\n",
    "        return \"Apex\"\n",
    "    if \"-\" in s:\n",
    "        ring, pos = s.split(\"-\", 1)\n",
    "        full_pos = ABBR_TO_FULL.get(pos, pos)\n",
    "        return f\"{ring}-{full_pos}\"\n",
    "    return s\n",
    "\n",
    "# =========================\n",
    "# 计算流程\n",
    "# =========================\n",
    "# 1) 读取数据 + 各 slice 子集均值（不取极值）\n",
    "s1 = pd.read_csv(SLICE_FILES[\"slice1\"])\n",
    "s2 = pd.read_csv(SLICE_FILES[\"slice2\"])\n",
    "s3 = pd.read_csv(SLICE_FILES[\"slice3\"])\n",
    "s4 = pd.read_csv(SLICE_FILES[\"slice4\"])\n",
    "s5 = pd.read_csv(SLICE_FILES[\"slice5\"])\n",
    "\n",
    "cir1, rad1 = per_slice_means_on_subset(s1)\n",
    "cir2, rad2 = per_slice_means_on_subset(s2)\n",
    "cir3, rad3 = per_slice_means_on_subset(s3)\n",
    "cir4, rad4 = per_slice_means_on_subset(s4)\n",
    "cir5_map, rad5_map = per_slice_means_on_subset(s5)\n",
    "\n",
    "# 2) (slice1,slice2) 与 (slice3,slice4) 对应位置平均\n",
    "cir12 = avg_maps(cir1, cir2)\n",
    "rad12 = avg_maps(rad1, rad2)\n",
    "cir34 = avg_maps(cir3, cir4)\n",
    "rad34 = avg_maps(rad3, rad4)\n",
    "\n",
    "# AHA 6 扇区顺序（环内位置的标准顺序）\n",
    "AHA6 = [\"Ant\", \"AntSept\", \"InfSept\", \"Inf\", \"InfLat\", \"AntLat\"]\n",
    "\n",
    "# 3) 组装 1–12 段（Basal、Mid）\n",
    "rows = []\n",
    "for i, pos in enumerate(AHA6, start=1):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label_abbr\": f\"Basal-{pos}\",\n",
    "        \"cir_mean\": cir12.get(pos, float('nan')),\n",
    "        \"rad_mean\": rad12.get(pos, float('nan'))\n",
    "    })\n",
    "for i, pos in enumerate(AHA6, start=7):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label_abbr\": f\"Mid-{pos}\",\n",
    "        \"cir_mean\": cir34.get(pos, float('nan')),\n",
    "        \"rad_mean\": rad34.get(pos, float('nan'))\n",
    "    })\n",
    "\n",
    "# 4) 组装 13–16 段（Apical，来自 slice5；按规则合并位置）\n",
    "APICAL_RULES = [\n",
    "    (13, \"Apical-Anterior\",  (\"Ant\",)),                      # 13=Ant\n",
    "    (14, \"Apical-Septal\",    (\"AntSept\", \"InfSept\")),        # 14=mean(AntSept, InfSept)\n",
    "    (15, \"Apical-Inferior\",  (\"Inf\",)),                      # 15=Inf\n",
    "    (16, \"Apical-Lateral\",   (\"AntLat\", \"InfLat\")),          # 16=mean(AntLat, InfLat)\n",
    "]\n",
    "for seg, label_full, pos_tuple in APICAL_RULES:\n",
    "    if len(pos_tuple) == 1:\n",
    "        p = pos_tuple[0]\n",
    "        cir_v = cir5_map.get(p, float('nan'))\n",
    "        rad_v = rad5_map.get(p, float('nan'))\n",
    "    else:\n",
    "        cir_v = mean2(cir5_map.get(pos_tuple[0], float('nan')),\n",
    "                      cir5_map.get(pos_tuple[1], float('nan')))\n",
    "        rad_v = mean2(rad5_map.get(pos_tuple[0], float('nan')),\n",
    "                      rad5_map.get(pos_tuple[1], float('nan')))\n",
    "    rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"label_abbr\": label_full,  # 作为缩写标签使用（Apical-* 已是全称）\n",
    "        \"cir_mean\": cir_v,\n",
    "        \"rad_mean\": rad_v\n",
    "    })\n",
    "\n",
    "# 5) 17 段占位\n",
    "rows.append({\n",
    "    \"segment\": 17,\n",
    "    \"label_abbr\": \"Apex (missing)\",\n",
    "    \"cir_mean\": float('nan'),\n",
    "    \"rad_mean\": float('nan')\n",
    "})\n",
    "\n",
    "table = pd.DataFrame(rows).sort_values(\"segment\").reset_index(drop=True)\n",
    "\n",
    "# 冗余一列：全称标签\n",
    "table[\"label_full\"] = table[\"label_abbr\"].map(to_full_label)\n",
    "\n",
    "# 保存逐段表（便于检查）\n",
    "table[[\"segment\", \"label_abbr\", \"label_full\", \"cir_mean\", \"rad_mean\"]].to_csv(OUT_TABLE, index=False)\n",
    "\n",
    "# 6) 依据你给定的 16 段顺序（仅 1–16 段）构建单行输出\n",
    "#    - 先 CIR 块（按顺序 16 列），再 RAD 块（按相同顺序 16 列）\n",
    "#    - 列名可选：全称或缩写\n",
    "order_abbr_16 = CUSTOM_ORDER_ABBR[:]  # 拷贝\n",
    "\n",
    "# 构造查找表：abbr → 值（从 table 中取）\n",
    "lookup_abbr_to_vals = {\n",
    "    lab: table.loc[table[\"label_abbr\"] == lab, [\"cir_mean\", \"rad_mean\"]].iloc[0].to_dict()\n",
    "    for lab in table[\"label_abbr\"].tolist()\n",
    "    if lab != \"Apex (missing)\"\n",
    "}\n",
    "\n",
    "# 生成列名序列（根据 USE_FULL_LABELS 选择全称/缩写）\n",
    "def col_name_base(label_abbr: str) -> str:\n",
    "    return to_full_label(label_abbr) if USE_FULL_LABELS else label_abbr\n",
    "\n",
    "cir_cols = [f\"{col_name_base(lab)}_cir\" for lab in order_abbr_16]\n",
    "rad_cols = [f\"{col_name_base(lab)}_rad\" for lab in order_abbr_16]\n",
    "\n",
    "# 生成对应取值（严格按顺序）\n",
    "cir_vals = [lookup_abbr_to_vals.get(lab, {\"cir_mean\": float('nan')})[\"cir_mean\"]\n",
    "            for lab in order_abbr_16]\n",
    "rad_vals = [lookup_abbr_to_vals.get(lab, {\"rad_mean\": float('nan')})[\"rad_mean\"]\n",
    "            for lab in order_abbr_16]\n",
    "\n",
    "one_row = pd.DataFrame([cir_vals + rad_vals], columns=cir_cols + rad_cols)\n",
    "\n",
    "# 输出文件（按标签样式选择）\n",
    "if USE_FULL_LABELS:\n",
    "    one_row.to_csv(OUT_ONE_ROW_FULL, index=False)\n",
    "    print(f\"Saved single-row (full labels) to: {OUT_ONE_ROW_FULL}\")\n",
    "else:\n",
    "    one_row.to_csv(OUT_ONE_ROW_ABBR, index=False)\n",
    "    print(f\"Saved single-row (abbr labels) to: {OUT_ONE_ROW_ABBR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bf314",
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcdd546",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e5947a-818e-47f0-a79b-dc04f3ac3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('RealCase_X_train.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('RealCase_Y_train_std.csv', header=None, delimiter=',').values\n",
    "\n",
    "X_test = pd.read_csv('RealCase_X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_test_std = pd.read_csv('RealCase_Y_test_std.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9aa961",
   "metadata": {},
   "outputs": [],
   "source": [
    "RealCase = pd.read_csv('RealCase_Y.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506a0921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True, False,  True,  True,\n",
       "        False,  True,  True,  True, False,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_min = np.nanmin(Y_train_std, axis=0)\n",
    "col_max = np.nanmax(Y_train_std, axis=0)\n",
    "\n",
    "\n",
    "(RealCase >= col_min) & (RealCase <= col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "pca.fit(Y_train_std)\n",
    "\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb933d04-1eda-4de5-9e5f-ffe2cb26375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(cumulative_variance >= 0.999) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "157ca255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_apply_pca(train_data, test_data, RealCase, variance_threshold=0.999):\n",
    "\n",
    "    # 拆分第一列\n",
    "    train_first_col = train_data[:, 0].reshape(-1, 1)\n",
    "    test_first_col = test_data[:, 0].reshape(-1, 1)\n",
    "    RealCase_first_col = RealCase[:, 0].reshape(-1, 1)\n",
    "    \n",
    "    train_remaining = train_data[:, 1:]\n",
    "    test_remaining = test_data[:, 1:]\n",
    "    RealCase_remaining = RealCase[:, 1:]\n",
    "    \n",
    "    # 初始化 PCA 并拟合剩余的列\n",
    "    pca = PCA()\n",
    "    pca.fit(train_remaining)\n",
    "    \n",
    "    # 计算累计方差\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # 确定主成分个数\n",
    "    n_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "    \n",
    "    # 根据主成分数重新拟合 PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    train_reduced = pca.fit_transform(train_remaining)\n",
    "    test_reduced = pca.transform(test_remaining)\n",
    "    RealCase_reduced = pca.transform(RealCase_remaining)\n",
    "\n",
    "    \n",
    "    # 合并第一列与降维后的数据\n",
    "    train_final = np.hstack((train_first_col, train_reduced))\n",
    "    test_final = np.hstack((test_first_col, test_reduced))\n",
    "    RealCase_final = np.hstack((RealCase_first_col, RealCase_reduced))\n",
    "    \n",
    "    return train_final, test_final, RealCase_final, n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca37626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pca, Y_test_pca, RealCase_pca, n_components = split_and_apply_pca(Y_train_std, Y_test_std, RealCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f5bd347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False,  True,  True, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False,  True,  True, False, False, False, False,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False, False,  True, False, False, False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_min = np.nanmin(Y_train_pca, axis=0)\n",
    "col_max = np.nanmax(Y_train_pca, axis=0)\n",
    "\n",
    "\n",
    "(RealCase_pca >= col_min) & (RealCase_pca <= col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"RealCase_Y_train_pca.csv\", Y_train_pca, delimiter=\",\", fmt=\"%.8f\")\n",
    "\n",
    "# np.savetxt(\"RealCase_Y_test_pca.csv\", Y_test_pca, delimiter=\",\", fmt=\"%.8f\")\n",
    "\n",
    "np.savetxt(\"RealCase_Y_pca.csv\", RealCase_pca, delimiter=\",\", fmt=\"%.8f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FGPyT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
