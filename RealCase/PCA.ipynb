{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ab895d",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f20e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2744d6",
   "metadata": {},
   "source": [
    "# RealCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba28972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SLICE_FILES = {\n",
    "    \"slice1\": Path(\"slice1.csv\"),\n",
    "    \"slice2\": Path(\"slice2.csv\"),\n",
    "    \"slice3\": Path(\"slice3.csv\"),\n",
    "    \"slice4\": Path(\"slice4.csv\"),\n",
    "    \"slice5\": Path(\"slice5.csv\"),\n",
    "}\n",
    "\n",
    "# 输出文件\n",
    "OUT_TABLE = Path(\"AHA17_peak_strains_subset_2_to_-2_table.csv\")  # 逐段表（1行/段）\n",
    "OUT_ONE_ROW_FULL = Path(\"AHA17_one_row_full_labels_cir_then_rad_custom_order.csv\")  # 单行（全称标签）\n",
    "OUT_ONE_ROW_ABBR = Path(\"AHA17_one_row_abbr_labels_cir_then_rad_custom_order.csv\")  # 单行（缩写标签）\n",
    "\n",
    "# 列名使用全称(True)或缩写(False)\n",
    "USE_FULL_LABELS = True\n",
    "\n",
    "# 你给定的 16 段顺序（仅 1–16 段）\n",
    "CUSTOM_ORDER_ABBR = [\n",
    "    \"Basal-InfSept\", \"Basal-AntSept\", \"Basal-Ant\", \"Basal-AntLat\", \"Basal-InfLat\", \"Basal-Inf\",\n",
    "    \"Mid-InfSept\", \"Mid-AntSept\", \"Mid-Ant\", \"Mid-AntLat\", \"Mid-InfLat\", \"Mid-Inf\",\n",
    "    \"Apical-Septal\", \"Apical-Anterior\", \"Apical-Lateral\", \"Apical-Inferior\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 辅助函数\n",
    "# =========================\n",
    "def subset_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"仅保留第2行到倒数第2行；若行不足3，则返回空\"\"\"\n",
    "    if len(df) < 3:\n",
    "        return df.iloc[0:0].copy()\n",
    "    return df.iloc[1:-1].reset_index(drop=True)\n",
    "\n",
    "def pos_name(col: str) -> str:\n",
    "    \"\"\"将列名 'cirAntSeptTotal' / 'radInfLatTotal' 规范为位置名 'AntSept' / 'InfLat'\"\"\"\n",
    "    name = col[3:]  # 去掉前缀 'cir' 或 'rad'\n",
    "    if name.endswith(\"Total\"):\n",
    "        name = name[:-5]\n",
    "    return name\n",
    "\n",
    "def per_slice_extrema_on_subset(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    基于子集（去掉首尾行）计算单个 slice 极值：\n",
    "    - cir_* 列取最小值\n",
    "    - rad_* 列取最大值\n",
    "    返回两个 dict：cir_min_map, rad_max_map（键：位置名，如 'Ant','InfSept' 等）\n",
    "    \"\"\"\n",
    "    sub = subset_df(df)\n",
    "    cir_cols = [c for c in sub.columns if c.startswith(\"cir\")]\n",
    "    rad_cols = [c for c in sub.columns if c.startswith(\"rad\")]\n",
    "    cir_min = {pos_name(c): (sub[c].min(skipna=True) if not sub.empty else float('nan'))\n",
    "               for c in cir_cols}\n",
    "    rad_max = {pos_name(c): (sub[c].max(skipna=True) if not sub.empty else float('nan'))\n",
    "               for c in rad_cols}\n",
    "    return cir_min, rad_max\n",
    "\n",
    "def avg_maps(m1: dict, m2: dict) -> dict:\n",
    "    \"\"\"按键对两个映射做均值（忽略 NaN）\"\"\"\n",
    "    keys = set(m1.keys()) | set(m2.keys())\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        out[k] = pd.Series([m1.get(k, float('nan')), m2.get(k, float('nan'))]).mean(skipna=True)\n",
    "    return out\n",
    "\n",
    "def mean2(a, b):\n",
    "    return pd.Series([a, b]).mean(skipna=True)\n",
    "\n",
    "# 缩写→全称映射（环段位置）\n",
    "ABBR_TO_FULL = {\n",
    "    \"Ant\": \"Anterior\",\n",
    "    \"AntSept\": \"Anteroseptal\",\n",
    "    \"InfSept\": \"Inferoseptal\",\n",
    "    \"Inf\": \"Inferior\",\n",
    "    \"InfLat\": \"Inferolateral\",\n",
    "    \"AntLat\": \"Anterolateral\",\n",
    "    # 顶端象限（已是全称）\n",
    "    \"Septal\": \"Septal\",\n",
    "    \"Anterior\": \"Anterior\",\n",
    "    \"Lateral\": \"Lateral\",\n",
    "    \"Inferior\": \"Inferior\",\n",
    "}\n",
    "\n",
    "def to_full_label(label_abbr: str) -> str:\n",
    "    \"\"\"\n",
    "    将 'Basal-InfSept' → 'Basal-Inferoseptal'\n",
    "       'Apical-Septal' 保持不变\n",
    "       'Apex (missing)' → 'Apex'\n",
    "    \"\"\"\n",
    "    s = str(label_abbr).strip()\n",
    "    if s.startswith(\"Apex\"):\n",
    "        return \"Apex\"\n",
    "    if \"-\" in s:\n",
    "        ring, pos = s.split(\"-\", 1)\n",
    "        full_pos = ABBR_TO_FULL.get(pos, pos)\n",
    "        return f\"{ring}-{full_pos}\"\n",
    "    return s\n",
    "\n",
    "# =========================\n",
    "# 计算流程\n",
    "# =========================\n",
    "# 1) 读取数据 + 各 slice 子集极值\n",
    "s1 = pd.read_csv(SLICE_FILES[\"slice1\"])\n",
    "s2 = pd.read_csv(SLICE_FILES[\"slice2\"])\n",
    "s3 = pd.read_csv(SLICE_FILES[\"slice3\"])\n",
    "s4 = pd.read_csv(SLICE_FILES[\"slice4\"])\n",
    "s5 = pd.read_csv(SLICE_FILES[\"slice5\"])\n",
    "\n",
    "cir1, rad1 = per_slice_extrema_on_subset(s1)\n",
    "cir2, rad2 = per_slice_extrema_on_subset(s2)\n",
    "cir3, rad3 = per_slice_extrema_on_subset(s3)\n",
    "cir4, rad4 = per_slice_extrema_on_subset(s4)\n",
    "cir5_map, rad5_map = per_slice_extrema_on_subset(s5)\n",
    "\n",
    "# 2) (slice1,slice2) 与 (slice3,slice4) 对应位置平均\n",
    "cir12 = avg_maps(cir1, cir2)\n",
    "rad12 = avg_maps(rad1, rad2)\n",
    "cir34 = avg_maps(cir3, cir4)\n",
    "rad34 = avg_maps(rad3, rad4)\n",
    "\n",
    "# AHA 6 扇区顺序（环内位置的标准顺序）\n",
    "AHA6 = [\"Ant\", \"AntSept\", \"InfSept\", \"Inf\", \"InfLat\", \"AntLat\"]\n",
    "\n",
    "# 3) 组装 1–12 段（Basal、Mid）\n",
    "rows = []\n",
    "for i, pos in enumerate(AHA6, start=1):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label_abbr\": f\"Basal-{pos}\",\n",
    "        \"cir_min\": cir12.get(pos, float('nan')),\n",
    "        \"rad_max\": rad12.get(pos, float('nan'))\n",
    "    })\n",
    "for i, pos in enumerate(AHA6, start=7):\n",
    "    rows.append({\n",
    "        \"segment\": i,\n",
    "        \"label_abbr\": f\"Mid-{pos}\",\n",
    "        \"cir_min\": cir34.get(pos, float('nan')),\n",
    "        \"rad_max\": rad34.get(pos, float('nan'))\n",
    "    })\n",
    "\n",
    "# 4) 组装 13–16 段（Apical，来自 slice5；按规则合并位置）\n",
    "APICAL_RULES = [\n",
    "    (13, \"Apical-Anterior\",  (\"Ant\",)),                      # 13=Ant\n",
    "    (14, \"Apical-Septal\",    (\"AntSept\", \"InfSept\")),        # 14=mean(AntSept, InfSept)\n",
    "    (15, \"Apical-Inferior\",  (\"Inf\",)),                      # 15=Inf\n",
    "    (16, \"Apical-Lateral\",   (\"AntLat\", \"InfLat\")),          # 16=mean(AntLat, InfLat)\n",
    "]\n",
    "for seg, label_full, pos_tuple in APICAL_RULES:\n",
    "    if len(pos_tuple) == 1:\n",
    "        p = pos_tuple[0]\n",
    "        cir_v = cir5_map.get(p, float('nan'))\n",
    "        rad_v = rad5_map.get(p, float('nan'))\n",
    "    else:\n",
    "        cir_v = mean2(cir5_map.get(pos_tuple[0], float('nan')),\n",
    "                      cir5_map.get(pos_tuple[1], float('nan')))\n",
    "        rad_v = mean2(rad5_map.get(pos_tuple[0], float('nan')),\n",
    "                      rad5_map.get(pos_tuple[1], float('nan')))\n",
    "    # 这里 label_abbr 使用 'Apical-Anterior' 等（已是全称位置词）\n",
    "    rows.append({\n",
    "        \"segment\": seg,\n",
    "        \"label_abbr\": label_full,  # 作为缩写标签使用（Apical-* 已是全称）\n",
    "        \"cir_min\": cir_v,\n",
    "        \"rad_max\": rad_v\n",
    "    })\n",
    "\n",
    "# 5) 17 段占位\n",
    "rows.append({\n",
    "    \"segment\": 17,\n",
    "    \"label_abbr\": \"Apex (missing)\",\n",
    "    \"cir_min\": float('nan'),\n",
    "    \"rad_max\": float('nan')\n",
    "})\n",
    "\n",
    "table = pd.DataFrame(rows).sort_values(\"segment\").reset_index(drop=True)\n",
    "\n",
    "# 冗余一列：全称标签\n",
    "table[\"label_full\"] = table[\"label_abbr\"].map(to_full_label)\n",
    "\n",
    "# 保存逐段表（便于检查）\n",
    "table[[\"segment\", \"label_abbr\", \"label_full\", \"cir_min\", \"rad_max\"]].to_csv(OUT_TABLE, index=False)\n",
    "\n",
    "# 6) 依据你给定的 16 段顺序（仅 1–16 段）构建单行输出\n",
    "#    - 先 CIR 块（按顺序 16 列），再 RAD 块（按相同顺序 16 列）\n",
    "#    - 列名可选：全称或缩写\n",
    "order_abbr_16 = CUSTOM_ORDER_ABBR[:]  # 拷贝\n",
    "# 构造查找表：abbr → 值（从 table 中取）\n",
    "# 注意：table 中 apical 已采用全称词（Apical-Anterior 等），与 CUSTOM_ORDER_ABBR 的 Apical-* 保持一致\n",
    "lookup_abbr_to_vals = {\n",
    "    lab: table.loc[table[\"label_abbr\"] == lab, [\"cir_min\", \"rad_max\"]].iloc[0].to_dict()\n",
    "    for lab in table[\"label_abbr\"].tolist()\n",
    "    if lab != \"Apex (missing)\"\n",
    "}\n",
    "\n",
    "# 生成列名序列（根据 USE_FULL_LABELS 选择全称/缩写）\n",
    "def col_name_base(label_abbr: str) -> str:\n",
    "    return to_full_label(label_abbr) if USE_FULL_LABELS else label_abbr\n",
    "\n",
    "cir_cols = [f\"{col_name_base(lab)}_cir\" for lab in order_abbr_16]\n",
    "rad_cols = [f\"{col_name_base(lab)}_rad\" for lab in order_abbr_16]\n",
    "\n",
    "# 生成对应取值（严格按顺序）\n",
    "cir_vals = [lookup_abbr_to_vals.get(lab, {\"cir_min\": float('nan')})[\"cir_min\"]\n",
    "            for lab in order_abbr_16]\n",
    "rad_vals = [lookup_abbr_to_vals.get(lab, {\"rad_max\": float('nan')})[\"rad_max\"]\n",
    "            for lab in order_abbr_16]\n",
    "\n",
    "one_row = pd.DataFrame([cir_vals + rad_vals], columns=cir_cols + rad_cols)\n",
    "\n",
    "# 输出文件（按标签样式选择）\n",
    "if USE_FULL_LABELS:\n",
    "    one_row.to_csv(OUT_ONE_ROW_FULL, index=False)\n",
    "    print(f\"Saved single-row (full labels) to: {OUT_ONE_ROW_FULL}\")\n",
    "else:\n",
    "    one_row.to_csv(OUT_ONE_ROW_ABBR, index=False)\n",
    "    print(f\"Saved single-row (abbr labels) to: {OUT_ONE_ROW_ABBR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLICE_FILES = {\n",
    "    \"slice1\": Path(\"slice1.csv\"),\n",
    "    \"slice2\": Path(\"slice2.csv\"),\n",
    "    \"slice3\": Path(\"slice3.csv\"),\n",
    "    \"slice4\": Path(\"slice4.csv\"),\n",
    "    \"slice5\": Path(\"slice5.csv\"),\n",
    "}\n",
    "\n",
    "# 输出文件（注意：现在两个文件都会产生多行结果，并新增 source 列）\n",
    "OUT_TABLE = Path(\"AHA17_subset_by_rows_table.csv\")\n",
    "OUT_ONE_ROW_FULL = Path(\"AHA17_rows_full_labels_cir_then_rad.csv\")\n",
    "OUT_ONE_ROW_ABBR = Path(\"AHA17_rows_abbr_labels_cir_then_rad.csv\")\n",
    "\n",
    "# 列名使用全称(True)或缩写(False)\n",
    "USE_FULL_LABELS = True\n",
    "\n",
    "# 你给定的 16 段顺序（仅 1–16 段）\n",
    "CUSTOM_ORDER_ABBR = [\n",
    "    \"Basal-InfSept\", \"Basal-AntSept\", \"Basal-Ant\", \"Basal-AntLat\", \"Basal-InfLat\", \"Basal-Inf\",\n",
    "    \"Mid-InfSept\", \"Mid-AntSept\", \"Mid-Ant\", \"Mid-AntLat\", \"Mid-InfLat\", \"Mid-Inf\",\n",
    "    \"Apical-Septal\", \"Apical-Anterior\", \"Apical-Lateral\", \"Apical-Inferior\"\n",
    "]\n",
    "\n",
    "# AHA 6 扇区顺序（环内位置的标准顺序）\n",
    "AHA6 = [\"Ant\", \"AntSept\", \"InfSept\", \"Inf\", \"InfLat\", \"AntLat\"]\n",
    "\n",
    "# Apical 规则（slice5）\n",
    "APICAL_RULES = [\n",
    "    (13, \"Apical-Anterior\",  (\"Ant\",)),                      # 13=Ant\n",
    "    (14, \"Apical-Septal\",    (\"AntSept\", \"InfSept\")),        # 14=mean(AntSept, InfSept)\n",
    "    (15, \"Apical-Inferior\",  (\"Inf\",)),                      # 15=Inf\n",
    "    (16, \"Apical-Lateral\",   (\"AntLat\", \"InfLat\")),          # 16=mean(AntLat, InfLat)\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 辅助函数\n",
    "# =========================\n",
    "def subset_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"仅保留第2行到倒数第2行；若行不足3，则返回空\"\"\"\n",
    "    if len(df) < 3:\n",
    "        return df.iloc[0:0].copy()\n",
    "    return df.iloc[1:-1].reset_index(drop=True)\n",
    "\n",
    "def pos_name(col: str) -> str:\n",
    "    \"\"\"将列名 'cirAntSeptTotal' / 'radInfLatTotal' 规范为位置名 'AntSept' / 'InfLat'\"\"\"\n",
    "    name = col[3:]  # 去掉前缀 'cir' 或 'rad'\n",
    "    if name.endswith(\"Total\"):\n",
    "        name = name[:-5]\n",
    "    return name\n",
    "\n",
    "def per_slice_extrema_on_subset(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    极值行（第0行用）：基于子集（去掉首尾行）\n",
    "    - cir_* 列取最小值\n",
    "    - rad_* 列取最大值\n",
    "    返回两个 dict：cir_min_map, rad_max_map（键：位置名）\n",
    "    \"\"\"\n",
    "    sub = subset_df(df)\n",
    "    cir_cols = [c for c in sub.columns if c.startswith(\"cir\")]\n",
    "    rad_cols = [c for c in sub.columns if c.startswith(\"rad\")]\n",
    "    if sub.empty:\n",
    "        cir_min = {pos_name(c): float('nan') for c in cir_cols}\n",
    "        rad_max = {pos_name(c): float('nan') for c in rad_cols}\n",
    "    else:\n",
    "        cir_min = {pos_name(c): sub[c].min(skipna=True) for c in cir_cols}\n",
    "        rad_max = {pos_name(c): sub[c].max(skipna=True) for c in rad_cols}\n",
    "    return cir_min, rad_max\n",
    "\n",
    "def per_slice_row_values_on_subset(df: pd.DataFrame, row_idx: int):\n",
    "    \"\"\"\n",
    "    行对齐法（第1..N行用）：基于子集（去掉首尾行）选取第 row_idx 行的**原始值**（不取极值/均值）\n",
    "    返回两个 dict：cir_map, rad_map（键：位置名）\n",
    "    \"\"\"\n",
    "    sub = subset_df(df)\n",
    "    cir_cols = [c for c in sub.columns if c.startswith(\"cir\")]\n",
    "    rad_cols = [c for c in sub.columns if c.startswith(\"rad\")]\n",
    "    if row_idx < 0 or row_idx >= len(sub):\n",
    "        # 越界时返回 NaN\n",
    "        cir_map = {pos_name(c): float('nan') for c in cir_cols}\n",
    "        rad_map = {pos_name(c): float('nan') for c in rad_cols}\n",
    "    else:\n",
    "        row = sub.iloc[row_idx]\n",
    "        cir_map = {pos_name(c): row[c] for c in cir_cols}\n",
    "        rad_map = {pos_name(c): row[c] for c in rad_cols}\n",
    "    return cir_map, rad_map\n",
    "\n",
    "def avg_maps(m1: dict, m2: dict) -> dict:\n",
    "    \"\"\"按键对两个映射做均值（忽略 NaN）\"\"\"\n",
    "    keys = set(m1.keys()) | set(m2.keys())\n",
    "    return {k: pd.Series([m1.get(k, float('nan')), m2.get(k, float('nan'))]).mean(skipna=True)\n",
    "            for k in keys}\n",
    "\n",
    "def mean2(a, b):\n",
    "    return pd.Series([a, b]).mean(skipna=True)\n",
    "\n",
    "# 缩写→全称映射（环段位置）\n",
    "ABBR_TO_FULL = {\n",
    "    \"Ant\": \"Anterior\",\n",
    "    \"AntSept\": \"Anteroseptal\",\n",
    "    \"InfSept\": \"Inferoseptal\",\n",
    "    \"Inf\": \"Inferior\",\n",
    "    \"InfLat\": \"Inferolateral\",\n",
    "    \"AntLat\": \"Anterolateral\",\n",
    "    # 顶端象限（已是全称）\n",
    "    \"Septal\": \"Septal\",\n",
    "    \"Anterior\": \"Anterior\",\n",
    "    \"Lateral\": \"Lateral\",\n",
    "    \"Inferior\": \"Inferior\",\n",
    "}\n",
    "\n",
    "def to_full_label(label_abbr: str) -> str:\n",
    "    \"\"\"'Basal-InfSept' → 'Basal-Inferoseptal'；'Apical-Septal' 保持；'Apex (missing)' → 'Apex'\"\"\"\n",
    "    s = str(label_abbr).strip()\n",
    "    if s.startswith(\"Apex\"):\n",
    "        return \"Apex\"\n",
    "    if \"-\" in s:\n",
    "        ring, pos = s.split(\"-\", 1)\n",
    "        full_pos = ABBR_TO_FULL.get(pos, pos)\n",
    "        return f\"{ring}-{full_pos}\"\n",
    "    return s\n",
    "\n",
    "def build_aha17_rows(cir12: dict, rad12: dict, cir34: dict, rad34: dict,\n",
    "                     cir5_map: dict, rad5_map: dict, source: str):\n",
    "    \"\"\"\n",
    "    给定 Basal/Mid/Apical 三部分的映射，组装 AHA17（含占位17段）。\n",
    "    返回：长表 rows_list（逐段）、以及宽表一行（先 CIR 16 列，再 RAD 16 列）。\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    # 1–12 段：Basal, Mid\n",
    "    for i, pos in enumerate(AHA6, start=1):\n",
    "        rows.append({\n",
    "            \"source\": source,\n",
    "            \"segment\": i,\n",
    "            \"label_abbr\": f\"Basal-{pos}\",\n",
    "            \"cir\": cir12.get(pos, float('nan')),\n",
    "            \"rad\": rad12.get(pos, float('nan')),\n",
    "        })\n",
    "    for i, pos in enumerate(AHA6, start=7):\n",
    "        rows.append({\n",
    "            \"source\": source,\n",
    "            \"segment\": i,\n",
    "            \"label_abbr\": f\"Mid-{pos}\",\n",
    "            \"cir\": cir34.get(pos, float('nan')),\n",
    "            \"rad\": rad34.get(pos, float('nan')),\n",
    "        })\n",
    "\n",
    "    # 13–16 段：Apical（slice5）\n",
    "    for seg, label_full, pos_tuple in APICAL_RULES:\n",
    "        if len(pos_tuple) == 1:\n",
    "            p = pos_tuple[0]\n",
    "            cir_v = cir5_map.get(p, float('nan'))\n",
    "            rad_v = rad5_map.get(p, float('nan'))\n",
    "        else:\n",
    "            cir_v = mean2(cir5_map.get(pos_tuple[0], float('nan')),\n",
    "                          cir5_map.get(pos_tuple[1], float('nan')))\n",
    "            rad_v = mean2(rad5_map.get(pos_tuple[0], float('nan')),\n",
    "                          rad5_map.get(pos_tuple[1], float('nan')))\n",
    "        rows.append({\n",
    "            \"source\": source,\n",
    "            \"segment\": seg,\n",
    "            \"label_abbr\": label_full,\n",
    "            \"cir\": cir_v,\n",
    "            \"rad\": rad_v,\n",
    "        })\n",
    "\n",
    "    # 17 段占位\n",
    "    rows.append({\n",
    "        \"source\": source,\n",
    "        \"segment\": 17,\n",
    "        \"label_abbr\": \"Apex (missing)\",\n",
    "        \"cir\": float('nan'),\n",
    "        \"rad\": float('nan'),\n",
    "    })\n",
    "\n",
    "    # 加全称\n",
    "    for r in rows:\n",
    "        r[\"label_full\"] = to_full_label(r[\"label_abbr\"])\n",
    "\n",
    "    # 宽表一行（仅 1–16 段，先 CIR 后 RAD）\n",
    "    order_abbr_16 = CUSTOM_ORDER_ABBR[:]\n",
    "    # 先做查找\n",
    "    tmp_df = pd.DataFrame(rows)\n",
    "    tmp_df16 = tmp_df[tmp_df[\"segment\"] <= 16].copy()\n",
    "    lookup = {\n",
    "        lab: tmp_df16.loc[tmp_df16[\"label_abbr\"] == lab, [\"cir\", \"rad\"]].iloc[0].to_dict()\n",
    "        for lab in tmp_df16[\"label_abbr\"].unique()\n",
    "    }\n",
    "\n",
    "    def col_name_base(label_abbr: str) -> str:\n",
    "        return to_full_label(label_abbr) if USE_FULL_LABELS else label_abbr\n",
    "\n",
    "    cir_cols = [f\"{col_name_base(lab)}_cir\" for lab in order_abbr_16]\n",
    "    rad_cols = [f\"{col_name_base(lab)}_rad\" for lab in order_abbr_16]\n",
    "    cir_vals = [lookup.get(lab, {\"cir\": float('nan')})[\"cir\"] for lab in order_abbr_16]\n",
    "    rad_vals = [lookup.get(lab, {\"rad\": float('nan')})[\"rad\"] for lab in order_abbr_16]\n",
    "    wide_row = {\"source\": source}\n",
    "    wide_row.update({c: v for c, v in zip(cir_cols, cir_vals)})\n",
    "    wide_row.update({c: v for c, v in zip(rad_cols, rad_vals)})\n",
    "\n",
    "    return rows, wide_row\n",
    "\n",
    "# =========================\n",
    "# 主流程\n",
    "# =========================\n",
    "# 读取\n",
    "s1 = pd.read_csv(SLICE_FILES[\"slice1\"])\n",
    "s2 = pd.read_csv(SLICE_FILES[\"slice2\"])\n",
    "s3 = pd.read_csv(SLICE_FILES[\"slice3\"])\n",
    "s4 = pd.read_csv(SLICE_FILES[\"slice4\"])\n",
    "s5 = pd.read_csv(SLICE_FILES[\"slice5\"])\n",
    "\n",
    "# 子集（去首尾）\n",
    "sub1, sub2, sub3, sub4, sub5 = map(subset_df, [s1, s2, s3, s4, s5])\n",
    "\n",
    "# --------- 第 0 行：极值法 ----------\n",
    "cir1_ext, rad1_ext = per_slice_extrema_on_subset(s1)\n",
    "cir2_ext, rad2_ext = per_slice_extrema_on_subset(s2)\n",
    "cir3_ext, rad3_ext = per_slice_extrema_on_subset(s3)\n",
    "cir4_ext, rad4_ext = per_slice_extrema_on_subset(s4)\n",
    "cir5_ext, rad5_ext = per_slice_extrema_on_subset(s5)\n",
    "\n",
    "cir12_ext = avg_maps(cir1_ext, cir2_ext)\n",
    "rad12_ext = avg_maps(rad1_ext, rad2_ext)\n",
    "cir34_ext = avg_maps(cir3_ext, cir4_ext)\n",
    "rad34_ext = avg_maps(rad3_ext, rad4_ext)\n",
    "\n",
    "rows_all, wide_all = [], []\n",
    "rows0, wide0 = build_aha17_rows(cir12_ext, rad12_ext, cir34_ext, rad34_ext,\n",
    "                                cir5_ext, rad5_ext, source=\"extrema\")\n",
    "rows_all.extend(rows0)\n",
    "wide_all.append(wide0)\n",
    "\n",
    "# --------- 后续行：行对齐法 ----------\n",
    "len12 = min(len(sub1), len(sub2))\n",
    "len34 = min(len(sub3), len(sub4))\n",
    "len5  = len(sub5)\n",
    "N = min(len12, len34, len5)\n",
    "\n",
    "for k in range(N):\n",
    "    cir1_k, rad1_k = per_slice_row_values_on_subset(s1, k)\n",
    "    cir2_k, rad2_k = per_slice_row_values_on_subset(s2, k)\n",
    "    cir3_k, rad3_k = per_slice_row_values_on_subset(s3, k)\n",
    "    cir4_k, rad4_k = per_slice_row_values_on_subset(s4, k)\n",
    "    cir5_k, rad5_k = per_slice_row_values_on_subset(s5, k)\n",
    "\n",
    "    cir12_k = avg_maps(cir1_k, cir2_k)\n",
    "    rad12_k = avg_maps(rad1_k, rad2_k)\n",
    "    cir34_k = avg_maps(cir3_k, cir4_k)\n",
    "    rad34_k = avg_maps(rad3_k, rad4_k)\n",
    "\n",
    "    src = f\"row_{k}\"\n",
    "    rows_k, wide_k = build_aha17_rows(cir12_k, rad12_k, cir34_k, rad34_k,\n",
    "                                      cir5_k, rad5_k, source=src)\n",
    "    rows_all.extend(rows_k)\n",
    "    wide_all.append(wide_k)\n",
    "\n",
    "# ========== 保存 ==========\n",
    "# 长表（多行×17段）\n",
    "table = pd.DataFrame(rows_all).sort_values([\"source\", \"segment\"]).reset_index(drop=True)\n",
    "table.to_csv(OUT_TABLE, index=False)\n",
    "\n",
    "# 宽表（多行×(1 + 32列)，含 source）\n",
    "wide = pd.DataFrame(wide_all)\n",
    "if USE_FULL_LABELS:\n",
    "    wide.to_csv(OUT_ONE_ROW_FULL, index=False)\n",
    "    print(f\"Saved multi-row wide table (full labels) to: {OUT_ONE_ROW_FULL}\")\n",
    "else:\n",
    "    wide.to_csv(OUT_ONE_ROW_ABBR, index=False)\n",
    "    print(f\"Saved multi-row wide table (abbr labels) to: {OUT_ONE_ROW_ABBR}\")\n",
    "\n",
    "print(f\"Saved long table (per-segment) to: {OUT_TABLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bf314",
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcdd546",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e5947a-818e-47f0-a79b-dc04f3ac3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('RealCase_X_train.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('RealCase_Y_train_std.csv', header=None, delimiter=',').values\n",
    "\n",
    "X_test = pd.read_csv('RealCase_X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_test_std = pd.read_csv('RealCase_Y_test_std.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b9aa961",
   "metadata": {},
   "outputs": [],
   "source": [
    "RealCase = pd.read_csv('RealCase_Y.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AHA17_rows_full_labels_cir_then_rad = pd.read_csv('AHA17_rows_full_labels_cir_then_rad.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e73e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "AHA17_rows_full_labels_cir_then_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8959cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506a0921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30,  2,  6, 15, 27, 31, 32, 31, 32, 31, 31, 31, 32, 31, 30])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_min = np.nanmin(Y_train_std, axis=0)\n",
    "col_max = np.nanmax(Y_train_std, axis=0)\n",
    "\n",
    "\n",
    "((RealCase >= col_min) & (RealCase <= col_max)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74dfc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Row_11 = RealCase[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78d5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrow_11 = (Row_11 >= col_min) & (Row_11 <= col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d2543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RealCase_11 = RealCase[:,maskrow_11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9103de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_std_11 = Y_train_std[:,maskrow_11]\n",
    "Y_test_std_11 = Y_test_std[:,maskrow_11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "pca.fit(Y_train_std_11)\n",
    "\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb933d04-1eda-4de5-9e5f-ffe2cb26375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(cumulative_variance >= 0.999) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "157ca255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sign_flip_scores(components, scores):\n",
    "\n",
    "    comps = components.copy()\n",
    "    Z = scores.copy()\n",
    "    for i in range(comps.shape[0]):\n",
    "        j = np.argmax(np.abs(comps[i]))  # 该成分绝对值最大的载荷索引\n",
    "        if comps[i, j] < 0:              # 若为负则整体翻转\n",
    "            comps[i] *= -1\n",
    "            Z[:, i] *= -1\n",
    "    return comps, Z\n",
    "\n",
    "def split_and_apply_pca(train_data, test_data, RealCase_pca, variance_threshold=0.999,\n",
    "                        svd_solver='full', random_state=0):\n",
    "\n",
    "\n",
    "    train_first_col = train_data[:, 0].reshape(-1, 1)\n",
    "    test_first_col  = test_data[:, 0].reshape(-1, 1)\n",
    "    RealCase_first_col  = RealCase_pca[:, 0].reshape(-1, 1)\n",
    "\n",
    "    train_remaining = train_data[:, 1:]\n",
    "    test_remaining  = test_data[:, 1:]\n",
    "    RealCase_remaining  = RealCase_pca[:, 1:]\n",
    "\n",
    "\n",
    "    pca_full = PCA(svd_solver=svd_solver, random_state=random_state)\n",
    "    pca_full.fit(train_remaining)\n",
    "    cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "    n_components = int(np.argmax(cumulative_variance >= variance_threshold) + 1)\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=n_components, svd_solver=svd_solver, random_state=random_state)\n",
    "    train_scores = pca.fit_transform(train_remaining)  # Z_train\n",
    "    test_scores  = pca.transform(test_remaining)       # Z_test\n",
    "    RealCase_scores  = pca.transform(RealCase_remaining)       # Z_test\n",
    "\n",
    "    # 5) 进行“符号固定”，消除 ± 号的随机性\n",
    "    comps_fixed, train_scores_fixed = _sign_flip_scores(pca.components_, train_scores)\n",
    "    _,           test_scores_fixed  = _sign_flip_scores(pca.components_, test_scores)\n",
    "    _,           RealCase_scores_fixed  = _sign_flip_scores(pca.components_, RealCase_scores)\n",
    "\n",
    "    # （可选）若你希望把固定后的 components 回写给 pca 对象，可取消下面两行注释：\n",
    "    # pca.components_ = comps_fixed\n",
    "    # 注意：scikit-learn 并不依赖 components_ 的符号唯一性，回写仅用于记录\n",
    "\n",
    "    # 6) 合并回第一列\n",
    "    train_final = np.hstack((train_first_col, train_scores_fixed))\n",
    "    test_final  = np.hstack((test_first_col,  test_scores_fixed))\n",
    "    RealCase_final  = np.hstack((RealCase_first_col,  RealCase_scores_fixed))\n",
    "\n",
    "    return train_final, test_final, RealCase_final, n_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca37626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pca, Y_test_pca, RealCase_pca, n_components = split_and_apply_pca(Y_train_std_11, Y_test_std_11, RealCase_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c5ec8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f5bd347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 14, 14, 14, 15, 15, 15, 12, 10,  9, 11, 11, 11, 12, 11])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_min = np.nanmin(Y_train_pca, axis=0)\n",
    "col_max = np.nanmax(Y_train_pca, axis=0)\n",
    "\n",
    "\n",
    "((RealCase_pca >= col_min) & (RealCase_pca <= col_max)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"RealCase_Y_train_pca.csv\", Y_train_pca, delimiter=\",\", fmt=\"%.8f\")\n",
    "\n",
    "np.savetxt(\"RealCase_Y_test_pca.csv\", Y_test_pca, delimiter=\",\", fmt=\"%.8f\")\n",
    "\n",
    "np.savetxt(\"RealCase_Y_pca.csv\", RealCase_pca, delimiter=\",\", fmt=\"%.8f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FGPyT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
