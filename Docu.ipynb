{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from linear_operator import settings\n",
    "\n",
    "import pyro\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GP_functions.Loss_function as Loss_function\n",
    "import GP_functions.bound as bound\n",
    "import GP_functions.Estimation as Estimation\n",
    "import GP_functions.Training as Training\n",
    "import GP_functions.Prediction as Prediction\n",
    "import GP_functions.GP_models as GP_models\n",
    "import GP_functions.Tools as Tools\n",
    "import GP_functions.FeatureE as FeatureE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/X_train.csv', header=None, delimiter=',').values\n",
    "X_test = pd.read_csv('Data/X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "# Y_train_8 = pd.read_csv('Data/Y_train_8.csv', header=None, delimiter=',').values\n",
    "# Y_test_8 = pd.read_csv('Data/Y_test_8.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_21 = pd.read_csv('Data/Y_train_std_21.csv', header=None, delimiter=',').values\n",
    "Y_test_21 = pd.read_csv('Data/Y_test_std_21.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('Data/Y_train_std.csv', header=None, delimiter=',').values\n",
    "Y_test_std = pd.read_csv('Data/Y_test_std.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(X_train, dtype=torch.float32)\n",
    "test_x = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# train_y_8 = torch.tensor(Y_train_8, dtype=torch.float32)\n",
    "# test_y_8 = torch.tensor(Y_test_8, dtype=torch.float32)\n",
    "\n",
    "train_y_21 = torch.tensor(Y_train_21, dtype=torch.float32)\n",
    "test_y_21 = torch.tensor(Y_test_21, dtype=torch.float32)\n",
    "\n",
    "train_y = torch.tensor(Y_train_std, dtype=torch.float32)\n",
    "test_y = torch.tensor(Y_test_std, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_20 = PCA(n_components = 20)\n",
    "\n",
    "pca_20.fit(train_y[:,1:])\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_num_threads(8)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 100)\n",
    "\n",
    "bounds = bound.get_bounds(local_train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LocalGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'Result/LocalGP_21_result.csv'\n",
    "\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('Iteration,test_preds,estimated_params,posterior_means\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "\n",
    "input_point = test_y_21[row_idx, :]\n",
    "\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y_21, k=100)\n",
    "\n",
    "LocalGP_models, LocalGP_likelihoods = Training.train_one_row_LocalGP_Parallel(\n",
    "    train_x, train_y_21, test_y_21, row_idx,\n",
    "    covar_type='RBF', k_num=100, lr=0.025,\n",
    "    num_iterations=5000, patience=10, device=Device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tmp = Prediction.full_preds(\n",
    "    LocalGP_models, LocalGP_likelihoods, test_x[row_idx, :].unsqueeze(0).to(Device)\n",
    ").cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "estimated_params_tmp, _ = Estimation.multi_start_estimation(\n",
    "    LocalGP_models, LocalGP_likelihoods, row_idx, test_y_21, bounds,\n",
    "    Estimation.estimate_params_Adam, num_starts=5, num_iterations=2000, lr=0.01,\n",
    "    patience=50, attraction_threshold=0.1, repulsion_strength=0.1, device=Device\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = bound.get_bounds(local_train_x)\n",
    "params = []\n",
    "\n",
    "for i, (min_val, max_val) in enumerate(bounds):\n",
    "    param_i = pyro.sample(f'param_{i}', dist.Uniform(min_val, max_val))\n",
    "    params.append(param_i)\n",
    "\n",
    "theta = torch.stack(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(torch.tensor(b[0], dtype=torch.float32), torch.tensor(b[1], dtype=torch.float32)) for b in bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for i, (min_val, max_val) in enumerate(bounds):\n",
    "    param_i = pyro.sample(f'param_{i}', dist.Uniform(min_val, max_val))\n",
    "    params.append(param_i)\n",
    "\n",
    "theta = torch.stack(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate(\"params\", len(bounds)):\n",
    "    min_vals = torch.tensor([b[0].item() for b in bounds], dtype=torch.float32)\n",
    "    max_vals = torch.tensor([b[1].item() for b in bounds], dtype=torch.float32)\n",
    "    params = pyro.sample(\"params\", dist.Uniform(min_vals, max_vals).to_event(1))\n",
    "    print(f\"Sampled params: {params}\")\n",
    "\n",
    "theta = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "with pyro.plate(\"params\", len(bounds)):\n",
    "    for i, (min_val, max_val) in enumerate(bounds):\n",
    "        param_i = pyro.sample(f\"param_{i}\", dist.Uniform(min_val, max_val))\n",
    "        params.append(param_i)\n",
    "theta = torch.stack(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_func = pca_20\n",
    "num_sampling=200\n",
    "warmup_step=100\n",
    "num_chains=1\n",
    "\n",
    "\n",
    "\n",
    "bounds = [(torch.tensor(b[0], dtype=torch.float32), torch.tensor(b[1], dtype=torch.float32)) for b in bounds]\n",
    "\n",
    "if PCA_func != 'None':\n",
    "    components = torch.from_numpy(PCA_func.components_).to(dtype=torch.float32)\n",
    "    mean_PCA = torch.from_numpy(PCA_func.mean_).to(dtype=torch.float32)\n",
    "\n",
    "@torch.compile\n",
    "def model():\n",
    "\n",
    "    params = []\n",
    "    for i, (min_val, max_val) in enumerate(bounds):\n",
    "        param_i = pyro.sample(f'param_{i}', dist.Uniform(min_val, max_val))\n",
    "        params.append(param_i)\n",
    "    \n",
    "    theta = torch.stack(params)\n",
    "\n",
    "    sigma = pyro.sample('sigma', dist.HalfNormal(10.0))\n",
    "\n",
    "    if PCA_func == 'None':\n",
    "        mu_value = Prediction.full_preds(LocalGP_models, LocalGP_likelihoods, theta.unsqueeze(0)).view(-1)\n",
    "    else:\n",
    "        preds = Prediction.full_preds(LocalGP_models, LocalGP_likelihoods, theta.unsqueeze(0))\n",
    "        first_col = preds[0].view(-1)\n",
    "        remaining_cols = preds[1:].view(-1)\n",
    "        processed_cols = (torch.matmul(remaining_cols, components) + mean_PCA)\n",
    "        mu_value = torch.cat([first_col.unsqueeze(1), processed_cols.unsqueeze(0)], dim=1).view(-1)\n",
    "\n",
    "    y_obs = test_y[row_idx, :]\n",
    "    pyro.sample('obs', dist.Normal(mu_value, sigma), obs=y_obs)\n",
    "\n",
    "nuts_kernel = NUTS(model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=num_sampling, warmup_steps=warmup_step, num_chains=num_chains)\n",
    "mcmc.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.config.verbose = True\n",
    "mcmc_result_Uniform = Estimation.run_mcmc_Uniform(\n",
    "    Prediction.full_preds, LocalGP_models, LocalGP_likelihoods, \n",
    "    row_idx, test_y, bounds, \n",
    "    PCA_func=pca_20, \n",
    "    num_sampling=400, warmup_step=100, num_chains=1\n",
    ")\n",
    "posterior_samples_Uniform = mcmc_result_Uniform.get_samples()\n",
    "\n",
    "param_names = [f'param_{i}' for i in range(len(bounds))]\n",
    "posterior_means_array_tmp = np.zeros(len(param_names))\n",
    "\n",
    "for idx, param_name in enumerate(param_names):\n",
    "    samples = posterior_samples_Uniform[param_name]\n",
    "    if samples.ndim > 1:\n",
    "        samples = samples.reshape(-1)\n",
    "    posterior_means_array_tmp[idx] = torch.mean(samples).item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior_samples_Uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'a') as f:\n",
    "    f.write(f\"{row_idx + 1},\\\"{list(preds_tmp)}\\\",\\\"{list(estimated_params_tmp.detach().numpy())}\\\",\\\"{list(posterior_means_array_tmp)}\\\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_LocalGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "    LocalGP_models, LocalGP_likelihoods = Training.train_one_row_LocalGP(\n",
    "        train_x, train_y, test_y, row_idx, covar_type = 'RQ', k_num=K_num, lr=0.05, num_iterations=5000, patience=10, device=Device\n",
    "    )\n",
    "    \n",
    "    preds = Prediction.full_preds(LocalGP_models, LocalGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).cpu().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_LocalGP)(row_idx, train_x, train_y_20, test_x, test_y_20, PCA_trans = pca_20) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_LocalGP = np.vstack(results)\n",
    "\n",
    "MSE_LocalGP = np.mean((full_test_preds_LocalGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_LocalGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_LocalGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y_21[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y_21, k = 100)\n",
    "\n",
    "\n",
    "MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP(local_train_x, local_train_y, n_tasks = local_train_y.shape[1], \n",
    "                                                                                 covar_type = 'RBF', lr=0.05, num_iterations=5000, patience=10, device=Device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction.preds_for_one_model(MultitaskGP_models, MultitaskGP_likelihoods, theta.unsqueeze(0)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_MGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "\n",
    "    input_point = test_y[row_idx,:]\n",
    "    local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = K_num)\n",
    "\n",
    "    MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], covar_type = 'RQ', \n",
    "                                                                                     lr=0.05, num_iterations=10000, patience=10, device=Device)\n",
    "\n",
    "    preds = Prediction.preds_for_one_model(MultitaskGP_models, MultitaskGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_MGP)(row_idx, train_x, train_y, test_x, test_y) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "np.mean((full_test_preds_MGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN + MultiGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 100)\n",
    "\n",
    "MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_NNMultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], \n",
    "                                                                                   feature_extractor_class = FeatureE.FeatureExtractor_1, covar_type = 'RBF', \n",
    "                                                                                   lr=0.05, num_iterations=5000, patience=10, device = Device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_NNMGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "\n",
    "    input_point = test_y[row_idx,:]\n",
    "    local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = K_num)\n",
    "\n",
    "    NNMultitaskGP_models, NNMultitaskGP_likelihoods = Training.train_one_row_NNMultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], \n",
    "                                                                                            feature_extractor_class = FeatureE.FeatureExtractor_4, covar_type = 'RBF', \n",
    "                                                                                            lr=0.05, num_iterations=5000, patience=10, device = Device)\n",
    "\n",
    "    preds = Prediction.preds_for_one_model(NNMultitaskGP_models, NNMultitaskGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).squeeze().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        # preds = PCA_trans.inverse_transform(preds)\n",
    "        first_column = preds[0]\n",
    "        remaining_columns = preds[1:]\n",
    "        remaining_columns = PCA_trans.inverse_transform(remaining_columns)\n",
    "        preds = np.concatenate((first_column, remaining_columns), axis=1)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_NNMGP)(row_idx, train_x, train_y, test_x, test_y) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "MSE_NNMGP = np.mean((full_test_preds_MGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_NNMGP)(row_idx, train_x, train_y_21, test_x, test_y_21, PCA_trans = pca_20) for row_idx in range(test_y.shape[0]))\n",
    "# results = Parallel(n_jobs=-1)(delayed(train_and_predict_NNMGP)(row_idx, train_x, train_y_21, test_x, test_y_21) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "MSE_NNMGP_20 = np.mean((full_test_preds_MGP - test_y_21.numpy()) ** 2)\n",
    "MSE_NNMGP_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_NNMGP_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inducing_points = train_x[:600, :].to(Device)\n",
    "VGP_models, VGP_likelihoods = Training.train_full_VGP_Parallel(train_x, train_y_21, inducing_points, covar_type = 'RQ', lr=0.025, num_iterations=5000, patience=30, device=Device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_models, MVGP_likelihoods = Training.train_full_MultitaskVGP(train_x, train_y_21, \n",
    "                                                                 num_latents=12, num_inducing=100, \n",
    "                                                                 lr_hyper=0.05, lr_variational=0.05, num_iterations=5000, patience=50, device=Device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_preds_MVGP = Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, test_x.to(Device)).cpu().detach().numpy()\n",
    "np.mean((full_test_preds_MVGP.reshape(120,21) - test_y_21.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_preds_MVGP = pca_20.inverse_transform(full_test_preds_MVGP)\n",
    "MSE_MVGP = np.mean((full_test_preds_MVGP - test_y.numpy()) ** 2)\n",
    "MSE_MVGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device = 'cuda'\n",
    "DGP_2 = Training.train_full_DGP_2(train_x, train_y, num_hidden_dgp_dims = 10, inducing_num = 100, num_iterations = 5000, patiences = 50, device=Device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params, func_loss = Estimation.multi_start_estimation(MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, bounds, Estimation.estimate_params_for_one_model_Adam, \n",
    "                                                                num_starts=5, num_iterations=2000, lr=0.01, patience=10, \n",
    "                                                                attraction_threshold=0.1, repulsion_strength=0.1, device=Device)\n",
    "\n",
    "\n",
    "# full_estimated_params = estimated_params.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions.transforms as transforms\n",
    "from functools import partial\n",
    "\n",
    "def mcmc_model(Models, Likelihoods, row_idx, test_y, bounds, device):\n",
    "\n",
    "    device = torch.device(device)\n",
    "    bounds_tensor = torch.tensor(bounds, dtype=torch.float32, device=device)\n",
    "    n_params = bounds_tensor.size(0)\n",
    "    a = bounds_tensor[:, 0]\n",
    "    b = bounds_tensor[:, 1]\n",
    "\n",
    "    base_dist = dist.Normal(torch.zeros(n_params, device=device),\n",
    "                            torch.ones(n_params, device=device))\n",
    "    transform = transforms.ComposeTransform([\n",
    "        transforms.SigmoidTransform(),\n",
    "        transforms.AffineTransform(loc=a, scale=b - a)\n",
    "    ])\n",
    "    transformed_dist = dist.TransformedDistribution(base_dist, transform)\n",
    "    theta = pyro.sample('theta', transformed_dist)\n",
    "    \n",
    "\n",
    "\n",
    "    gp_value = Likelihoods(Models(theta.unsqueeze(0).to(device)))\n",
    "    # Pre_function(model_to_pass, likelihood_to_pass, theta.unsqueeze(0).to(device)).squeeze()\n",
    "    y_obs = test_y[row_idx].to(device)\n",
    "    \n",
    "    pyro.sample('obs', gp_value, obs=y_obs)\n",
    "\n",
    "def run_mcmc(Models, Likelihoods, row_idx, test_y, bounds,\n",
    "             num_sampling=2000, warmup_step=1000, num_chains=1, device='cpu',\n",
    "             jit_compile=True):\n",
    "    \"\"\"\n",
    "    将 mcmc_model 固定参数后传递给 NUTS 内核，运行 MCMC。\n",
    "    \"\"\"\n",
    "    model = partial(mcmc_model, Models, Likelihoods, row_idx, test_y, bounds, device)\n",
    "    \n",
    "    nuts_kernel = NUTS(model, jit_compile=jit_compile)\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=num_sampling, warmup_steps=warmup_step,\n",
    "                num_chains=num_chains)\n",
    "    mcmc.run()\n",
    "    return mcmc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result = Estimation.run_mcmc_Uniform(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, bounds, \n",
    "                                                  PCA_func = pca_20, \n",
    "                                                  num_sampling = 400, warmup_step = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result_Uniform = Estimation.run_mcmc_Uniform(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, bounds, \n",
    "                                                  PCA_func = pca_20, \n",
    "                                                  num_sampling = 400, warmup_step = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result_Normal = Estimation.run_mcmc_Normal(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, local_train_x, \n",
    "                                                 PCA_func = pca_20, \n",
    "                                                 num_sampling = 400, warmup_step = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = mcmc_result_Uniform.get_samples()\n",
    "\n",
    "param_names = [f'param_{i}' for i in range(len(bounds))]\n",
    "\n",
    "posterior_means_array = np.zeros(len(param_names))\n",
    "\n",
    "\n",
    "for idx, param_name in enumerate(param_names):\n",
    "    samples = posterior_samples[param_name]\n",
    "    if samples.ndim > 1:\n",
    "        samples = samples.reshape(-1)\n",
    "    mean_value = torch.mean(samples).item()\n",
    "    posterior_means_array[idx] = mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior_samples_Normal = mcmc_result_Uniform.get_samples()\n",
    "\n",
    "true_values = test_x[row_idx,:]\n",
    "\n",
    "point_estimations = posterior_means_array_tmp\n",
    "\n",
    "fig, axes = plt.subplots(len(posterior_samples_Uniform), 1, figsize=(8, len(posterior_samples_Uniform) * 3))\n",
    "\n",
    "for i, (param_name, samples) in enumerate(posterior_samples_Uniform.items()):\n",
    "    if len(posterior_samples_Uniform) > 1:\n",
    "        ax = axes[i]\n",
    "    else:\n",
    "        ax = axes\n",
    "    sns.kdeplot(samples.detach().numpy(), ax=ax, color='blue')\n",
    "    ax.set_title(f'Density of {param_name}')\n",
    "    \n",
    "    # 标记 true_values 和 point_estimations\n",
    "    if true_values is not None and i < len(true_values):\n",
    "        ax.axvline(true_values[i], color='red', linestyle='--', label='True Value')\n",
    "    if point_estimations is not None and i < len(point_estimations):\n",
    "        ax.axvline(point_estimations[i], color='green', linestyle='-.', label='Point Estimation')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **End**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for the Gaussian distribution\n",
    "mu = 0  # mean\n",
    "sigma = 1  # standard deviation\n",
    "\n",
    "# Generate random samples from the Gaussian distribution\n",
    "x = np.random.normal(mu, sigma, 10000)\n",
    "# x = np.random.uniform(mu, sigma, 10000)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(x, bins=30, density=True, alpha=0.6, color='b', edgecolor='black')\n",
    "\n",
    "\n",
    "# Labeling the plot\n",
    "\n",
    "plt.xlabel(\"X values\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the affine transformation function\n",
    "def affine_transform(x, loc=1.3, scale=2.6):\n",
    "    return loc + scale * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sigmoid transform to the generated data\n",
    "# x_1 = affine_transform(x,3,1.5)\n",
    "x_2 = sigmoid(x)\n",
    "x_transformed = affine_transform(x_2)\n",
    "\n",
    "# Plot the transformed distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(x_transformed, bins=30, density=True, alpha=0.6, color='b', edgecolor='black')\n",
    "\n",
    "# Labeling the plot\n",
    "plt.xlabel(\"Transformed X values\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 400)\n",
    "\n",
    "# 假设x是已知数据\n",
    "x = local_train_x[:,3] \n",
    "\n",
    "# 1. 绘制直方图\n",
    "plt.hist(x, bins=30, density=True, alpha=0.6, color='g')\n",
    "\n",
    "# 2. 尝试拟合正态分布\n",
    "mu, std = stats.norm.fit(x)\n",
    "\n",
    "# 3. 绘制拟合的正态分布曲线\n",
    "xmin, xmax = plt.xlim()\n",
    "x_plot = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x_plot, mu, std)\n",
    "plt.plot(x_plot, p, 'k', linewidth=2)\n",
    "title = f\"Fit results: mu = {mu:.2f}, std = {std:.2f}\"\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "# 4. 生成与数据类似的随机数\n",
    "random_data = np.random.normal(mu, std, len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x[0,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
