{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from linear_operator import settings\n",
    "\n",
    "import pyro\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import arviz as az\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GP_functions.Loss_function as Loss_function\n",
    "import GP_functions.bound as bound\n",
    "import GP_functions.Estimation as Estimation\n",
    "import GP_functions.Training as Training\n",
    "import GP_functions.Prediction as Prediction\n",
    "import GP_functions.GP_models as GP_models\n",
    "import GP_functions.Tools as Tools\n",
    "import GP_functions.FeatureE as FeatureE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/X_train.csv', header=None, delimiter=',').values\n",
    "X_test = pd.read_csv('Data/X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_8 = pd.read_csv('Data/Y_train_8.csv', header=None, delimiter=',').values\n",
    "Y_test_8 = pd.read_csv('Data/Y_test_8.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_20 = pd.read_csv('Data/Y_train_20.csv', header=None, delimiter=',').values\n",
    "Y_test_20 = pd.read_csv('Data/Y_test_20.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('Data/Y_train_std.csv', header=None, delimiter=',').values\n",
    "Y_test_std = pd.read_csv('Data/Y_test_std.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(X_train, dtype=torch.float32)\n",
    "test_x = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "train_y_8 = torch.tensor(Y_train_8, dtype=torch.float32)\n",
    "test_y_8 = torch.tensor(Y_test_8, dtype=torch.float32)\n",
    "\n",
    "train_y_20 = torch.tensor(Y_train_20, dtype=torch.float32)\n",
    "test_y_20 = torch.tensor(Y_test_20, dtype=torch.float32)\n",
    "\n",
    "train_y = torch.tensor(Y_train_std, dtype=torch.float32)\n",
    "test_y = torch.tensor(Y_test_std, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_8 = PCA(n_components = 8)\n",
    "pca_20 = PCA(n_components = 20)\n",
    "\n",
    "pca_8.fit(Y_train_std)\n",
    "pca_20.fit(Y_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 100)\n",
    "\n",
    "bounds = bound.get_bounds(local_train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LocalGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_LocalGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "    LocalGP_models, LocalGP_likelihoods = Training.train_one_row_LocalGP(\n",
    "        train_x, train_y, test_y, row_idx, k_num=K_num, lr=0.05, num_iterations=5000, patience=10, device=Device\n",
    "    )\n",
    "    \n",
    "    preds = Prediction.full_preds(LocalGP_models, LocalGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).cpu().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_LocalGP)(row_idx, train_x, train_y_20, test_x, test_y_20, PCA_trans = pca_20) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_LocalGP = np.vstack(results)\n",
    "\n",
    "MSE_LocalGP = np.mean((full_test_preds_LocalGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y_20[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y_20, k = 100)\n",
    "\n",
    "\n",
    "MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP(local_train_x, local_train_y, n_tasks = local_train_y.shape[1], \n",
    "                                                                                 covar_type = 'RQ', lr=0.05, num_iterations=5000, patience=10, device=Device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y_20[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y_20, k = 100)\n",
    "\n",
    "MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP_lcm(local_train_x, local_train_y, n_tasks = local_train_y.shape[1], \n",
    "                                                                                     lr=0.05, num_iterations=5000, patience=10, device=Device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_MGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "\n",
    "    input_point = test_y[row_idx,:]\n",
    "    local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = K_num)\n",
    "\n",
    "    MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], covar_type = 'RQ', \n",
    "                                                                                     lr=0.05, num_iterations=10000, patience=10, device=Device)\n",
    "\n",
    "    preds = Prediction.preds_for_one_model(MultitaskGP_models, MultitaskGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).squeeze().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_MGP_lcm(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "\n",
    "    input_point = test_y[row_idx,:]\n",
    "    local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = K_num)\n",
    "\n",
    "    MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP_lcm(local_train_x, local_train_y, n_tasks = train_y.shape[1], \n",
    "                                                                                         lr=0.05, num_iterations=10000, patience=10, device=Device)\n",
    "\n",
    "    preds = Prediction.preds_for_one_model(MultitaskGP_models, MultitaskGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).squeeze().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_MGP)(row_idx, train_x, train_y_20, test_x, test_y_20, PCA_trans = pca_20) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "np.mean((full_test_preds_MGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN + MultiGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 100)\n",
    "\n",
    "MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_NNMultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], \n",
    "                                                                                            feature_extractor_class = FeatureE.FeatureExtractor_1, covar_type = 'RBF', \n",
    "                                                                                            lr=0.05, num_iterations=5000, patience=10, device = Device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_NNMGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "\n",
    "    input_point = test_y[row_idx,:]\n",
    "    local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = K_num)\n",
    "\n",
    "    NNMultitaskGP_models, NNMultitaskGP_likelihoods = Training.train_one_row_NNMultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], \n",
    "                                                                                            feature_extractor_class = FeatureE.FeatureExtractor_1, covar_type = 'RBF', \n",
    "                                                                                            lr=0.05, num_iterations=5000, patience=10, device = Device)\n",
    "\n",
    "    preds = Prediction.preds_for_one_model(NNMultitaskGP_models, NNMultitaskGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).squeeze().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_NNMGP)(row_idx, train_x, train_y, test_x, test_y) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "MSE_NNMGP = np.mean((full_test_preds_MGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_NNMGP)(row_idx, train_x, train_y_20, test_x, test_y_20, PCA_trans = pca_20) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "MSE_NNMGP_20 = np.mean((full_test_preds_MGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inducing_points = train_x[:600, :].to(Device)\n",
    "VGP_models, VGP_likelihoods = Training.train_full_VGP_Parallel(train_x, train_y_20, inducing_points, covar_type = 'RQ', lr=0.025, num_iterations=5000, patience=30, device=Device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_models, MVGP_likelihoods = Training.train_full_MultitaskVGP(train_x, train_y_20, num_latents=8, num_inducing=1000, lr_hyper=0.05, lr_variational=0.05, num_iterations=5000, patience=50, device=Device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_preds_MVGP = Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, test_x.to(Device)).cpu().detach().numpy()\n",
    "np.mean((full_test_preds_MVGP - test_y_20.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_preds_MVGP = pca_20.inverse_transform(full_test_preds_MVGP)\n",
    "MSE_MVGP = np.mean((full_test_preds_MVGP - test_y.numpy()) ** 2)\n",
    "MSE_MVGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device = 'cuda'\n",
    "DGP_2 = Training.train_full_DGP_2(train_x, train_y, num_hidden_dgp_dims = 20, inducing_num = 400, num_iterations = 5000, patiences = 50, device=Device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params, func_loss = Estimation.multi_start_estimation(MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, bounds, Estimation.estimate_params_for_one_model_Adam, \n",
    "                                                                num_starts=5, num_iterations=2000, lr=0.01, patience=10, \n",
    "                                                                attraction_threshold=0.1, repulsion_strength=0.1, device=Device)\n",
    "\n",
    "\n",
    "# full_estimated_params = estimated_params.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result_Uniform = Estimation.run_mcmc_Uniform(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, bounds, \n",
    "                                                 PCA_func = pca_20, \n",
    "                                                 num_sampling = 2000, warmup_step = 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result_Normal = Estimation.run_mcmc_Normal(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, local_train_x, \n",
    "                                                 PCA_func = pca_20, \n",
    "                                                 num_sampling = 2000, warmup_step = 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result_Normal_20 = Estimation.run_mcmc_Normal(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y_20, local_train_x, \n",
    "                                                #  PCA_func = pca_20, \n",
    "                                                 num_sampling = 2000, warmup_step = 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result = Estimation.run_mcmc(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, bounds, \n",
    "                                  PCA_func = pca_20, \n",
    "                                  num_sampling = 2000, warmup_step = 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = mcmc_result.get_samples()\n",
    "\n",
    "param_names = [f'param_{i}' for i in range(len(bounds))]\n",
    "\n",
    "posterior_means_array = np.zeros(len(param_names))\n",
    "\n",
    "\n",
    "for idx, param_name in enumerate(param_names):\n",
    "    samples = posterior_samples[param_name]\n",
    "    if samples.ndim > 1:\n",
    "        samples = samples.reshape(-1)\n",
    "    mean_value = torch.mean(samples).item()\n",
    "    posterior_means_array[idx] = mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples_Normal = mcmc_result_Normal.get_samples()\n",
    "\n",
    "true_values = test_x[row_idx,:]\n",
    "\n",
    "point_estimations = posterior_means_array\n",
    "\n",
    "fig, axes = plt.subplots(len(posterior_samples_Normal), 1, figsize=(8, len(posterior_samples_Normal) * 3))\n",
    "\n",
    "for i, (param_name, samples) in enumerate(posterior_samples_Normal.items()):\n",
    "    if len(posterior_samples_Normal) > 1:\n",
    "        ax = axes[i]\n",
    "    else:\n",
    "        ax = axes\n",
    "    sns.kdeplot(samples.detach().numpy(), ax=ax, color='blue')\n",
    "    ax.set_title(f'Density of {param_name}')\n",
    "    \n",
    "    # 标记 true_values 和 point_estimations\n",
    "    if true_values is not None and i < len(true_values):\n",
    "        ax.axvline(true_values[i], color='red', linestyle='--', label='True Value')\n",
    "    if point_estimations is not None and i < len(point_estimations):\n",
    "        ax.axvline(point_estimations[i], color='green', linestyle='-.', label='Point Estimation')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **End**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for the Gaussian distribution\n",
    "mu = 0  # mean\n",
    "sigma = 1  # standard deviation\n",
    "\n",
    "# Generate random samples from the Gaussian distribution\n",
    "x = np.random.normal(mu, sigma, 10000)\n",
    "# x = np.random.uniform(mu, sigma, 10000)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(x, bins=30, density=True, alpha=0.6, color='b', edgecolor='black')\n",
    "\n",
    "\n",
    "# Labeling the plot\n",
    "\n",
    "plt.xlabel(\"X values\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the affine transformation function\n",
    "def affine_transform(x, loc=1.3, scale=2.6):\n",
    "    return loc + scale * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sigmoid transform to the generated data\n",
    "# x_1 = affine_transform(x,3,1.5)\n",
    "x_2 = sigmoid(x)\n",
    "x_transformed = affine_transform(x_2)\n",
    "\n",
    "# Plot the transformed distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(x_transformed, bins=30, density=True, alpha=0.6, color='b', edgecolor='black')\n",
    "\n",
    "# Labeling the plot\n",
    "plt.xlabel(\"Transformed X values\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 400)\n",
    "\n",
    "# 假设x是已知数据\n",
    "x = local_train_x[:,3] \n",
    "\n",
    "# 1. 绘制直方图\n",
    "plt.hist(x, bins=30, density=True, alpha=0.6, color='g')\n",
    "\n",
    "# 2. 尝试拟合正态分布\n",
    "mu, std = stats.norm.fit(x)\n",
    "\n",
    "# 3. 绘制拟合的正态分布曲线\n",
    "xmin, xmax = plt.xlim()\n",
    "x_plot = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x_plot, mu, std)\n",
    "plt.plot(x_plot, p, 'k', linewidth=2)\n",
    "title = f\"Fit results: mu = {mu:.2f}, std = {std:.2f}\"\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "# 4. 生成与数据类似的随机数\n",
    "random_data = np.random.normal(mu, std, len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x[0,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
