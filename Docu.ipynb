{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "from linear_operator import settings\n",
    "\n",
    "import pyro\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GP_functions.Loss_function as Loss_function\n",
    "import GP_functions.bound as bound\n",
    "import GP_functions.Estimation as Estimation\n",
    "import GP_functions.Training as Training\n",
    "import GP_functions.Prediction as Prediction\n",
    "import GP_functions.GP_models as GP_models\n",
    "import GP_functions.Tools as Tools\n",
    "import GP_functions.FeatureE as FeatureE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/X_train.csv', header=None, delimiter=',').values\n",
    "X_test = pd.read_csv('Data/X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "# Y_train_8 = pd.read_csv('Data/Y_train_8.csv', header=None, delimiter=',').values\n",
    "# Y_test_8 = pd.read_csv('Data/Y_test_8.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_21 = pd.read_csv('Data/Y_train_std_21.csv', header=None, delimiter=',').values\n",
    "Y_test_21 = pd.read_csv('Data/Y_test_std_21.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('Data/Y_train_std.csv', header=None, delimiter=',').values\n",
    "Y_test_std = pd.read_csv('Data/Y_test_std.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(X_train, dtype=torch.float32)\n",
    "test_x = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# train_y_8 = torch.tensor(Y_train_8, dtype=torch.float32)\n",
    "# test_y_8 = torch.tensor(Y_test_8, dtype=torch.float32)\n",
    "\n",
    "train_y_21 = torch.tensor(Y_train_21, dtype=torch.float32)\n",
    "test_y_21 = torch.tensor(Y_test_21, dtype=torch.float32)\n",
    "\n",
    "train_y = torch.tensor(Y_train_std, dtype=torch.float32)\n",
    "test_y = torch.tensor(Y_test_std, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_20 = PCA(n_components = 20)\n",
    "\n",
    "pca_20.fit(train_y[:,1:])\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_num_threads(8)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 100)\n",
    "\n",
    "bounds = bound.get_bounds(local_train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LocalGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'Result/LocalGP_21_result.csv'\n",
    "\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('Iteration,test_preds,estimated_params,posterior_means\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "\n",
    "input_point = test_y_21[row_idx, :]\n",
    "\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y_21, k=100)\n",
    "\n",
    "LocalGP_models, LocalGP_likelihoods = Training.train_one_row_LocalGP_Parallel(\n",
    "    train_x, train_y_21, test_y_21, row_idx,\n",
    "    covar_type='RBF', k_num=100, lr=0.025,\n",
    "    num_iterations=5000, patience=10, device=Device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tmp = Prediction.full_preds(\n",
    "    LocalGP_models, LocalGP_likelihoods, test_x[row_idx, :].unsqueeze(0).to(Device)\n",
    ").cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "estimated_params_tmp, _ = Estimation.multi_start_estimation(\n",
    "    LocalGP_models, LocalGP_likelihoods, row_idx, test_y_21, bounds,\n",
    "    Estimation.estimate_params_Adam, num_starts=5, num_iterations=2000, lr=0.01,\n",
    "    patience=50, attraction_threshold=0.1, repulsion_strength=0.1, device=Device\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = bound.get_bounds(local_train_x)\n",
    "params = []\n",
    "\n",
    "for i, (min_val, max_val) in enumerate(bounds):\n",
    "    param_i = pyro.sample(f'param_{i}', dist.Uniform(min_val, max_val))\n",
    "    params.append(param_i)\n",
    "\n",
    "theta = torch.stack(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(torch.tensor(b[0], dtype=torch.float32), torch.tensor(b[1], dtype=torch.float32)) for b in bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for i, (min_val, max_val) in enumerate(bounds):\n",
    "    param_i = pyro.sample(f'param_{i}', dist.Uniform(min_val, max_val))\n",
    "    params.append(param_i)\n",
    "\n",
    "theta = torch.stack(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate(\"params\", len(bounds)):\n",
    "    min_vals = torch.tensor([b[0].item() for b in bounds], dtype=torch.float32)\n",
    "    max_vals = torch.tensor([b[1].item() for b in bounds], dtype=torch.float32)\n",
    "    params = pyro.sample(\"params\", dist.Uniform(min_vals, max_vals).to_event(1))\n",
    "    print(f\"Sampled params: {params}\")\n",
    "\n",
    "theta = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "with pyro.plate(\"params\", len(bounds)):\n",
    "    for i, (min_val, max_val) in enumerate(bounds):\n",
    "        param_i = pyro.sample(f\"param_{i}\", dist.Uniform(min_val, max_val))\n",
    "        params.append(param_i)\n",
    "theta = torch.stack(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_func = pca_20\n",
    "num_sampling=200\n",
    "warmup_step=100\n",
    "num_chains=1\n",
    "\n",
    "\n",
    "\n",
    "bounds = [(torch.tensor(b[0], dtype=torch.float32), torch.tensor(b[1], dtype=torch.float32)) for b in bounds]\n",
    "\n",
    "if PCA_func != 'None':\n",
    "    components = torch.from_numpy(PCA_func.components_).to(dtype=torch.float32)\n",
    "    mean_PCA = torch.from_numpy(PCA_func.mean_).to(dtype=torch.float32)\n",
    "\n",
    "@torch.compile\n",
    "def model():\n",
    "\n",
    "    params = []\n",
    "    for i, (min_val, max_val) in enumerate(bounds):\n",
    "        param_i = pyro.sample(f'param_{i}', dist.Uniform(min_val, max_val))\n",
    "        params.append(param_i)\n",
    "    \n",
    "    theta = torch.stack(params)\n",
    "\n",
    "    sigma = pyro.sample('sigma', dist.HalfNormal(10.0))\n",
    "\n",
    "    if PCA_func == 'None':\n",
    "        mu_value = Prediction.full_preds(LocalGP_models, LocalGP_likelihoods, theta.unsqueeze(0)).view(-1)\n",
    "    else:\n",
    "        preds = Prediction.full_preds(LocalGP_models, LocalGP_likelihoods, theta.unsqueeze(0))\n",
    "        first_col = preds[0].view(-1)\n",
    "        remaining_cols = preds[1:].view(-1)\n",
    "        processed_cols = (torch.matmul(remaining_cols, components) + mean_PCA)\n",
    "        mu_value = torch.cat([first_col.unsqueeze(1), processed_cols.unsqueeze(0)], dim=1).view(-1)\n",
    "\n",
    "    y_obs = test_y[row_idx, :]\n",
    "    pyro.sample('obs', dist.Normal(mu_value, sigma), obs=y_obs)\n",
    "\n",
    "nuts_kernel = NUTS(model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=num_sampling, warmup_steps=warmup_step, num_chains=num_chains)\n",
    "mcmc.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.config.verbose = True\n",
    "mcmc_result_Uniform = Estimation.run_mcmc_Uniform(\n",
    "    Prediction.full_preds, LocalGP_models, LocalGP_likelihoods, \n",
    "    row_idx, test_y, bounds, \n",
    "    PCA_func=pca_20, \n",
    "    num_sampling=400, warmup_step=100, num_chains=1\n",
    ")\n",
    "posterior_samples_Uniform = mcmc_result_Uniform.get_samples()\n",
    "\n",
    "param_names = [f'param_{i}' for i in range(len(bounds))]\n",
    "posterior_means_array_tmp = np.zeros(len(param_names))\n",
    "\n",
    "for idx, param_name in enumerate(param_names):\n",
    "    samples = posterior_samples_Uniform[param_name]\n",
    "    if samples.ndim > 1:\n",
    "        samples = samples.reshape(-1)\n",
    "    posterior_means_array_tmp[idx] = torch.mean(samples).item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior_samples_Uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'a') as f:\n",
    "    f.write(f\"{row_idx + 1},\\\"{list(preds_tmp)}\\\",\\\"{list(estimated_params_tmp.detach().numpy())}\\\",\\\"{list(posterior_means_array_tmp)}\\\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_LocalGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "    LocalGP_models, LocalGP_likelihoods = Training.train_one_row_LocalGP(\n",
    "        train_x, train_y, test_y, row_idx, covar_type = 'RQ', k_num=K_num, lr=0.05, num_iterations=5000, patience=10, device=Device\n",
    "    )\n",
    "    \n",
    "    preds = Prediction.full_preds(LocalGP_models, LocalGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).cpu().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_LocalGP)(row_idx, train_x, train_y_20, test_x, test_y_20, PCA_trans = pca_20) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_LocalGP = np.vstack(results)\n",
    "\n",
    "MSE_LocalGP = np.mean((full_test_preds_LocalGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_LocalGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_LocalGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y_21[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y_21, k = 100)\n",
    "\n",
    "\n",
    "MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP(local_train_x, local_train_y, n_tasks = local_train_y.shape[1], \n",
    "                                                                                 covar_type = 'RBF', lr=0.05, num_iterations=5000, patience=10, device=Device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction.preds_for_one_model(MultitaskGP_models, MultitaskGP_likelihoods, theta.unsqueeze(0)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_MGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "\n",
    "    input_point = test_y[row_idx,:]\n",
    "    local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = K_num)\n",
    "\n",
    "    MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], covar_type = 'RQ', \n",
    "                                                                                     lr=0.05, num_iterations=10000, patience=10, device=Device)\n",
    "\n",
    "    preds = Prediction.preds_for_one_model(MultitaskGP_models, MultitaskGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_MGP_lcm(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "\n",
    "    input_point = test_y[row_idx,:]\n",
    "    local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = K_num)\n",
    "\n",
    "    MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_MultitaskGP_lcm(local_train_x, local_train_y, n_tasks = train_y.shape[1], \n",
    "                                                                                         lr=0.05, num_iterations=10000, patience=10, device=Device)\n",
    "\n",
    "    preds = Prediction.preds_for_one_model(MultitaskGP_models, MultitaskGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).squeeze().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_MGP)(row_idx, train_x, train_y_20, test_x, test_y_20, PCA_trans = pca_20) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "np.mean((full_test_preds_MGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN + MultiGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 100)\n",
    "\n",
    "MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_NNMultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], \n",
    "                                                                                   feature_extractor_class = FeatureE.FeatureExtractor_1, covar_type = 'RBF', \n",
    "                                                                                   lr=0.05, num_iterations=5000, patience=10, device = Device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_NNMGP(row_idx, train_x, train_y, test_x, test_y, K_num = 100, Device = 'cpu', PCA_trans = 'None'):\n",
    "\n",
    "\n",
    "    input_point = test_y[row_idx,:]\n",
    "    local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = K_num)\n",
    "\n",
    "    NNMultitaskGP_models, NNMultitaskGP_likelihoods = Training.train_one_row_NNMultitaskGP(local_train_x, local_train_y, n_tasks = train_y.shape[1], \n",
    "                                                                                            feature_extractor_class = FeatureE.FeatureExtractor_1, covar_type = 'RBF', \n",
    "                                                                                            lr=0.05, num_iterations=5000, patience=10, device = Device)\n",
    "\n",
    "    preds = Prediction.preds_for_one_model(NNMultitaskGP_models, NNMultitaskGP_likelihoods, test_x[row_idx,:].unsqueeze(0).to(Device)).squeeze().detach().numpy()\n",
    "    if PCA_trans != 'None':\n",
    "        preds = PCA_trans.inverse_transform(preds)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_NNMGP)(row_idx, train_x, train_y, test_x, test_y) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "MSE_NNMGP = np.mean((full_test_preds_MGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(delayed(train_and_predict_NNMGP)(row_idx, train_x, train_y_20, test_x, test_y_20, PCA_trans = pca_20) for row_idx in range(test_y.shape[0]))\n",
    "full_test_preds_MGP = np.vstack(results)\n",
    "\n",
    "\n",
    "MSE_NNMGP_20 = np.mean((full_test_preds_MGP - test_y.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inducing_points = train_x[:600, :].to(Device)\n",
    "VGP_models, VGP_likelihoods = Training.train_full_VGP_Parallel(train_x, train_y_21, inducing_points, covar_type = 'RQ', lr=0.025, num_iterations=5000, patience=30, device=Device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_models, MVGP_likelihoods = Training.train_full_MultitaskVGP(train_x, train_y_21, \n",
    "                                                                 num_latents=12, num_inducing=100, \n",
    "                                                                 lr_hyper=0.05, lr_variational=0.05, num_iterations=5000, patience=50, device=Device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_models, MVGP_likelihoods = Training.train_full_MultitaskVGP(train_x, train_y_21, \n",
    "                                                                 num_latents=10, lr_hyper=0.01, k=256, training_batch_size=256, \n",
    "                                                                 num_iterations=50, patience=10, device=Device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_preds_MVGP = Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, test_x.to(Device)).cpu().detach().numpy()\n",
    "np.mean((full_test_preds_MVGP.reshape(120,21) - test_y_21.numpy()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_preds_MVGP = pca_20.inverse_transform(full_test_preds_MVGP)\n",
    "MSE_MVGP = np.mean((full_test_preds_MVGP - test_y.numpy()) ** 2)\n",
    "MSE_MVGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device = 'cuda'\n",
    "DGP_2 = Training.train_full_DGP_2(train_x, train_y, num_hidden_dgp_dims = 10, inducing_num = 100, num_iterations = 5000, patiences = 50, device=Device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params, func_loss = Estimation.multi_start_estimation(MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, bounds, Estimation.estimate_params_for_one_model_Adam, \n",
    "                                                                num_starts=5, num_iterations=2000, lr=0.01, patience=10, \n",
    "                                                                attraction_threshold=0.1, repulsion_strength=0.1, device=Device)\n",
    "\n",
    "\n",
    "# full_estimated_params = estimated_params.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions.transforms as transforms\n",
    "\n",
    "def mcmc_model(Pre_function, Models, Likelihoods, row_idx, test_y, bounds, device):\n",
    "    \"\"\"\n",
    "    顶层定义的模型函数。\n",
    "    对传入的 Models 和 Likelihoods 进行冻结处理，并在调用 Pre_function 时确保传入单个模型和似然函数。\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "    bounds_tensor = torch.tensor(bounds, dtype=torch.float32, device=device)\n",
    "    n_params = bounds_tensor.size(0)\n",
    "    a = bounds_tensor[:, 0]\n",
    "    b = bounds_tensor[:, 1]\n",
    "\n",
    "    # 定义潜变量 theta 的先验：经过 Sigmoid 和 Affine 变换\n",
    "    base_dist = dist.Normal(torch.zeros(n_params, device=device),\n",
    "                            torch.ones(n_params, device=device))\n",
    "    transform = transforms.ComposeTransform([\n",
    "        transforms.SigmoidTransform(),\n",
    "        transforms.AffineTransform(loc=a, scale=b - a)\n",
    "    ])\n",
    "    transformed_dist = dist.TransformedDistribution(base_dist, transform)\n",
    "    theta = pyro.sample('theta', transformed_dist)\n",
    "    \n",
    "\n",
    "\n",
    "    # 在调用预测函数前，尝试清空模型缓存，避免使用带梯度的输入作为 key\n",
    "    if hasattr(model_to_pass, \"prediction_strategy\"):\n",
    "        model_to_pass.prediction_strategy = None\n",
    "\n",
    "    # 在 gpytorch 的上下文中禁用缓存（如果有效）\n",
    "    with gp_settings.fast_pred_var(False):\n",
    "        mu_value = Pre_function(model_to_pass, likelihood_to_pass, theta.unsqueeze(0).to(device)).squeeze()\n",
    "    y_obs = test_y[row_idx].to(device)\n",
    "    \n",
    "    pyro.sample('obs', dist.Normal(mu_value, sigma), obs=y_obs)\n",
    "\n",
    "def run_mcmc(Pre_function, Models, Likelihoods, row_idx, test_y, bounds,\n",
    "             num_sampling=2000, warmup_step=1000, num_chains=1, device='cpu',\n",
    "             jit_compile=True):\n",
    "    \"\"\"\n",
    "    将 mcmc_model 固定参数后传递给 NUTS 内核，运行 MCMC。\n",
    "    \"\"\"\n",
    "    model = partial(mcmc_model, Pre_function, Models, Likelihoods, row_idx, test_y, bounds, device)\n",
    "    \n",
    "    nuts_kernel = NUTS(model, jit_compile=jit_compile)\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=num_sampling, warmup_steps=warmup_step,\n",
    "                num_chains=num_chains)\n",
    "    mcmc.run()\n",
    "    return mcmc\n",
    "\n",
    "\n",
    "def run_mcmc_Uniform(Pre_function, Models, Likelihoods, row_idx, test_y, bounds, PCA_func='None', num_sampling=2000, warmup_step=1000, num_chains=1):\n",
    "    test_y = test_y.to(dtype=torch.float32)\n",
    "    bounds = [(torch.tensor(b[0], dtype=torch.float32), torch.tensor(b[1], dtype=torch.float32)) for b in bounds]\n",
    "\n",
    "    if PCA_func != 'None':\n",
    "        components = torch.from_numpy(PCA_func.components_).to(dtype=torch.float32)\n",
    "        mean_PCA = torch.from_numpy(PCA_func.mean_).to(dtype=torch.float32)\n",
    "    \n",
    "    def model():\n",
    "\n",
    "        params = []\n",
    "        for i, (min_val, max_val) in enumerate(bounds):\n",
    "            param_i = pyro.sample(f'param_{i}', dist.Uniform(min_val, max_val))\n",
    "            params.append(param_i)\n",
    "        \n",
    "        theta = torch.stack(params)\n",
    "\n",
    "        sigma = pyro.sample('sigma', dist.HalfNormal(10.0))\n",
    "\n",
    "        if PCA_func == 'None':\n",
    "            mu_value = Pre_function(Models, Likelihoods, theta.unsqueeze(0)).view(-1)\n",
    "        else:\n",
    "            preds = Pre_function(Models, Likelihoods, theta.unsqueeze(0))\n",
    "            first_col = preds[0].view(-1)\n",
    "            remaining_cols = preds[1:].view(-1)\n",
    "            processed_cols = (torch.matmul(remaining_cols, components) + mean_PCA)\n",
    "            mu_value = torch.cat([first_col.unsqueeze(1), processed_cols.unsqueeze(0)], dim=1).view(-1)\n",
    "\n",
    "        y_obs = test_y[row_idx, :]\n",
    "        pyro.sample('obs', dist.Normal(mu_value, sigma), obs=y_obs)\n",
    "\n",
    "    nuts_kernel = NUTS(model)\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=num_sampling, warmup_steps=warmup_step, num_chains=num_chains)\n",
    "    mcmc.run()\n",
    "\n",
    "    return mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/500 [00:00, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x0 and 20x51)\nTrace Shapes:  \n Param Sites:  \nSample Sites:  \n param_0 dist |\n        value |\n param_1 dist |\n        value |\n param_2 dist |\n        value |\n param_3 dist |\n        value |\n param_4 dist |\n        value |\n param_5 dist |\n        value |\n param_6 dist |\n        value |\n param_7 dist |\n        value |\n param_8 dist |\n        value |\n param_9 dist |\n        value |\n   sigma dist |\n        value |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:191\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Multioutput_FixedG_GP/GP_functions/Estimation.py:377\u001b[0m, in \u001b[0;36mrun_mcmc_Uniform.<locals>.model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    376\u001b[0m remaining_cols \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 377\u001b[0m processed_cols \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m mean_PCA)\n\u001b[1;32m    378\u001b[0m mu_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([first_col\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), processed_cols\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x0 and 20x51)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mcmc_result_Uniform \u001b[38;5;241m=\u001b[39m \u001b[43mEstimation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mcmc_Uniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPrediction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreds_for_one_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMultitaskGP_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMultitaskGP_likelihoods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mPCA_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpca_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mnum_sampling\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Multioutput_FixedG_GP/GP_functions/Estimation.py:385\u001b[0m, in \u001b[0;36mrun_mcmc_Uniform\u001b[0;34m(Pre_function, Models, Likelihoods, row_idx, test_y, bounds, PCA_func, num_sampling, warmup_step, num_chains)\u001b[0m\n\u001b[1;32m    383\u001b[0m nuts_kernel \u001b[38;5;241m=\u001b[39m NUTS(model)\n\u001b[1;32m    384\u001b[0m mcmc \u001b[38;5;241m=\u001b[39m MCMC(nuts_kernel, num_samples\u001b[38;5;241m=\u001b[39mnum_sampling, warmup_steps\u001b[38;5;241m=\u001b[39mwarmup_step, num_chains\u001b[38;5;241m=\u001b[39mnum_chains)\n\u001b[0;32m--> 385\u001b[0m \u001b[43mmcmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mcmc\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/poutine/messenger.py:32\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_context_wrap\u001b[39m(\n\u001b[1;32m     26\u001b[0m     context: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessenger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     fn: Callable,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39margs: Any,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/api.py:565\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optional(\n\u001b[1;32m    557\u001b[0m     pyro\u001b[38;5;241m.\u001b[39mvalidation_enabled(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_validation),\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_validation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;66;03m# This also resolves \"RuntimeError: Cowardly refusing to serialize non-leaf tensor which\u001b[39;00m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;66;03m# requires_grad\", which happens with `jit_compile` under PyTorch 1.7\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     args \u001b[38;5;241m=\u001b[39m [arg\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(arg) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, chain_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m num_samples[chain_id] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    567\u001b[0m             num_samples[chain_id] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/api.py:225\u001b[0m, in \u001b[0;36m_UnarySampler.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m logger \u001b[38;5;241m=\u001b[39m initialize_logger(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, progress_bar)\n\u001b[1;32m    224\u001b[0m hook_w_logging \u001b[38;5;241m=\u001b[39m _add_logging_hook(logger, progress_bar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m _gen_samples(\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel,\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarmup_steps,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples,\n\u001b[1;32m    229\u001b[0m     hook_w_logging,\n\u001b[1;32m    230\u001b[0m     i \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_chains \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    233\u001b[0m ):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m sample, i  \u001b[38;5;66;03m# sample, chain_id\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/api.py:146\u001b[0m, in \u001b[0;36m_gen_samples\u001b[0;34m(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gen_samples\u001b[39m(kernel, warmup_steps, num_samples, hook, chain_id, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 146\u001b[0m     \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     params \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39minitial_params\n\u001b[1;32m    148\u001b[0m     save_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(kernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_params\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msorted\u001b[39m(params))\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/hmc.py:345\u001b[0m, in \u001b[0;36mHMC.setup\u001b[0;34m(self, warmup_steps, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warmup_steps \u001b[38;5;241m=\u001b[39m warmup_steps\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_model_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_params:\n\u001b[1;32m    347\u001b[0m     z \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_params\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/hmc.py:279\u001b[0m, in \u001b[0;36mHMC._initialize_model_properties\u001b[0;34m(self, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_model_properties\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_args, model_kwargs):\n\u001b[0;32m--> 279\u001b[0m     init_params, potential_fn, transforms, trace \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_plate_nesting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_plate_nesting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjit_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_jit_warnings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ignore_jit_warnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpotential_fn \u001b[38;5;241m=\u001b[39m potential_fn\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/util.py:427\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(model, model_args, model_kwargs, transforms, max_plate_nesting, jit_compile, jit_options, skip_jit_warnings, num_chains, init_strategy, initial_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     automatic_transform_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_plate_nesting \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     max_plate_nesting \u001b[38;5;241m=\u001b[39m \u001b[43m_guess_max_plate_nesting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Wrap model in `poutine.enum` to enumerate over discrete latent sites.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# No-op if model does not have any discrete latents.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m model \u001b[38;5;241m=\u001b[39m poutine\u001b[38;5;241m.\u001b[39menum(\n\u001b[1;32m    431\u001b[0m     config_enumerate(model), first_available_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m max_plate_nesting\n\u001b[1;32m    432\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/util.py:251\u001b[0m, in \u001b[0;36m_guess_max_plate_nesting\u001b[0;34m(model, args, kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03mGuesses max_plate_nesting by running the model once\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mwithout enumeration. This optimistically assumes static model\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mstructure.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mblock():\n\u001b[0;32m--> 251\u001b[0m     model_trace \u001b[38;5;241m=\u001b[39m \u001b[43mpoutine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m sites \u001b[38;5;241m=\u001b[39m [site \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m model_trace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    254\u001b[0m dims \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    255\u001b[0m     frame\u001b[38;5;241m.\u001b[39mdim\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m sites\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond_indep_stack\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame\u001b[38;5;241m.\u001b[39mvectorized\n\u001b[1;32m    259\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:216\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Trace:\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         exc \u001b[38;5;241m=\u001b[39m exc_type(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    197\u001b[0m         exc \u001b[38;5;241m=\u001b[39m exc\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 198\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_RETURN\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_RETURN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39mret\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:191\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    193\u001b[0m     exc_type, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/Multioutput_FixedG_GP/GP_functions/Estimation.py:377\u001b[0m, in \u001b[0;36mrun_mcmc_Uniform.<locals>.model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    375\u001b[0m     first_col \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    376\u001b[0m     remaining_cols \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 377\u001b[0m     processed_cols \u001b[38;5;241m=\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m mean_PCA)\n\u001b[1;32m    378\u001b[0m     mu_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([first_col\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), processed_cols\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    380\u001b[0m y_obs \u001b[38;5;241m=\u001b[39m test_y[row_idx, :]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x0 and 20x51)\nTrace Shapes:  \n Param Sites:  \nSample Sites:  \n param_0 dist |\n        value |\n param_1 dist |\n        value |\n param_2 dist |\n        value |\n param_3 dist |\n        value |\n param_4 dist |\n        value |\n param_5 dist |\n        value |\n param_6 dist |\n        value |\n param_7 dist |\n        value |\n param_8 dist |\n        value |\n param_9 dist |\n        value |\n   sigma dist |\n        value |"
     ]
    }
   ],
   "source": [
    "mcmc_result_Uniform = Estimation.run_mcmc_Uniform(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, bounds, \n",
    "                                                  PCA_func = pca_20, \n",
    "                                                  num_sampling = 400, warmup_step = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result_Normal = Estimation.run_mcmc_Normal(Prediction.preds_for_one_model, MultitaskGP_models, MultitaskGP_likelihoods, row_idx, test_y, local_train_x, \n",
    "                                                 PCA_func = pca_20, \n",
    "                                                 num_sampling = 400, warmup_step = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = mcmc_result_Uniform.get_samples()\n",
    "\n",
    "param_names = [f'param_{i}' for i in range(len(bounds))]\n",
    "\n",
    "posterior_means_array = np.zeros(len(param_names))\n",
    "\n",
    "\n",
    "for idx, param_name in enumerate(param_names):\n",
    "    samples = posterior_samples[param_name]\n",
    "    if samples.ndim > 1:\n",
    "        samples = samples.reshape(-1)\n",
    "    mean_value = torch.mean(samples).item()\n",
    "    posterior_means_array[idx] = mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior_samples_Normal = mcmc_result_Uniform.get_samples()\n",
    "\n",
    "true_values = test_x[row_idx,:]\n",
    "\n",
    "point_estimations = posterior_means_array_tmp\n",
    "\n",
    "fig, axes = plt.subplots(len(posterior_samples_Uniform), 1, figsize=(8, len(posterior_samples_Uniform) * 3))\n",
    "\n",
    "for i, (param_name, samples) in enumerate(posterior_samples_Uniform.items()):\n",
    "    if len(posterior_samples_Uniform) > 1:\n",
    "        ax = axes[i]\n",
    "    else:\n",
    "        ax = axes\n",
    "    sns.kdeplot(samples.detach().numpy(), ax=ax, color='blue')\n",
    "    ax.set_title(f'Density of {param_name}')\n",
    "    \n",
    "    # 标记 true_values 和 point_estimations\n",
    "    if true_values is not None and i < len(true_values):\n",
    "        ax.axvline(true_values[i], color='red', linestyle='--', label='True Value')\n",
    "    if point_estimations is not None and i < len(point_estimations):\n",
    "        ax.axvline(point_estimations[i], color='green', linestyle='-.', label='Point Estimation')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **End**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for the Gaussian distribution\n",
    "mu = 0  # mean\n",
    "sigma = 1  # standard deviation\n",
    "\n",
    "# Generate random samples from the Gaussian distribution\n",
    "x = np.random.normal(mu, sigma, 10000)\n",
    "# x = np.random.uniform(mu, sigma, 10000)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(x, bins=30, density=True, alpha=0.6, color='b', edgecolor='black')\n",
    "\n",
    "\n",
    "# Labeling the plot\n",
    "\n",
    "plt.xlabel(\"X values\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the affine transformation function\n",
    "def affine_transform(x, loc=1.3, scale=2.6):\n",
    "    return loc + scale * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sigmoid transform to the generated data\n",
    "# x_1 = affine_transform(x,3,1.5)\n",
    "x_2 = sigmoid(x)\n",
    "x_transformed = affine_transform(x_2)\n",
    "\n",
    "# Plot the transformed distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(x_transformed, bins=30, density=True, alpha=0.6, color='b', edgecolor='black')\n",
    "\n",
    "# Labeling the plot\n",
    "plt.xlabel(\"Transformed X values\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx,:]\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_CPU(input_point, train_x, train_y, k = 400)\n",
    "\n",
    "# 假设x是已知数据\n",
    "x = local_train_x[:,3] \n",
    "\n",
    "# 1. 绘制直方图\n",
    "plt.hist(x, bins=30, density=True, alpha=0.6, color='g')\n",
    "\n",
    "# 2. 尝试拟合正态分布\n",
    "mu, std = stats.norm.fit(x)\n",
    "\n",
    "# 3. 绘制拟合的正态分布曲线\n",
    "xmin, xmax = plt.xlim()\n",
    "x_plot = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x_plot, mu, std)\n",
    "plt.plot(x_plot, p, 'k', linewidth=2)\n",
    "title = f\"Fit results: mu = {mu:.2f}, std = {std:.2f}\"\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "# 4. 生成与数据类似的随机数\n",
    "random_data = np.random.normal(mu, std, len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x[0,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
