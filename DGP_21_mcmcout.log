nohup: ignoring input
/home/pgrad1/2633042r/Multioutput_FixedG_GP/DGP_21_mcmc.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(ckpt_path, map_location=Device)
Warmup:   0%|          | 0/1500 [00:00, ?it/s]Traceback (most recent call last):
  File "/home/pgrad1/2633042r/Multioutput_FixedG_GP/DGP_21_mcmc.py", line 82, in <module>
    mcmc_result_Uniform = Estimation.run_mcmc_Uniform_dgp(
  File "/home/pgrad1/2633042r/Multioutput_FixedG_GP/GP_functions/Estimation.py", line 717, in run_mcmc_Uniform_dgp
    mcmc.run()
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/poutine/messenger.py", line 32, in _context_wrap
    return fn(*args, **kwargs)
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/api.py", line 565, in run
    for x, chain_id in self.sampler.run(*args, **kwargs):
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/api.py", line 225, in run
    for sample in _gen_samples(
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/api.py", line 146, in _gen_samples
    kernel.setup(warmup_steps, *args, **kwargs)
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/hmc.py", line 345, in setup
    self._initialize_model_properties(args, kwargs)
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/hmc.py", line 279, in _initialize_model_properties
    init_params, potential_fn, transforms, trace = initialize_model(
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/util.py", line 427, in initialize_model
    max_plate_nesting = _guess_max_plate_nesting(model, model_args, model_kwargs)
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/infer/mcmc/util.py", line 251, in _guess_max_plate_nesting
    model_trace = poutine.trace(model).get_trace(*args, **kwargs)
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py", line 216, in get_trace
    self(*args, **kwargs)
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py", line 191, in __call__
    ret = self.fn(*args, **kwargs)
  File "/home/pgrad1/2633042r/Multioutput_FixedG_GP/GP_functions/Estimation.py", line 709, in model
    gp_pred = Pre_function(Models, theta.unsqueeze(0))
  File "/home/pgrad1/2633042r/Multioutput_FixedG_GP/GP_functions/Prediction.py", line 121, in dgp_predict_cov
    x = x.to(device)
  File "/home/pgrad1/2633042r/miniconda3/envs/GT/lib/python3.10/site-packages/torch/cuda/__init__.py", line 310, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
