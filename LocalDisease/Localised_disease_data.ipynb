{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb9903f",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954ad320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "561174f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = np.random.default_rng(1030)\n",
    "\n",
    "LOW, HIGH = 0.1, 5.0\n",
    "BASELINE = 2.5\n",
    "CENTRES = [1.0, 1.1, 1.5, 2.0, 3.0]\n",
    "REPLICATES_PER_REGION = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_trunc_bvn(mean: np.ndarray, cov: np.ndarray, low: float, high: float) -> np.ndarray:\n",
    "    while True:\n",
    "        x = RNG.multivariate_normal(mean, cov)\n",
    "        if low <= x[0] <= high and low <= x[1] <= high:\n",
    "            return x\n",
    "\n",
    "# def build_datasets_for_centre(\n",
    "#     m: float,\n",
    "#     sd2: float = 0.1,\n",
    "#     rho: float = 0.3,\n",
    "#     baseline_jitter: float = 1e-2,\n",
    "#     jitter_mode: str = \"random\"\n",
    "# ) -> pd.DataFrame:\n",
    "#     sd = np.sqrt(sd2)\n",
    "#     cov = np.array([[sd**2, rho*sd**2],\n",
    "#                     [rho*sd**2, sd**2]])\n",
    "#     rows = []\n",
    "#     for region in range(1, 6):\n",
    "#         for _ in range(REPLICATES_PER_REGION):\n",
    "#             mean = np.array([m, m])\n",
    "#             a_r, b_r = sample_trunc_bvn(mean, cov, LOW, HIGH)\n",
    "\n",
    "#             params = []\n",
    "#             for r in range(1, 6):\n",
    "#                 if r == region:\n",
    "#                     # 当前被“激活”的区域：用真正采样到的那一对\n",
    "#                     params.extend([a_r, b_r])\n",
    "#                 else:\n",
    "#                     # 其他区域：本来是 BASELINE，这里加一个很小的扰动\n",
    "#                     if jitter_mode == \"random\":\n",
    "#                         # 随机小抖动，零均值，幅度由 baseline_jitter 控制\n",
    "#                         eps_a = np.random.uniform(-baseline_jitter, baseline_jitter)\n",
    "#                         eps_b = np.random.uniform(-baseline_jitter, baseline_jitter)\n",
    "#                         params.extend([BASELINE + eps_a, BASELINE + eps_b])\n",
    "#                     else:\n",
    "#                         # 固定的小偏移，保证不等于 BASELINE\n",
    "#                         params.extend([BASELINE + baseline_jitter,\n",
    "#                                        BASELINE + baseline_jitter])\n",
    "\n",
    "#             rows.append(params)\n",
    "\n",
    "#     df = pd.DataFrame(\n",
    "#         rows,\n",
    "#         columns=[f\"{ab}{r}\" for r in range(1, 6) for ab in (\"a\", \"b\")]\n",
    "#     )\n",
    "#     return df\n",
    "\n",
    "\n",
    "def build_datasets_for_centre(\n",
    "    m: float,\n",
    "    sd2: float = 0.1,\n",
    "    rho: float = 0.3,\n",
    "    baseline_jitter: float = 1e-2,\n",
    "    jitter_mode: str = \"random\",\n",
    "    n_active_regions: int = 1,   # 新增：每行激活多少个区域\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    if not (1 <= n_active_regions <= 5):\n",
    "        raise ValueError(\"n_active_regions must be between 1 and 5.\")\n",
    "\n",
    "    sd = np.sqrt(sd2)\n",
    "    cov = np.array([[sd**2,        rho * sd**2],\n",
    "                    [rho * sd**2,  sd**2      ]])\n",
    "\n",
    "    rows = []\n",
    "    all_regions = list(range(1, 6))\n",
    "\n",
    "    for region in all_regions:\n",
    "\n",
    "        for _ in range(REPLICATES_PER_REGION):\n",
    "            mean = np.array([m, m])\n",
    "\n",
    "            # === 选出本行中被激活的区域集合 ===\n",
    "            # 确保当前 region 一定在激活集合里，然后再随机补足剩下的\n",
    "            active_regions = [region]\n",
    "            if n_active_regions > 1:\n",
    "                others = [r for r in all_regions if r != region]\n",
    "                extra = np.random.choice(\n",
    "                    others,\n",
    "                    size=n_active_regions - 1,\n",
    "                    replace=False\n",
    "                )\n",
    "                active_regions.extend(extra)\n",
    "\n",
    "            # === 为每一个激活区域单独采样一对 (a_r, b_r) ===\n",
    "            samples = {}\n",
    "            for r_act in active_regions:\n",
    "                samples[r_act] = sample_trunc_bvn(mean, cov, LOW, HIGH)  # 返回 shape (2,)\n",
    "\n",
    "            # === 组装这一行的 10 个参数 a1,b1,...,a5,b5 ===\n",
    "            params = []\n",
    "            for r in all_regions:\n",
    "                if r in active_regions:\n",
    "                    a_r, b_r = samples[r]\n",
    "                    params.extend([a_r, b_r])\n",
    "                else:\n",
    "                    # 非激活区域：baseline + 小扰动\n",
    "                    if jitter_mode == \"random\":\n",
    "                        eps_a = np.random.uniform(-baseline_jitter, baseline_jitter)\n",
    "                        eps_b = np.random.uniform(-baseline_jitter, baseline_jitter)\n",
    "                        params.extend([BASELINE + eps_a, BASELINE + eps_b])\n",
    "                    else:\n",
    "                        params.extend([BASELINE + baseline_jitter,\n",
    "                                       BASELINE + baseline_jitter])\n",
    "\n",
    "            rows.append(params)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[f\"{ab}{r}\" for r in range(1, 6) for ab in (\"a\", \"b\")]\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83bf30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = build_datasets_for_centre(1.2, sd2=0.05, rho=0.3, baseline_jitter = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2f9b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf15bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({f'col_{i}': [5] for i in range(10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a68cd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_numpy()\n",
    "m, n = df.shape\n",
    "\n",
    "\n",
    "new_data = np.zeros((m, 34))\n",
    "\n",
    "\n",
    "mapping = {\n",
    "    0: [4, 16],\n",
    "    1: [5, 17],\n",
    "    2: [10, 22],\n",
    "    3: [11, 23],\n",
    "    4: [8, 6, 20, 18],\n",
    "    5: [9, 7, 21, 19],\n",
    "    6: [2, 0, 14, 12],\n",
    "    7: [3, 1, 15, 13],\n",
    "    8: [24, 26, 28, 30, 32],\n",
    "    9: [25, 27, 29, 31, 33]\n",
    "}\n",
    "\n",
    "for orig_col, new_cols in mapping.items():\n",
    "    for new_col in new_cols:\n",
    "        new_data[:, new_col] = df[:, orig_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0ab73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"LocalDisease/X_3.txt\", new_data, fmt='%0.4f')\n",
    "np.savetxt(\"X_5_max.txt\", new_data, fmt='%0.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0401b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_1_1.txt', header=None, delimiter=' ').values\n",
    "\n",
    "m = X_train.shape[0]\n",
    "\n",
    "mapping = {\n",
    "    0: [4, 16],\n",
    "    1: [5, 17],\n",
    "    2: [10, 22],\n",
    "    3: [11, 23],\n",
    "    4: [8, 6, 20, 18],\n",
    "    5: [9, 7, 21, 19],\n",
    "    6: [2, 0, 14, 12],\n",
    "    7: [3, 1, 15, 13],\n",
    "    8: [24, 26, 28, 30, 32],\n",
    "    9: [25, 27, 29, 31, 33]\n",
    "}\n",
    "\n",
    "X_all_recovered = np.zeros((m, len(mapping)))\n",
    "\n",
    "\n",
    "for orig_col, new_cols in mapping.items():\n",
    "\n",
    "    X_all_recovered[:, orig_col] = X_train[:, new_cols].mean(axis=1)\n",
    "\n",
    "X_train = np.around(X_all_recovered, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4fa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_1_1.csv\", X_train, delimiter=\",\", fmt=\"%.4f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564824ac",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a750cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pca = pd.read_csv('Y_train_std_pca.csv', header=None, delimiter=',').values\n",
    "Y_test_pca = pd.read_csv('Y_test_std_pca.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_data_1_1_pca = pd.read_csv('Y_data_1_1_pca.csv', header=None, delimiter=',').values\n",
    "Y_data_1_5_pca = pd.read_csv('Y_data_1_5_pca.csv', header=None, delimiter=',').values\n",
    "Y_data_2_pca = pd.read_csv('Y_data_2_pca.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_edge_std_pca = pd.read_csv('Y_edge_std_pca.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_data_1_2_jitter_B_2_5_pca = pd.read_csv('Y_data_1_2_jitter_B_2_5_pca.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ebf028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "       21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_min = np.nanmin(Y_train_pca, axis=0)\n",
    "col_max = np.nanmax(Y_train_pca, axis=0)\n",
    "\n",
    "\n",
    "((Y_data_1_1_pca >= col_min) & (Y_data_1_1_pca <= col_max)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95799f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../Data/X_train.csv', header=None, delimiter=',').values\n",
    "X_test = pd.read_csv('../Data/X_test.csv', header=None, delimiter=',').values\n",
    "X_edge = pd.read_csv('../Data/X_edge.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.vstack([X_train, X_edge])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPTG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
