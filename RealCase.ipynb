{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7b1e67",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7d7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import statsmodels\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from pyro.ops.stats import (\n",
    "    gelman_rubin,\n",
    "    split_gelman_rubin,\n",
    "    autocorrelation,\n",
    "    effective_sample_size,\n",
    "    resample,\n",
    "    quantile,\n",
    "    weighed_quantile\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import GP_functions.Loss_function as Loss_function\n",
    "import GP_functions.bound as bound\n",
    "import GP_functions.Estimation as Estimation\n",
    "import GP_functions.Training as Training\n",
    "import GP_functions.Prediction as Prediction\n",
    "import GP_functions.GP_models as GP_models\n",
    "import GP_functions.Tools as Tools\n",
    "import GP_functions.FeatureE as FeatureE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57c16c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_RealCase_train = pd.read_csv('Data/Y_train_std.csv', header=None, delimiter=',')\n",
    "# df_new = Y_RealCase_train.drop(Y_RealCase_train.columns[-18:], axis=1)\n",
    "# Y_data_train = df_new.drop(df_new.columns[17], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"Y_RealCase_train.csv\", Y_data_train.values, delimiter=\",\", fmt=\"%.8f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea4680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('RealCase/RealCase_X_train.csv', header=None, delimiter=',').values\n",
    "X_test = pd.read_csv('RealCase/RealCase_X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_pca = pd.read_csv('RealCase/RealCase_Y_train_pca.csv', header=None, delimiter=',').values\n",
    "Y_test_pca = pd.read_csv('RealCase/RealCase_Y_test_pca.csv', header=None, delimiter=',').values\n",
    "Realcase_data_pca = pd.read_csv('RealCase/RealCase_Y_pca.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('RealCase/RealCase_Y_train_std.csv', header=None, delimiter=',').values\n",
    "Y_test_std = pd.read_csv('RealCase/RealCase_Y_test_std.csv', header=None, delimiter=',').values\n",
    "Realcase_data_std = pd.read_csv('RealCase/RealCase_Y_std.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train = pd.read_csv('RealCase/RealCase_Y_train.csv', header=None, delimiter=',').values\n",
    "Y_test = pd.read_csv('RealCase/RealCase_Y_test.csv', header=None, delimiter=',').values\n",
    "Realcase_data = pd.read_csv('RealCase/RealCase.csv', header=None, delimiter=',').values\n",
    "\n",
    "# Realcase_data_extra = pd.read_csv('RealCase/RealCase_Y_extra.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e64197",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Y_train[:,0] < 181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3950e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_hist_grid(Y, start=0, num=24, ncols=6, bins=30):\n",
    "\n",
    "\n",
    "    p = Y.shape[1]\n",
    "    end = min(p, start + num)\n",
    "    idxs = list(range(start, end))\n",
    "\n",
    "    nrows = math.ceil(len(idxs) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "    for k, j in enumerate(idxs):\n",
    "        r, c = divmod(k, ncols)\n",
    "        ax = axes[r][c]\n",
    "        ax.hist(Y[:, j], bins=bins)\n",
    "        ax.set_title(f\"col {j}\")\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # 多余子图关掉\n",
    "    for k in range(len(idxs), nrows*ncols):\n",
    "        r, c = divmod(k, ncols)\n",
    "        axes[r][c].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# real = Realcase_data.squeeze()\n",
    "plot_hist_grid(X_train[mask,:], start=0,  num=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "# seaborn.pairplot(pd.DataFrame(np.column_stack((Y_train[:,[1,2,7,8]], X_train[:,:10]))))\n",
    "\n",
    "# outer - zone 4 causes zone 1\n",
    "# outer - zone 1 causes zone 2\n",
    "# outer - zone 3 causes zone 3\n",
    "# outer - zone 2 causes zone 4\n",
    "# inner - zone 4 causes zone 1\n",
    "# middle - zone 5 causes zone 5\n",
    "# middle - zone 1 causes zone 2\n",
    "# middle - zone 3 causes zone 3\n",
    "# middle - zone 2 causes zone 4\n",
    "seaborn.kdeplot(pd.DataFrame(Y_train[:,[7,8,9,10,11,12]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d770d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.column_stack((Y_train[:,2], X_train[:,7:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053377a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38033fd9",
   "metadata": {},
   "source": [
    "## tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf0ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(X_train, dtype=torch.float32)\n",
    "test_x = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "train_y_pca = torch.tensor(Y_train_pca, dtype=torch.float32)\n",
    "test_y_pca = torch.tensor(Y_test_pca, dtype=torch.float32)\n",
    "realcase_y_pca = torch.tensor(Realcase_data_pca, dtype=torch.float32)\n",
    "\n",
    "train_y = torch.tensor(Y_train_std, dtype=torch.float32)\n",
    "test_y = torch.tensor(Y_test_std, dtype=torch.float32)\n",
    "realcase_y = torch.tensor(Realcase_data_std, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_min = np.nanmin(Y_train_pca, axis=0)\n",
    "col_max = np.nanmax(Y_train_pca, axis=0)\n",
    "\n",
    "\n",
    "((Realcase_data_pca >= col_min) & (Realcase_data_pca <= col_max)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51931fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aae49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Realcase_data >= col_min) & (Realcase_data <= col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d982194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f866f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Realcase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9694f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Realcase_data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_hist_grid(Y, real, start=0, num=24, ncols=6, bins=30):\n",
    "    real = np.asarray(real).squeeze()\n",
    "    if real.ndim == 0:\n",
    "        real = real[None]\n",
    "\n",
    "    p = Y.shape[1]\n",
    "    end = min(p, start + num)\n",
    "    idxs = list(range(start, end))\n",
    "\n",
    "    nrows = math.ceil(len(idxs) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "    for k, j in enumerate(idxs):\n",
    "        r, c = divmod(k, ncols)\n",
    "        ax = axes[r][c]\n",
    "        ax.hist(Y[:, j], bins=bins)\n",
    "        ax.axvline(real[j])  # RealCase 的位置\n",
    "        ax.set_title(f\"col {j}\")\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # 多余子图关掉\n",
    "    for k in range(len(idxs), nrows*ncols):\n",
    "        r, c = divmod(k, ncols)\n",
    "        axes[r][c].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "real = Realcase_data_pca.squeeze()\n",
    "plot_hist_grid(Y_train_pca, real, start=0,  num=33)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d3995",
   "metadata": {},
   "source": [
    "# Emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9cf6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device = 'cpu'\n",
    "\n",
    "Device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd48f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_models, MVGP_likelihoods = Training.train_MultitaskVGP_minibatch(\n",
    "    train_x=train_x.to(Device),\n",
    "    train_y=train_y_pca.to(Device),\n",
    "    covar_type='RBF',\n",
    "    num_latents=24,\n",
    "    num_inducing=500,\n",
    "    lr_hyper=0.01,\n",
    "    lr_variational=0.1,\n",
    "    num_iterations=10000,\n",
    "    patience=10,\n",
    "    device=Device,\n",
    "    batch_size=512,\n",
    "    eval_every=100,\n",
    "    eval_batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model_state_dict': MVGP_models.state_dict(),\n",
    "    'likelihood_state_dict': MVGP_likelihoods.state_dict(),\n",
    "    'model_params': {\n",
    "        'num_latents': 24,\n",
    "        'num_inducing': 500,\n",
    "        'covar_type': 'RBF',\n",
    "        'input_dim': train_x.size(1),\n",
    "        'num_tasks': train_y.size(1)\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'multitask_gp_checkpoint_Realcase_pca.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb877cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, train_x[0].cuda().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877679b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2835b4",
   "metadata": {},
   "source": [
    "## MVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('multitask_gp_checkpoint_Realcase.pth', map_location=Device)\n",
    "model_params = checkpoint['model_params']\n",
    "\n",
    "MVGP_models = GP_models.MultitaskVariationalGP(train_x, train_y, \n",
    "                                               num_latents=model_params['num_latents'],\n",
    "                                               num_inducing=model_params['num_inducing'],  \n",
    "                                               covar_type=model_params['covar_type']).to(Device)\n",
    "\n",
    "MVGP_models.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "MVGP_likelihoods = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=train_y.shape[1]).to(Device)\n",
    "MVGP_likelihoods.load_state_dict(checkpoint['likelihood_state_dict'])\n",
    "\n",
    "MVGP_models.eval()\n",
    "MVGP_likelihoods.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a67692",
   "metadata": {},
   "source": [
    "## L.DKMGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31728aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = realcase_y\n",
    "\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_GPU(input_point, train_x, train_y, k=500)\n",
    "\n",
    "bounds = bound.get_bounds(local_train_x)\n",
    "\n",
    "MultitaskGP_models, MultitaskGP_likelihoods = Training.train_one_row_NNMultitaskGP(\n",
    "    local_train_x, local_train_y, n_tasks = local_train_y.shape[1], \n",
    "    feature_extractor_class = FeatureE.FeatureExtractor_1, covar_type = 'RBF', \n",
    "    lr=0.05, num_iterations=5000, patience=10, device = Device, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5a1a3",
   "metadata": {},
   "source": [
    "# PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc7196b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe84563e0365462aab05565cf07fa78a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multi-start:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed14149afa044bbafc79befd48c6149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Start 1/16:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502be88993a04dc1ac65f1d8a4f96d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Start 2/16:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20f77e36bd14793b2792bfe0e3a2cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Start 3/16:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m bounds = bound.get_bounds(local_train_x)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m estimated_params_tmp, _ = \u001b[43mEstimation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_start_estimation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMultitaskGP_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMultitaskGP_likelihoods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealcase_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEstimation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimate_params_for_one_model_Adam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_starts\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattraction_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepulsion_strength\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\programming\\python\\Multioutput_FixedG_GP\\GP_functions\\Estimation.py:117\u001b[39m, in \u001b[36mmulti_start_estimation\u001b[39m\u001b[34m(model, likelihood, row_idx, test_y, param_ranges, estimate_function, num_starts, num_iterations, lr, patience, attraction_threshold, repulsion_strength, device, show_progress, progress_desc)\u001b[39m\n\u001b[32m    111\u001b[39m sample = sobol_samples[start]\n\u001b[32m    112\u001b[39m initial_guess = [\n\u001b[32m    113\u001b[39m     min_val + s.item() * (max_val - min_val)\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m s, (min_val, max_val) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sample, param_ranges)\n\u001b[32m    115\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m estimated_params, loss = \u001b[43mestimate_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_guess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattraction_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattraction_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepulsion_strength\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepulsion_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# 关键：把开关传下去\u001b[39;49;00m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_desc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStart \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_starts\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 每次 start 的内层进度条标题\u001b[39;49;00m\n\u001b[32m    124\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss < best_overall_loss:\n\u001b[32m    127\u001b[39m     best_overall_loss = loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\programming\\python\\Multioutput_FixedG_GP\\GP_functions\\Estimation.py:60\u001b[39m, in \u001b[36mestimate_params_for_one_model_Adam\u001b[39m\u001b[34m(model, likelihood, row_idx, test_y, initial_guess, param_ranges, num_iterations, lr, patience, attraction_threshold, repulsion_strength, device, show_progress, progress_desc)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[32m     58\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     loss = torch.norm(likelihood.to(device)(\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_x\u001b[49m\u001b[43m)\u001b[49m).mean - target_y, p=\u001b[32m2\u001b[39m).sum()\n\u001b[32m     61\u001b[39m     loss.backward(retain_graph=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     62\u001b[39m     optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\gpytorch\\models\\exact_gp.py:345\u001b[39m, in \u001b[36mExactGP.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m settings.cg_tolerance(settings.eval_cg_tolerance.value()):\n\u001b[32m    342\u001b[39m     (\n\u001b[32m    343\u001b[39m         predictive_mean,\n\u001b[32m    344\u001b[39m         predictive_covar,\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexact_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[32m    348\u001b[39m predictive_mean = predictive_mean.view(*batch_shape, *test_shape).contiguous()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:325\u001b[39m, in \u001b[36mDefaultPredictionStrategy.exact_prediction\u001b[39m\u001b[34m(self, joint_mean, joint_covar)\u001b[39m\n\u001b[32m    320\u001b[39m     test_test_covar = joint_covar[..., \u001b[38;5;28mself\u001b[39m.num_train :, \u001b[38;5;28mself\u001b[39m.num_train :]\n\u001b[32m    321\u001b[39m     test_train_covar = joint_covar[..., \u001b[38;5;28mself\u001b[39m.num_train :, : \u001b[38;5;28mself\u001b[39m.num_train]\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m.exact_predictive_mean(test_mean, test_train_covar),\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexact_predictive_covar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_test_covar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    326\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:396\u001b[39m, in \u001b[36mDefaultPredictionStrategy.exact_predictive_covar\u001b[39m\u001b[34m(self, test_test_covar, test_train_covar)\u001b[39m\n\u001b[32m    394\u001b[39m test_train_covar = to_dense(test_train_covar)\n\u001b[32m    395\u001b[39m train_test_covar = test_train_covar.transpose(-\u001b[32m1\u001b[39m, -\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m covar_correction_rhs = \u001b[43mtrain_train_covar\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_test_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# For efficiency\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.is_tensor(test_test_covar):\n\u001b[32m    399\u001b[39m     \u001b[38;5;66;03m# We can use addmm in the 2d case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:2342\u001b[39m, in \u001b[36mLinearOperator.solve\u001b[39m\u001b[34m(self, right_tensor, left_tensor)\u001b[39m\n\u001b[32m   2340\u001b[39m func = Solve\n\u001b[32m   2341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m left_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2344\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func.apply(\n\u001b[32m   2345\u001b[39m         \u001b[38;5;28mself\u001b[39m.representation_tree(),\n\u001b[32m   2346\u001b[39m         \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2349\u001b[39m         *\u001b[38;5;28mself\u001b[39m.representation(),\n\u001b[32m   2350\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\torch\\autograd\\function.py:581\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    579\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    580\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    587\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    588\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    589\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\functions\\_solve.py:53\u001b[39m, in \u001b[36mSolve.forward\u001b[39m\u001b[34m(ctx, representation_tree, has_left, *args)\u001b[39m\n\u001b[32m     51\u001b[39m     res = left_tensor @ res\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     solves = \u001b[43m_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     res = solves\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.is_vector:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\functions\\_solve.py:21\u001b[39m, in \u001b[36m_solve\u001b[39m\u001b[34m(linear_op, rhs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     20\u001b[39m     preconditioner = linear_op.detach()._solve_preconditioner()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlinear_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreconditioner\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\operators\\kronecker_product_added_diag_linear_operator.py:213\u001b[39m, in \u001b[36mKroneckerProductAddedDiagLinearOperator._solve\u001b[39m\u001b[34m(self, rhs, preconditioner, num_tridiag)\u001b[39m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m (\n\u001b[32m    199\u001b[39m         \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    200\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInverses of KroneckerProductAddedDiagonals and ConstantDiagLinearOperators are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    201\u001b[39m             + \u001b[33m\"\u001b[39m\u001b[33mnot implemented yet.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         )\n\u001b[32m    203\u001b[39m     )\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# in this case we can pull across the diagonals\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# (\\otimes K_i + \\otimes D_i) = (\\otimes D_i^{1/2})\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m#   (\\otimes D_i^{-1/2}K_iD_i^{-1/2} + I)(\\otimes D_i^{1/2})\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Reference: Rakitsch, et al, 2013. \"It is all in the noise,\"\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# https://papers.nips.cc/paper/2013/file/59c33016884a62116be975a9bb8257e3-Paper.pdf\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m dlt_inv_root, evals_p_i, evecs = \u001b[43m_symmetrize_kpadlt_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdlt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m res1 = evecs._transpose_nonbatch().matmul(dlt_inv_root.matmul(rhs))\n\u001b[32m    216\u001b[39m res2 = evals_p_i.solve(res1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\operators\\kronecker_product_added_diag_linear_operator.py:43\u001b[39m, in \u001b[36m_symmetrize_kpadlt_constructor\u001b[39m\u001b[34m(lt, dlt)\u001b[39m\n\u001b[32m     39\u001b[39m dlt_inv_root = dlt.sqrt().inverse()\n\u001b[32m     40\u001b[39m symm_prod = KroneckerProductLinearOperator(\n\u001b[32m     41\u001b[39m     *[d.matmul(k).matmul(d) \u001b[38;5;28;01mfor\u001b[39;00m k, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lt.linear_ops, dlt_inv_root.linear_ops)]\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m evals, evecs = \u001b[43msymm_prod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiagonalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m evals_plus_i = DiagLinearOperator(evals + \u001b[32m1.0\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dlt_inv_root, evals_plus_i, evecs\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\operators\\kronecker_product_linear_operator.py:152\u001b[39m, in \u001b[36mKroneckerProductLinearOperator.diagonalization\u001b[39m\u001b[34m(self, method)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     method = \u001b[33m\"\u001b[39m\u001b[33msymeig\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiagonalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\utils\\memoize.py:59\u001b[39m, in \u001b[36m_cached.<locals>.g\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m kwargs_pkl = pickle.dumps(kwargs)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, *args, kwargs_pkl=kwargs_pkl):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, *args, kwargs_pkl=kwargs_pkl)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, *args, kwargs_pkl=kwargs_pkl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:1461\u001b[39m, in \u001b[36mLinearOperator.diagonalization\u001b[39m\u001b[34m(self, method)\u001b[39m\n\u001b[32m   1458\u001b[39m     evecs = to_linear_operator(evecs)\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33msymeig\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1461\u001b[39m     evals, evecs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_symeig\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenvectors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1462\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown diagonalization method \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\operators\\kronecker_product_linear_operator.py:342\u001b[39m, in \u001b[36mKroneckerProductLinearOperator._symeig\u001b[39m\u001b[34m(self, eigenvectors, return_evals_as_lazy)\u001b[39m\n\u001b[32m    340\u001b[39m evals, evecs = [], []\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.linear_ops:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     evals_, evecs_ = \u001b[43mlt\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_symeig\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenvectors\u001b[49m\u001b[43m=\u001b[49m\u001b[43meigenvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m     evals.append(evals_)\n\u001b[32m    344\u001b[39m     evecs.append(evecs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\GPTG\\Lib\\site-packages\\linear_operator\\operators\\_linear_operator.py:892\u001b[39m, in \u001b[36mLinearOperator._symeig\u001b[39m\u001b[34m(self, eigenvectors, return_evals_as_lazy)\u001b[39m\n\u001b[32m    890\u001b[39m \u001b[38;5;66;03m# potentially perform decomposition in double precision for numerical stability\u001b[39;00m\n\u001b[32m    891\u001b[39m dtype = \u001b[38;5;28mself\u001b[39m.dtype\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m evals, evecs = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_linalg_dtype_symeig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[38;5;66;03m# chop any negative eigenvalues.\u001b[39;00m\n\u001b[32m    894\u001b[39m \u001b[38;5;66;03m# TODO: warn if evals are significantly negative\u001b[39;00m\n\u001b[32m    895\u001b[39m evals = evals.clamp_min(\u001b[32m0.0\u001b[39m).to(dtype=dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "bounds = bound.get_bounds(local_train_x)\n",
    "\n",
    "estimated_params_tmp, _ = Estimation.multi_start_estimation(\n",
    "    MultitaskGP_models, MultitaskGP_likelihoods, row_idx, realcase_y, bounds,\n",
    "    Estimation.estimate_params_for_one_model_Adam, num_starts=16, num_iterations=2000, lr=0.01,\n",
    "    patience=50, attraction_threshold=0.1, repulsion_strength=0.1, device=Device, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbe270",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = realcase_y_pca\n",
    "\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_GPU(input_point, train_x, train_y_pca, k=500)\n",
    "\n",
    "bounds = bound.get_bounds(local_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_hist_grid(Y, real, start=0, num=24, ncols=6, bins=30):\n",
    "    real = np.asarray(real).squeeze()\n",
    "    if real.ndim == 0:\n",
    "        real = real[None]\n",
    "\n",
    "    p = Y.shape[1]\n",
    "    end = min(p, start + num)\n",
    "    idxs = list(range(start, end))\n",
    "\n",
    "    nrows = math.ceil(len(idxs) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "    for k, j in enumerate(idxs):\n",
    "        r, c = divmod(k, ncols)\n",
    "        ax = axes[r][c]\n",
    "        ax.hist(Y[:, j], bins=bins)\n",
    "        ax.axvline(real[j])  # RealCase 的位置\n",
    "        ax.set_title(f\"col {j}\")\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # 多余子图关掉\n",
    "    for k in range(len(idxs), nrows*ncols):\n",
    "        r, c = divmod(k, ncols)\n",
    "        axes[r][c].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_hist_grid(local_train_y, realcase_y_pca, start=0,  num=33)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39504c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37666f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = local_train_x\n",
    "start=0\n",
    "num=11\n",
    "ncols=6\n",
    "bins=30\n",
    "\n",
    "p = Y.shape[1]\n",
    "end = min(p, start + num)\n",
    "idxs = list(range(start, end))\n",
    "\n",
    "nrows = math.ceil(len(idxs) / ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "for k, j in enumerate(idxs):\n",
    "    r, c = divmod(k, ncols)\n",
    "    ax = axes[r][c]\n",
    "    ax.hist(Y[:, j], bins=bins)\n",
    "    ax.set_title(f\"col {j}\")\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "# 多余子图关掉\n",
    "for k in range(len(idxs), nrows*ncols):\n",
    "    r, c = divmod(k, ncols)\n",
    "    axes[r][c].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def sobol_loguniform(\n",
    "    d: int,\n",
    "    *,\n",
    "    m: int | None = None,\n",
    "    n: int | None = None,\n",
    "    l_bounds=0.1,\n",
    "    u_bounds=5.0,\n",
    "    seed: int | None = None,\n",
    "    scramble: bool = True,\n",
    "    log_base: float = np.e,   # np.e 表示自然对数；10 表示 log10\n",
    "    return_engine: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    生成 Sobol 序列并将其映射为对数均匀分布（log-uniform）采样。\n",
    "\n",
    "    参数\n",
    "    ----\n",
    "    d : int\n",
    "        维度。\n",
    "    m : int, optional\n",
    "        使用 random_base2(m) 生成 2**m 个 Sobol 点（推荐 Sobol 的标准用法）。\n",
    "    n : int, optional\n",
    "        使用 random(n) 生成 n 个 Sobol 点（不要求 2 的幂）。\n",
    "    l_bounds, u_bounds : float or array-like\n",
    "        每一维的下界/上界。可传标量或长度为 d 的列表/数组。\n",
    "        注意：log-uniform 要求 l_bounds > 0。\n",
    "    seed : int, optional\n",
    "        随机种子（scramble=True 时生效）。\n",
    "    scramble : bool\n",
    "        是否打乱（推荐 True）。\n",
    "    log_base : float\n",
    "        对数底。np.e 表示自然对数；10 表示 log10。\n",
    "    return_engine : bool\n",
    "        是否同时返回 Sobol engine。\n",
    "\n",
    "    返回\n",
    "    ----\n",
    "    X : ndarray, shape (N, d)\n",
    "        对数均匀采样点。\n",
    "    (optional) engine : qmc.Sobol\n",
    "    \"\"\"\n",
    "    if (m is None) == (n is None):\n",
    "        raise ValueError(\"请二选一：提供 m（生成 2**m 个点）或提供 n（生成 n 个点）。\")\n",
    "\n",
    "    lb = np.asarray(l_bounds, dtype=float)\n",
    "    ub = np.asarray(u_bounds, dtype=float)\n",
    "\n",
    "    if lb.ndim == 0:\n",
    "        lb = np.full(d, lb)\n",
    "    if ub.ndim == 0:\n",
    "        ub = np.full(d, ub)\n",
    "\n",
    "    if lb.shape != (d,) or ub.shape != (d,):\n",
    "        raise ValueError(f\"l_bounds/u_bounds 必须是标量或长度为 d={d} 的数组。\")\n",
    "    if np.any(lb <= 0):\n",
    "        raise ValueError(\"log-uniform 要求所有下界 l_bounds > 0。\")\n",
    "    if np.any(ub <= lb):\n",
    "        raise ValueError(\"要求 u_bounds > l_bounds。\")\n",
    "\n",
    "    engine = qmc.Sobol(d=d, scramble=scramble, seed=seed)\n",
    "\n",
    "    U = engine.random_base2(m=m) if m is not None else engine.random(n=n)\n",
    "\n",
    "    # log-uniform 逐维变换\n",
    "    if log_base == 10:\n",
    "        log_lb = np.log10(lb)\n",
    "        log_ub = np.log10(ub)\n",
    "        X = 10 ** (log_lb + U * (log_ub - log_lb))\n",
    "    elif log_base == np.e:\n",
    "        log_lb = np.log(lb)\n",
    "        log_ub = np.log(ub)\n",
    "        X = np.exp(log_lb + U * (log_ub - log_lb))\n",
    "    else:\n",
    "        # 任意底：log_b(x)=ln(x)/ln(b)\n",
    "        ln_lb, ln_ub = np.log(lb), np.log(ub)\n",
    "        X = np.exp(ln_lb + U * (ln_ub - ln_lb))  # 采样不依赖底，只影响“解释”\n",
    "    \n",
    "    return (X, engine) if return_engine else X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extra = sobol_loguniform(\n",
    "    d=10,\n",
    "    m=10,\n",
    "    l_bounds=[0.1]*10,\n",
    "    u_bounds=[5]*10,\n",
    "    seed=24,\n",
    "    scramble=True,\n",
    "    log_base=np.e\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32050a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_extra\n",
    "m, n = df.shape\n",
    "\n",
    "\n",
    "new_data = np.zeros((m, 34))\n",
    "\n",
    "\n",
    "mapping = {\n",
    "    0: [4, 16],\n",
    "    1: [5, 17],\n",
    "    2: [10, 22],\n",
    "    3: [11, 23],\n",
    "    4: [8, 6, 20, 18],\n",
    "    5: [9, 7, 21, 19],\n",
    "    6: [2, 0, 14, 12],\n",
    "    7: [3, 1, 15, 13],\n",
    "    8: [24, 26, 28, 30, 32],\n",
    "    9: [25, 27, 29, 31, 33]\n",
    "}\n",
    "\n",
    "for orig_col, new_cols in mapping.items():\n",
    "    for new_col in new_cols:\n",
    "        new_data[:, new_col] = df[:, orig_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_extra_RealCase.txt\", new_data, fmt='%0.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X_extra\n",
    "start=0\n",
    "num=11\n",
    "ncols=6\n",
    "bins=30\n",
    "\n",
    "p = Y.shape[1]\n",
    "end = min(p, start + num)\n",
    "idxs = list(range(start, end))\n",
    "\n",
    "nrows = math.ceil(len(idxs) / ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "for k, j in enumerate(idxs):\n",
    "    r, c = divmod(k, ncols)\n",
    "    ax = axes[r][c]\n",
    "    ax.hist(Y[:, j], bins=bins)\n",
    "    ax.set_title(f\"col {j}\")\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "# 多余子图关掉\n",
    "for k in range(len(idxs), nrows*ncols):\n",
    "    r, c = divmod(k, ncols)\n",
    "    axes[r][c].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b731907",
   "metadata": {},
   "source": [
    "# PE Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params_tmp, Loss_tmp = Estimation.multi_start_estimation(\n",
    "        MVGP_models, MVGP_likelihoods, row_idx, realcase_y_pca, bounds,\n",
    "        Estimation.estimate_params_for_one_model_Adam, num_starts=16, num_iterations=2000, lr=0.05,\n",
    "        patience=15, attraction_threshold=0.1, repulsion_strength=0.1, device=Device, show_progress=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a91bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5910591",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(estimated_params_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53386486",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, torch.tensor(estimated_params_tmp).cuda().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded26516",
   "metadata": {},
   "source": [
    "# Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_pca_result = pd.read_csv('RealCase/Result/MVGP_21_result.csv')\n",
    "MVGP_pca_result['estimated_params_list'] = MVGP_pca_result['estimated_params'].apply(ast.literal_eval)\n",
    "\n",
    "MVGP_pca_result = np.array(MVGP_pca_result['estimated_params_list'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ca9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "realcase_paras_pca = torch.tensor(MVGP_pca_result, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tmp = Prediction.preds_for_one_model(\n",
    "        MVGP_models, MVGP_likelihoods, realcase_paras_pca.to(Device)\n",
    "        ).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a3d66",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result_Uniform = Estimation.run_mcmc_Uniform(\n",
    "    Prediction.preds_distribution, MVGP_models, MVGP_likelihoods, \n",
    "    row_idx, realcase_y_pca, bounds, \n",
    "    num_sampling=1200, warmup_step=300, num_chains=1, device=Device\n",
    ")\n",
    "posterior_samples_Uniform = mcmc_result_Uniform.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eaa39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(posterior_samples_Uniform, \"mcmc_RealCase_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b7da8",
   "metadata": {},
   "source": [
    "# MCMC Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"RealCase/Result/MVGP_21_mcmc_result/result_1.pkl\", \"rb\") as f:\n",
    "    loaded_samples_chain1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_samples = torch.load(\"mcmc_RealCase_test.pt\", map_location=Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309dfa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_est   = {k: v.mean(dim=0) for k, v in loaded_samples.items()}\n",
    "median_est = {k: v.median(dim=0).values for k, v in loaded_samples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PE_est = torch.tensor([2.331779  , 0.1191    , 3.3170652 , 1.2486118 , 1.4911077 ,0.1097    , 1.3861945 , 0.11462227, 0.453993  , 4.9712])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4115637",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, PE_est.cpu().unsqueeze(0)), realcase_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97423654",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_est_tensor = torch.stack([mean_est[f\"param_{i}\"] for i in range(len(mean_est))])\n",
    "median_est_tensor = torch.stack([median_est[f\"param_{i}\"] for i in range(len(median_est))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, mean_est_tensor.cpu().unsqueeze(0)), realcase_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, median_est_tensor.cpu().unsqueeze(0)), realcase_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_mode_hist(x, bins=60):\n",
    "    x = x.detach().flatten()\n",
    "    xmin, xmax = x.min().item(), x.max().item()\n",
    "    hist = torch.histc(x, bins=bins, min=xmin, max=xmax)\n",
    "    idx = int(hist.argmax())\n",
    "    edges = torch.linspace(xmin, xmax, bins + 1)\n",
    "    return 0.5 * (edges[idx] + edges[idx + 1])\n",
    "\n",
    "mode_est = {}\n",
    "for k, v in loaded_samples.items():\n",
    "\n",
    "    if v.ndim == 1:\n",
    "        mode_est[k] = approx_mode_hist(v)\n",
    "    else:\n",
    "        mode_est[k] = torch.stack([approx_mode_hist(v[:, i]) for i in range(v.shape[1])])\n",
    "\n",
    "print(mode_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r = [np.float32(2.2888), \n",
    "          np.float32(0.1250), \n",
    "          np.float32(3.9497), \n",
    "          np.float32(1.6686), \n",
    "          np.float32(0.1079), \n",
    "          np.float32(2.2909), \n",
    "          np.float32(1.3089), \n",
    "          np.float32(0.1650), \n",
    "          np.float32(0.6204), \n",
    "          np.float32(4.9653)]\n",
    "\n",
    "# Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, torch.tensor(test_r).cpu().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af31c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, torch.tensor(test_r).cpu().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc79a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "realcase_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, torch.tensor(test_r).cpu().unsqueeze(0)), realcase_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a28652",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_chain_samples = posterior_samples_Uniform  # dict: param -> Tensor[n_samples]\n",
    "\n",
    "# 将每条参数的样本拆成两半\n",
    "def split_chain(chain_tensor):\n",
    "    n = chain_tensor.shape[0]\n",
    "    half = n // 2\n",
    "    return chain_tensor[:half], chain_tensor[half:2*half]\n",
    "\n",
    "# 整理成 mcmc_samples：param -> Tensor[2, n_half]\n",
    "mcmc_samples = {}\n",
    "for param, samples in single_chain_samples.items():\n",
    "    chain_a, chain_b = split_chain(samples)\n",
    "    # 如果原链长度是奇数，可以选择丢弃最后一个样本或做其他处理\n",
    "    mcmc_samples[param] = torch.stack([chain_a, chain_b], dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 诊断和可视化\n",
    "for param, samples_chains in mcmc_samples.items():\n",
    "\n",
    "    \n",
    "    # 计算诊断量\n",
    "    rhat = gelman_rubin(samples_chains, chain_dim=0, sample_dim=1)\n",
    "    split_rhat = split_gelman_rubin(samples_chains, chain_dim=0, sample_dim=1)\n",
    "    ess = effective_sample_size(samples_chains, chain_dim=0, sample_dim=1)\n",
    "    print(f\"{param}: R-hat = {rhat:.3f}, split R-hat = {split_rhat:.3f}, ESS = {ess:.1f}\")\n",
    "    \n",
    "    # 绘制 Trace Plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i in range(2):\n",
    "        plt.plot(samples_chains[i].cpu().numpy(), marker='o', label=f\"Chain {i+1}\", alpha=0.7)\n",
    "\n",
    "    plt.title(f\"Trace Plot for {param}\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(param)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 绘制 Histogram + Quantiles\n",
    "    plt.subplot(1, 2, 2)\n",
    "    all_samps = samples_chains.reshape(-1).cpu().numpy()\n",
    "\n",
    "    xmin, xmax = np.percentile(all_samps, [0.5, 99.5])\n",
    "\n",
    "    plt.hist(all_samps, bins=15, density=True, alpha=0.7, color='gray')\n",
    "\n",
    "    kde = gaussian_kde(all_samps)\n",
    "    x_grid = np.linspace(xmin, xmax, 200)\n",
    "    # plt.plot(x_grid, kde(x_grid), color='blue', linewidth=2, label=\"KDE\")\n",
    "    plt.plot(x_grid, kde(x_grid), color='blue', linewidth=2)\n",
    "\n",
    "    qs = torch.quantile(torch.from_numpy(all_samps), torch.tensor([0.025, 0.5, 0.975]))\n",
    "    for q in qs:\n",
    "        plt.axvline(q.item(), color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    # plt.xlim(0.1, 5)\n",
    "\n",
    "    plt.title(f\"Histogram + 2.5/50/97.5% Quantiles\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 绘制 ACF（仅第一“伪链”）\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plot_acf(samples_chains[0].cpu().numpy(), lags=40)\n",
    "    plt.title(f\"ACF for {param} (Chain 1)\")\n",
    "    plt.xlabel(\"Lag\")\n",
    "    plt.ylabel(\"Autocorrelation\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r = [(4.968), \n",
    "          (4.986), \n",
    "          (4.995), \n",
    "          (0.105), \n",
    "          (0.10), \n",
    "          (1.55),\n",
    "          (0.1), \n",
    "          (4.98), \n",
    "          (2.55), \n",
    "          (0.1)]\n",
    "\n",
    "Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, torch.tensor(test_r).cuda().unsqueeze(0)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ac69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225683c3",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPTG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
