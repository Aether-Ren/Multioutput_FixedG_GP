{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7b1e67",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7d7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import statsmodels\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from pyro.ops.stats import (\n",
    "    gelman_rubin,\n",
    "    split_gelman_rubin,\n",
    "    autocorrelation,\n",
    "    effective_sample_size,\n",
    "    resample,\n",
    "    quantile,\n",
    "    weighed_quantile\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import GP_functions.Loss_function as Loss_function\n",
    "import GP_functions.bound as bound\n",
    "import GP_functions.Estimation as Estimation\n",
    "import GP_functions.Training as Training\n",
    "import GP_functions.Prediction as Prediction\n",
    "import GP_functions.GP_models as GP_models\n",
    "import GP_functions.Tools as Tools\n",
    "import GP_functions.FeatureE as FeatureE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57c16c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_RealCase_train = pd.read_csv('Data/Y_train_std.csv', header=None, delimiter=',')\n",
    "# df_new = Y_RealCase_train.drop(Y_RealCase_train.columns[-18:], axis=1)\n",
    "# Y_data_train = df_new.drop(df_new.columns[17], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"Y_RealCase_train.csv\", Y_data_train.values, delimiter=\",\", fmt=\"%.8f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea4680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('RealCase/RealCase_X_train.csv', header=None, delimiter=',').values\n",
    "X_test = pd.read_csv('RealCase/RealCase_X_test.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_pca = pd.read_csv('RealCase/RealCase_Y_train_pca.csv', header=None, delimiter=',').values\n",
    "Y_test_pca = pd.read_csv('RealCase/RealCase_Y_test_pca.csv', header=None, delimiter=',').values\n",
    "Realcase_data_pca = pd.read_csv('RealCase/RealCase_Y_pca.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train_std = pd.read_csv('RealCase/RealCase_Y_train_std.csv', header=None, delimiter=',').values\n",
    "Y_test_std = pd.read_csv('RealCase/RealCase_Y_test_std.csv', header=None, delimiter=',').values\n",
    "Realcase_data_std = pd.read_csv('RealCase/RealCase_Y_std.csv', header=None, delimiter=',').values\n",
    "\n",
    "Y_train = pd.read_csv('RealCase/RealCase_Y_train.csv', header=None, delimiter=',').values\n",
    "Y_test = pd.read_csv('RealCase/RealCase_Y_test.csv', header=None, delimiter=',').values\n",
    "Realcase_data = pd.read_csv('RealCase/RealCase.csv', header=None, delimiter=',').values\n",
    "\n",
    "# Realcase_data_extra = pd.read_csv('RealCase/RealCase_Y_extra.csv', header=None, delimiter=',').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e64197",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Y_train[:,0] < 181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3950e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_hist_grid(Y, start=0, num=24, ncols=6, bins=30):\n",
    "\n",
    "\n",
    "    p = Y.shape[1]\n",
    "    end = min(p, start + num)\n",
    "    idxs = list(range(start, end))\n",
    "\n",
    "    nrows = math.ceil(len(idxs) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "    for k, j in enumerate(idxs):\n",
    "        r, c = divmod(k, ncols)\n",
    "        ax = axes[r][c]\n",
    "        ax.hist(Y[:, j], bins=bins)\n",
    "        ax.set_title(f\"col {j}\")\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # 多余子图关掉\n",
    "    for k in range(len(idxs), nrows*ncols):\n",
    "        r, c = divmod(k, ncols)\n",
    "        axes[r][c].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# real = Realcase_data.squeeze()\n",
    "plot_hist_grid(X_train[mask,:], start=0,  num=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "# seaborn.pairplot(pd.DataFrame(np.column_stack((Y_train[:,[1,2,7,8]], X_train[:,:10]))))\n",
    "\n",
    "# outer - zone 4 causes zone 1\n",
    "# outer - zone 1 causes zone 2\n",
    "# outer - zone 3 causes zone 3\n",
    "# outer - zone 2 causes zone 4\n",
    "# inner - zone 4 causes zone 1\n",
    "# middle - zone 5 causes zone 5\n",
    "# middle - zone 1 causes zone 2\n",
    "# middle - zone 3 causes zone 3\n",
    "# middle - zone 2 causes zone 4\n",
    "seaborn.kdeplot(pd.DataFrame(Y_train[:,[7,8,9,10,11,12]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d770d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.column_stack((Y_train[:,2], X_train[:,7:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053377a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38033fd9",
   "metadata": {},
   "source": [
    "## tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf0ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(X_train, dtype=torch.float32)\n",
    "test_x = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "train_y_pca = torch.tensor(Y_train_pca, dtype=torch.float32)\n",
    "test_y_pca = torch.tensor(Y_test_pca, dtype=torch.float32)\n",
    "realcase_y_pca = torch.tensor(Realcase_data_pca, dtype=torch.float32)\n",
    "\n",
    "train_y = torch.tensor(Y_train_std, dtype=torch.float32)\n",
    "test_y = torch.tensor(Y_test_std, dtype=torch.float32)\n",
    "realcase_y = torch.tensor(Realcase_data_std, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_min = np.nanmin(Y_train, axis=0)\n",
    "col_max = np.nanmax(Y_train, axis=0)\n",
    "\n",
    "\n",
    "((Realcase_data >= col_min) & (Realcase_data <= col_max)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aae49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Realcase_data >= col_min) & (Realcase_data <= col_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d982194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f866f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Realcase_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9694f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Realcase_data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_hist_grid(Y, real, start=0, num=24, ncols=6, bins=30):\n",
    "    real = np.asarray(real).squeeze()\n",
    "    if real.ndim == 0:\n",
    "        real = real[None]\n",
    "\n",
    "    p = Y.shape[1]\n",
    "    end = min(p, start + num)\n",
    "    idxs = list(range(start, end))\n",
    "\n",
    "    nrows = math.ceil(len(idxs) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "    for k, j in enumerate(idxs):\n",
    "        r, c = divmod(k, ncols)\n",
    "        ax = axes[r][c]\n",
    "        ax.hist(Y[:, j], bins=bins)\n",
    "        ax.axvline(real[j])  # RealCase 的位置\n",
    "        ax.set_title(f\"col {j}\")\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # 多余子图关掉\n",
    "    for k in range(len(idxs), nrows*ncols):\n",
    "        r, c = divmod(k, ncols)\n",
    "        axes[r][c].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "real = Realcase_data_pca.squeeze()\n",
    "plot_hist_grid(Y_train_pca, real, start=0,  num=33)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d3995",
   "metadata": {},
   "source": [
    "# Emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9cf6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device = 'cpu'\n",
    "\n",
    "Device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd48f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_models, MVGP_likelihoods = Training.train_MultitaskVGP_minibatch(\n",
    "    train_x=train_x.to(Device),\n",
    "    train_y=train_y.to(Device),\n",
    "    covar_type='RBF',\n",
    "    num_latents=42,\n",
    "    num_inducing=500,\n",
    "    lr_hyper=0.01,\n",
    "    lr_variational=0.1,\n",
    "    num_iterations=10000,\n",
    "    patience=10,\n",
    "    device=Device,\n",
    "    batch_size=512,\n",
    "    eval_every=100,\n",
    "    eval_batch_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model_state_dict': MVGP_models.state_dict(),\n",
    "    'likelihood_state_dict': MVGP_likelihoods.state_dict(),\n",
    "    'model_params': {\n",
    "        'num_latents': 42,\n",
    "        'num_inducing': 500,\n",
    "        'covar_type': 'RBF',\n",
    "        'input_dim': train_x.size(1),\n",
    "        'num_tasks': train_y.size(1)\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'multitask_gp_checkpoint_Realcase.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb877cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, train_x[0].cuda().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877679b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2835b4",
   "metadata": {},
   "source": [
    "## MVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df66aa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskGaussianLikelihood(\n",
       "  (raw_task_noises_constraint): GreaterThan(1.000E-04)\n",
       "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('multitask_gp_checkpoint_Realcase.pth', map_location=Device)\n",
    "model_params = checkpoint['model_params']\n",
    "\n",
    "MVGP_models = GP_models.MultitaskVariationalGP(train_x, train_y, \n",
    "                                               num_latents=model_params['num_latents'],\n",
    "                                               num_inducing=model_params['num_inducing'],  \n",
    "                                               covar_type=model_params['covar_type']).to(Device)\n",
    "\n",
    "MVGP_models.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "MVGP_likelihoods = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=train_y.shape[1]).to(Device)\n",
    "MVGP_likelihoods.load_state_dict(checkpoint['likelihood_state_dict'])\n",
    "\n",
    "MVGP_models.eval()\n",
    "MVGP_likelihoods.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5a1a3",
   "metadata": {},
   "source": [
    "# PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcbe270",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = realcase_y\n",
    "\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_GPU(input_point, train_x, train_y, k=500)\n",
    "\n",
    "bounds = bound.get_bounds(local_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "realcase_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_hist_grid(Y, real, start=0, num=24, ncols=6, bins=30):\n",
    "    real = np.asarray(real).squeeze()\n",
    "    if real.ndim == 0:\n",
    "        real = real[None]\n",
    "\n",
    "    p = Y.shape[1]\n",
    "    end = min(p, start + num)\n",
    "    idxs = list(range(start, end))\n",
    "\n",
    "    nrows = math.ceil(len(idxs) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "    for k, j in enumerate(idxs):\n",
    "        r, c = divmod(k, ncols)\n",
    "        ax = axes[r][c]\n",
    "        ax.hist(Y[:, j], bins=bins)\n",
    "        ax.axvline(real[j])  # RealCase 的位置\n",
    "        ax.set_title(f\"col {j}\")\n",
    "        ax.grid(alpha=0.2)\n",
    "\n",
    "    # 多余子图关掉\n",
    "    for k in range(len(idxs), nrows*ncols):\n",
    "        r, c = divmod(k, ncols)\n",
    "        axes[r][c].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_hist_grid(local_train_y, realcase_y, start=0,  num=33)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39504c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37666f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = local_train_x\n",
    "start=0\n",
    "num=11\n",
    "ncols=6\n",
    "bins=30\n",
    "\n",
    "p = Y.shape[1]\n",
    "end = min(p, start + num)\n",
    "idxs = list(range(start, end))\n",
    "\n",
    "nrows = math.ceil(len(idxs) / ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "for k, j in enumerate(idxs):\n",
    "    r, c = divmod(k, ncols)\n",
    "    ax = axes[r][c]\n",
    "    ax.hist(Y[:, j], bins=bins)\n",
    "    ax.set_title(f\"col {j}\")\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "# 多余子图关掉\n",
    "for k in range(len(idxs), nrows*ncols):\n",
    "    r, c = divmod(k, ncols)\n",
    "    axes[r][c].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def sobol_loguniform(\n",
    "    d: int,\n",
    "    *,\n",
    "    m: int | None = None,\n",
    "    n: int | None = None,\n",
    "    l_bounds=0.1,\n",
    "    u_bounds=5.0,\n",
    "    seed: int | None = None,\n",
    "    scramble: bool = True,\n",
    "    log_base: float = np.e,   # np.e 表示自然对数；10 表示 log10\n",
    "    return_engine: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    生成 Sobol 序列并将其映射为对数均匀分布（log-uniform）采样。\n",
    "\n",
    "    参数\n",
    "    ----\n",
    "    d : int\n",
    "        维度。\n",
    "    m : int, optional\n",
    "        使用 random_base2(m) 生成 2**m 个 Sobol 点（推荐 Sobol 的标准用法）。\n",
    "    n : int, optional\n",
    "        使用 random(n) 生成 n 个 Sobol 点（不要求 2 的幂）。\n",
    "    l_bounds, u_bounds : float or array-like\n",
    "        每一维的下界/上界。可传标量或长度为 d 的列表/数组。\n",
    "        注意：log-uniform 要求 l_bounds > 0。\n",
    "    seed : int, optional\n",
    "        随机种子（scramble=True 时生效）。\n",
    "    scramble : bool\n",
    "        是否打乱（推荐 True）。\n",
    "    log_base : float\n",
    "        对数底。np.e 表示自然对数；10 表示 log10。\n",
    "    return_engine : bool\n",
    "        是否同时返回 Sobol engine。\n",
    "\n",
    "    返回\n",
    "    ----\n",
    "    X : ndarray, shape (N, d)\n",
    "        对数均匀采样点。\n",
    "    (optional) engine : qmc.Sobol\n",
    "    \"\"\"\n",
    "    if (m is None) == (n is None):\n",
    "        raise ValueError(\"请二选一：提供 m（生成 2**m 个点）或提供 n（生成 n 个点）。\")\n",
    "\n",
    "    lb = np.asarray(l_bounds, dtype=float)\n",
    "    ub = np.asarray(u_bounds, dtype=float)\n",
    "\n",
    "    if lb.ndim == 0:\n",
    "        lb = np.full(d, lb)\n",
    "    if ub.ndim == 0:\n",
    "        ub = np.full(d, ub)\n",
    "\n",
    "    if lb.shape != (d,) or ub.shape != (d,):\n",
    "        raise ValueError(f\"l_bounds/u_bounds 必须是标量或长度为 d={d} 的数组。\")\n",
    "    if np.any(lb <= 0):\n",
    "        raise ValueError(\"log-uniform 要求所有下界 l_bounds > 0。\")\n",
    "    if np.any(ub <= lb):\n",
    "        raise ValueError(\"要求 u_bounds > l_bounds。\")\n",
    "\n",
    "    engine = qmc.Sobol(d=d, scramble=scramble, seed=seed)\n",
    "\n",
    "    U = engine.random_base2(m=m) if m is not None else engine.random(n=n)\n",
    "\n",
    "    # log-uniform 逐维变换\n",
    "    if log_base == 10:\n",
    "        log_lb = np.log10(lb)\n",
    "        log_ub = np.log10(ub)\n",
    "        X = 10 ** (log_lb + U * (log_ub - log_lb))\n",
    "    elif log_base == np.e:\n",
    "        log_lb = np.log(lb)\n",
    "        log_ub = np.log(ub)\n",
    "        X = np.exp(log_lb + U * (log_ub - log_lb))\n",
    "    else:\n",
    "        # 任意底：log_b(x)=ln(x)/ln(b)\n",
    "        ln_lb, ln_ub = np.log(lb), np.log(ub)\n",
    "        X = np.exp(ln_lb + U * (ln_ub - ln_lb))  # 采样不依赖底，只影响“解释”\n",
    "    \n",
    "    return (X, engine) if return_engine else X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extra = sobol_loguniform(\n",
    "    d=10,\n",
    "    m=10,\n",
    "    l_bounds=[0.1]*10,\n",
    "    u_bounds=[5]*10,\n",
    "    seed=24,\n",
    "    scramble=True,\n",
    "    log_base=np.e\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32050a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_extra\n",
    "m, n = df.shape\n",
    "\n",
    "\n",
    "new_data = np.zeros((m, 34))\n",
    "\n",
    "\n",
    "mapping = {\n",
    "    0: [4, 16],\n",
    "    1: [5, 17],\n",
    "    2: [10, 22],\n",
    "    3: [11, 23],\n",
    "    4: [8, 6, 20, 18],\n",
    "    5: [9, 7, 21, 19],\n",
    "    6: [2, 0, 14, 12],\n",
    "    7: [3, 1, 15, 13],\n",
    "    8: [24, 26, 28, 30, 32],\n",
    "    9: [25, 27, 29, 31, 33]\n",
    "}\n",
    "\n",
    "for orig_col, new_cols in mapping.items():\n",
    "    for new_col in new_cols:\n",
    "        new_data[:, new_col] = df[:, orig_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_extra_RealCase.txt\", new_data, fmt='%0.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X_extra\n",
    "start=0\n",
    "num=11\n",
    "ncols=6\n",
    "bins=30\n",
    "\n",
    "p = Y.shape[1]\n",
    "end = min(p, start + num)\n",
    "idxs = list(range(start, end))\n",
    "\n",
    "nrows = math.ceil(len(idxs) / ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(3.2*ncols, 2.4*nrows), squeeze=False)\n",
    "\n",
    "for k, j in enumerate(idxs):\n",
    "    r, c = divmod(k, ncols)\n",
    "    ax = axes[r][c]\n",
    "    ax.hist(Y[:, j], bins=bins)\n",
    "    ax.set_title(f\"col {j}\")\n",
    "    ax.grid(alpha=0.2)\n",
    "\n",
    "# 多余子图关掉\n",
    "for k in range(len(idxs), nrows*ncols):\n",
    "    r, c = divmod(k, ncols)\n",
    "    axes[r][c].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b731907",
   "metadata": {},
   "source": [
    "# PE Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e7d2c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa7e678d07e4e8da5e554d5dddedc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multi-start:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02975983fc8340ffb37a37eac49bd195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Start 1/16:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c8fd9321c447869717387d2de65113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Start 2/16:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      7\u001b[39m bounds = bound.get_bounds(local_train_x)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# estimated_params_tmp, Loss_tmp = Estimation.multi_start_estimation(\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#         MVGP_models, MVGP_likelihoods, row_idx, realcase_y, bounds,\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#         Estimation.estimate_params_for_one_model_Adam, num_starts=16, num_iterations=2000, lr=0.05,\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#         patience=15, attraction_threshold=0.1, repulsion_strength=0.1, device=Device, show_progress=True\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m estimated_params_tmp, Loss_tmp = \u001b[43mEstimation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_start_estimation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mMVGP_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMVGP_likelihoods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mEstimation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimate_params_for_one_model_Adam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_starts\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattraction_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepulsion_strength\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\programming\\python\\Multioutput_FixedG_GP\\GP_functions\\Estimation.py:117\u001b[39m, in \u001b[36mmulti_start_estimation\u001b[39m\u001b[34m(model, likelihood, row_idx, test_y, param_ranges, estimate_function, num_starts, num_iterations, lr, patience, attraction_threshold, repulsion_strength, device, show_progress, progress_desc)\u001b[39m\n\u001b[32m    111\u001b[39m sample = sobol_samples[start]\n\u001b[32m    112\u001b[39m initial_guess = [\n\u001b[32m    113\u001b[39m     min_val + s.item() * (max_val - min_val)\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m s, (min_val, max_val) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sample, param_ranges)\n\u001b[32m    115\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m estimated_params, loss = \u001b[43mestimate_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_guess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattraction_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattraction_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepulsion_strength\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepulsion_strength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# 关键：把开关传下去\u001b[39;49;00m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_desc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStart \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_starts\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 每次 start 的内层进度条标题\u001b[39;49;00m\n\u001b[32m    124\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss < best_overall_loss:\n\u001b[32m    127\u001b[39m     best_overall_loss = loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\programming\\python\\Multioutput_FixedG_GP\\GP_functions\\Estimation.py:64\u001b[39m, in \u001b[36mestimate_params_for_one_model_Adam\u001b[39m\u001b[34m(model, likelihood, row_idx, test_y, initial_guess, param_ranges, num_iterations, lr, patience, attraction_threshold, repulsion_strength, device, show_progress, progress_desc)\u001b[39m\n\u001b[32m     61\u001b[39m loss.backward(retain_graph=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     62\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m grad_norm = \u001b[43mtarget_x\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grad_norm < attraction_threshold:\n\u001b[32m     66\u001b[39m     target_x.grad.data += repulsion_strength * torch.randn_like(target_x.grad.data)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "row_idx = 0\n",
    "\n",
    "input_point = test_y[row_idx]\n",
    "\n",
    "local_train_x, local_train_y = Tools.find_k_nearest_neighbors_GPU(input_point, train_x, train_y, k=500)\n",
    "\n",
    "bounds = bound.get_bounds(local_train_x)\n",
    "\n",
    "# estimated_params_tmp, Loss_tmp = Estimation.multi_start_estimation(\n",
    "#         MVGP_models, MVGP_likelihoods, row_idx, realcase_y, bounds,\n",
    "#         Estimation.estimate_params_for_one_model_Adam, num_starts=16, num_iterations=2000, lr=0.05,\n",
    "#         patience=15, attraction_threshold=0.1, repulsion_strength=0.1, device=Device, show_progress=True\n",
    "#     )\n",
    "\n",
    "estimated_params_tmp, Loss_tmp = Estimation.multi_start_estimation(\n",
    "        MVGP_models, MVGP_likelihoods, row_idx, test_y, bounds,\n",
    "        Estimation.estimate_params_for_one_model_Adam, num_starts=16, num_iterations=2000, lr=0.05,\n",
    "        patience=15, attraction_threshold=0.1, repulsion_strength=0.1, device=Device, show_progress=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_params_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a91bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5910591",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(estimated_params_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53386486",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, torch.tensor(estimated_params_tmp).cuda().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded26516",
   "metadata": {},
   "source": [
    "# Check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_pca_result = pd.read_csv('RealCase/Result/MVGP_21_result.csv')\n",
    "MVGP_pca_result['estimated_params_list'] = MVGP_pca_result['estimated_params'].apply(ast.literal_eval)\n",
    "\n",
    "MVGP_pca_result = np.array(MVGP_pca_result['estimated_params_list'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ca9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVGP_pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "realcase_paras_pca = torch.tensor(MVGP_pca_result, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tmp = Prediction.preds_for_one_model(\n",
    "        MVGP_models, MVGP_likelihoods, realcase_paras_pca.to(Device)\n",
    "        ).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a3d66",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_result_Uniform = Estimation.run_mcmc_Uniform(\n",
    "    Prediction.preds_distribution, MVGP_models, MVGP_likelihoods, \n",
    "    row_idx, realcase_y_17, bounds, \n",
    "    num_sampling=1200, warmup_step=300, num_chains=1, device=Device\n",
    ")\n",
    "posterior_samples_Uniform = mcmc_result_Uniform.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eaa39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(posterior_samples_Uniform, \"mcmc_RealCase_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b7da8",
   "metadata": {},
   "source": [
    "# MCMC Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"RealCase/Result/MVGP_21_mcmc_result/result_1.pkl\", \"rb\") as f:\n",
    "    loaded_samples_chain1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_samples = torch.load(\"mcmc_RealCase_test.pt\", map_location=Device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309dfa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_est   = {k: v.mean(dim=0) for k, v in loaded_samples.items()}\n",
    "median_est = {k: v.median(dim=0).values for k, v in loaded_samples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PE_est = torch.tensor([2.331779  , 0.1191    , 3.3170652 , 1.2486118 , 1.4911077 ,0.1097    , 1.3861945 , 0.11462227, 0.453993  , 4.9712])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4115637",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, PE_est.cpu().unsqueeze(0)), realcase_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97423654",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_est_tensor = torch.stack([mean_est[f\"param_{i}\"] for i in range(len(mean_est))])\n",
    "median_est_tensor = torch.stack([median_est[f\"param_{i}\"] for i in range(len(median_est))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, mean_est_tensor.cpu().unsqueeze(0)), realcase_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, median_est_tensor.cpu().unsqueeze(0)), realcase_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_mode_hist(x, bins=60):\n",
    "    x = x.detach().flatten()\n",
    "    xmin, xmax = x.min().item(), x.max().item()\n",
    "    hist = torch.histc(x, bins=bins, min=xmin, max=xmax)\n",
    "    idx = int(hist.argmax())\n",
    "    edges = torch.linspace(xmin, xmax, bins + 1)\n",
    "    return 0.5 * (edges[idx] + edges[idx + 1])\n",
    "\n",
    "mode_est = {}\n",
    "for k, v in loaded_samples.items():\n",
    "\n",
    "    if v.ndim == 1:\n",
    "        mode_est[k] = approx_mode_hist(v)\n",
    "    else:\n",
    "        mode_est[k] = torch.stack([approx_mode_hist(v[:, i]) for i in range(v.shape[1])])\n",
    "\n",
    "print(mode_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d2c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r = [np.float32(2.2888), \n",
    "          np.float32(0.1250), \n",
    "          np.float32(3.9497), \n",
    "          np.float32(1.6686), \n",
    "          np.float32(0.1079), \n",
    "          np.float32(2.2909), \n",
    "          np.float32(1.3089), \n",
    "          np.float32(0.1650), \n",
    "          np.float32(0.6204), \n",
    "          np.float32(4.9653)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af31c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, torch.tensor(test_r).cpu().unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc79a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "realcase_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.mse_loss(Prediction.preds_for_one_model(MVGP_models, MVGP_likelihoods, torch.tensor(test_r).cpu().unsqueeze(0)), realcase_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a28652",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_chain_samples = loaded_samples_chain1  # dict: param -> Tensor[n_samples]\n",
    "\n",
    "# 将每条参数的样本拆成两半\n",
    "def split_chain(chain_tensor):\n",
    "    n = chain_tensor.shape[0]\n",
    "    half = n // 2\n",
    "    return chain_tensor[:half], chain_tensor[half:2*half]\n",
    "\n",
    "# 整理成 mcmc_samples：param -> Tensor[2, n_half]\n",
    "mcmc_samples = {}\n",
    "for param, samples in single_chain_samples.items():\n",
    "    chain_a, chain_b = split_chain(samples)\n",
    "    # 如果原链长度是奇数，可以选择丢弃最后一个样本或做其他处理\n",
    "    mcmc_samples[param] = torch.stack([chain_a, chain_b], dim=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 诊断和可视化\n",
    "for param, samples_chains in mcmc_samples.items():\n",
    "\n",
    "    \n",
    "    # 计算诊断量\n",
    "    rhat = gelman_rubin(samples_chains, chain_dim=0, sample_dim=1)\n",
    "    split_rhat = split_gelman_rubin(samples_chains, chain_dim=0, sample_dim=1)\n",
    "    ess = effective_sample_size(samples_chains, chain_dim=0, sample_dim=1)\n",
    "    print(f\"{param}: R-hat = {rhat:.3f}, split R-hat = {split_rhat:.3f}, ESS = {ess:.1f}\")\n",
    "    \n",
    "    # 绘制 Trace Plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i in range(2):\n",
    "        plt.plot(samples_chains[i].cpu().numpy(), marker='o', label=f\"Chain {i+1}\", alpha=0.7)\n",
    "\n",
    "    plt.title(f\"Trace Plot for {param}\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(param)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 绘制 Histogram + Quantiles\n",
    "    plt.subplot(1, 2, 2)\n",
    "    all_samps = samples_chains.reshape(-1).cpu().numpy()\n",
    "\n",
    "    xmin, xmax = np.percentile(all_samps, [0.5, 99.5])\n",
    "\n",
    "    plt.hist(all_samps, bins=15, density=True, alpha=0.7, color='gray')\n",
    "\n",
    "    kde = gaussian_kde(all_samps)\n",
    "    x_grid = np.linspace(xmin, xmax, 200)\n",
    "    # plt.plot(x_grid, kde(x_grid), color='blue', linewidth=2, label=\"KDE\")\n",
    "    plt.plot(x_grid, kde(x_grid), color='blue', linewidth=2)\n",
    "\n",
    "    qs = torch.quantile(torch.from_numpy(all_samps), torch.tensor([0.025, 0.5, 0.975]))\n",
    "    for q in qs:\n",
    "        plt.axvline(q.item(), color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    # plt.xlim(0.1, 5)\n",
    "\n",
    "    plt.title(f\"Histogram + 2.5/50/97.5% Quantiles\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 绘制 ACF（仅第一“伪链”）\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plot_acf(samples_chains[0].cpu().numpy(), lags=40)\n",
    "    plt.title(f\"ACF for {param} (Chain 1)\")\n",
    "    plt.xlabel(\"Lag\")\n",
    "    plt.ylabel(\"Autocorrelation\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225683c3",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPTG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
